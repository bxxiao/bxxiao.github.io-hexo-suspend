{"meta":{"title":"bxxiao","subtitle":null,"description":"nothing","author":"bxxiao","url":"http://example.com","root":"/"},"pages":[{"title":"tags","date":"2021-03-20T06:25:13.000Z","updated":"2021-03-20T06:25:25.756Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-03-20T06:24:10.000Z","updated":"2021-03-20T06:24:47.255Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"线程池","slug":"Java/多线程/线程池","date":"2021-04-17T14:24:03.426Z","updated":"2021-04-18T02:11:49.360Z","comments":true,"path":"2021/04/17/Java/多线程/线程池/","link":"","permalink":"http://example.com/2021/04/17/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"为什么要使用线程池 ★使用线程池主要有以下三个原因： 创建/销毁线程需要消耗系统资源，线程池可以复用已创建的线程。 控制并发的数量。并发数量过多，可能会导致资源消耗过多，从而造成服务器崩溃。（主要原因） 可以对线程做统一管理。 ThreadPoolExecutorThreadPoolExecutor 是 JUC 下的一个线程池实现。 线程池状态ThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量。这些信息存储在一个 AtomicInteger 类型的变量 ctl 中，目的是将线程池状态与线程个数合二为一，这样就可以用一次 cas 原子操作进行赋值： 1234private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));// rs 为高 3 位代表线程池状态， wc 为低 29 位代表线程个数private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; ThreadPoolExecutor 中定义的 5 种状态： 1234567private static final int COUNT_BITS = Integer.SIZE - 3;// 29// 5种状态private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 它们的含义是： RUNNING (111)：线程池创建后的状态。可以接收新任务和处理阻塞队列中的任务。 SHUTDOWN (000)：线程池停止接收新任务，但会处理完阻塞队列中的剩余任务。 STOP (001)：：线程池停止接收新任务，同时抛弃阻塞队列中的任务。 TIDYING (010)：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为 TIDYING 状态。接着会执行terminated()函数。 TERMINATED (011)：线程池处在 TIDYING 状态时，执行完 terminated() 方法之后，就会由 TIDYING -&gt; TERMINATED。 构造方法一共有四个构造方法： 12345678910111213141516171819202122232425262728293031// 五个参数的构造函数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue)// 六个参数的构造函数-1public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory)// 六个参数的构造函数-2public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler)// 七个参数的构造函数public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 7 个参数的含义： 必须的 5 个参数： int corePoolSize：该线程池中核心线程数最大值。 核心线程：线程池中有两类线程，核心线程和非核心线程。核心线程默认情况下会一直存在于线程池中，即使这个核心线程什么都不干（铁饭碗），而非核心线程如果长时间的闲置，就会被销毁（临时工）。 int maximumPoolSize：该线程池中线程总数最大值 。（非核心线程数 = maximumPoolSize - corePoolSize） long keepAliveTime：非核心线程闲置超时时长。非核心线程如果处于闲置状态超过该值，就会被销毁。 TimeUnit unit：keepAliveTime 的单位。 BlockingQueue workQueue：阻塞队列，维护着等待执行的 Runnable 任务对象。 常用的几个阻塞队列： LinkedBlockingQueue：链式阻塞队列，底层数据结构是链表，默认大小是Integer.MAX_VALUE，也可以指定大小。 ArrayBlockingQueue：数组阻塞队列，底层数据结构是数组，需要指定队列的大小。 SynchronousQueue：同步队列，这个队列接收到任务的时候，会直接提交给线程处理，而不保留它，如果所有线程都在工作，那就需要新建一个线程来处理这个任务。如果这时线程池已满，则会抛出 java.util.concurrent.RejectedExecutionException 异常，使用这个类型队列的时候，maximumPoolSize 一般指定成 Integer.MAX_VALUE ，即无限大。 DelayQueue：延迟队列，该队列中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素 。 另外 2 个参数： ThreadFactory threadFactory：创建线程的工厂 ，用于批量创建线程，统一在创建线程时设置一些参数，如是否守护线程、线程的优先级等。如果不指定，会新建一个默认的线程工厂。 RejectedExecutionHandler handler：拒绝策略，线程数量大于最大线程数就会采用拒绝处理策略，四种拒绝处理的策略为 ： ThreadPoolExecutor.AbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常。是默认拒绝处理策略。 ThreadPoolExecutor.DiscardPolicy：丢弃新来的任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列头部（最旧的）的任务，然后重新尝试执行程序。 ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务。 工作流程 线程总数量 &lt; corePoolSize，无论线程是否空闲，都会新建一个核心线程执行任务（让核心线程数量快速达到corePoolSize），注意，这一步需要获得全局锁（需要加锁进行）。 线程总数量 &gt;= corePoolSize 时，新来的线程任务会进入阻塞队列中等待，之后空闲的核心线程会依次去缓存队列中取任务来执行（体现了线程复用）。 当缓存队列满了，且无空闲核心线程，说明这个时候任务已经多到爆棚，需要一些“临时工”来执行这些任务了。于是会创建非核心线程去执行新来的任务。注意，创建非核心线程同样需要获得全局锁。 缓存队列满了， 且总线程数达到了 maximumPoolSize ，则会执行拒绝策略。 当高峰过去后，超过 corePoolSize 的救急线程如果一段时间没有任务做，需要结束掉节省资源，这个时间由 keepAliveTime 和 unit 来控制。 以上过程相关源码在 execute(Runnable command) 。（to be …） 如何做到线程复用总的来说： ThreadPoolExecutor 中会把线程封装成一个 Worker 对象： 12private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123;...&#125;//注意实现了Runnable接口 当一个 worker 在运行时，会通过 while 循环不断获取提交的任务或阻塞队列中的任务，而当在阻塞队列中获取不到任务时，会将线程阻塞，不占用 CPU ，直到拿到任务重新开始执行。 runWorker(Worker w) 中的 while 循环： 1while (task != null || (task = getTask()) != null) 阻塞的代码在 getTask() 中的 workQueue.take(); 。 具体源码分析 to be … 一些 API12345678910111213141516171819202122232425262728293031323334353637383940// 1.提交任务，测试代码见 thread_pool.jdk.TestSubmit`// 执行任务 void execute(Runnable command);// 提交任务 task，用返回值 Future 获得任务执行结果 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);// 提交 tasks 中所有任务 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException;// 提交 tasks 中所有任务，带超时时间 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException;// 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消，带超时时间 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;// 2.关系线程池 测试代码见 thread_pool.jdk.TestShtuDown// 线程池状态变为 SHUTDOWN void shutdown();// 线程池状态变为 STOP List&lt;Runnable&gt; shutdownNow();// 3.其他// 不在 RUNNING 状态的线程池，此方法就返回trueboolean isShutdown();// 线程池状态是否是 TERMINATEDboolean isTerminated();// 调用 shutdown 后，由于调用线程并不会等待所有任务运行结束，因此如果它想在线程池 TERMINATED 后做些事情，//可以利用此方法等待 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; Executors根据 ThreadPoolExecutor 的构造方法，JDK提供的 Executors 类中提供了众多工厂方法来创建各种用途的线程池 newCachedThreadPool1234567public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, // 核心线程数为0 Integer.MAX_VALUE, // 线程总数 60L,// 线程存活时间60s TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 运行流程如下： 提交任务进线程池。 因为 corePoolSize 为 0 的关系，不创建核心线程，线程池最大为 Integer.MAX_VALUE 。 所以直接将任务添加到 SynchronousQueue 队列。 添加到 SynchronousQueue 队列的任务会立刻提交给线程处理，如果此时没有空闲线程，则创建非核心线程进行处理。 整个线程池表现为线程数会根据任务量不断增长，没有上限，当任务执行完毕，空闲1分钟后释放线程。适合任务数比较密集，但每个任务执行时间较短的情况。 SynchronousQueue 使用示例： 12345678910111213141516171819public static void main(String[] args) &#123; ThreadPoolExecutor executor = new ThreadPoolExecutor(9, 9, 0L, TimeUnit.SECONDS, new SynchronousQueue&lt;&gt;()); for (int i = 0; i &lt; 10; i++) &#123; Runnable task = () -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; start...&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; end...&quot;); &#125;; executor.execute(task); &#125;&#125; 输出：因为第5个线程提交时没有线程可以处理，抛出异常 12345678910Exception in thread &quot;main&quot; java.util.concurrent.RejectedExecutionException: Task test.TestJdk8$$Lambda$1/1078694789@7ba4f24f rejected from java.util.concurrent.ThreadPoolExecutor@3b9a45b3[Running, pool size = 4, active threads = 4, queued tasks = 0, completed tasks = 0] at ...pool-1-thread-1 start...pool-1-thread-3 start...pool-1-thread-4 start...pool-1-thread-2 start...pool-1-thread-4 end...pool-1-thread-2 end...pool-1-thread-3 end...pool-1-thread-1 end... newFixedThreadPool1234567public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 特点： 核心线程数是自定义的。 核心线程数 = 最大线程数（没有救急线程被创建），因此也无需超时时间 。 阻塞队列默认大小是 Integer.MAX_VALUE 。队列长度很大，一般不会有队列满的情况。 适用于任务量已知，相对耗时的任务。 与CachedThreadPool的区别： 因为 corePoolSize == maximumPoolSize ，所以 FixedThreadPool 只会创建核心线程。 而 CachedThreadPool 因为corePoolSize=0，所以只会创建非核心线程。 newFixedThreadPool在 getTask() 方法中，如果队列里没有任务可取，线程会一直阻塞在 LinkedBlockingQueue.take() ，不会被回收，而 CachedThreadPool 会在 60s 后收回。 由于线程不会被回收，会一直卡在阻塞，所以没有任务的情况下， FixedThreadPool占用资源更多。 都几乎不会触发拒绝策略，但是原理不同。FixedThreadPool 是因为阻塞队列可以很大（最大为Integer最大值），故几乎不会触发拒绝策略；CachedThreadPool 是因为线程池很大（最大为Integer最大值），几乎不会导致线程数量大于最大线程数，故几乎不会触发拒绝策略。 newSingleThreadExecutor1234567public static ExecutorService newSingleThreadExecutor() &#123; // 注意这里用FinalizableDelegatedExecutorService封装了ThreadPoolExecutor return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 使用场景：希望多个任务串行执行。线程数固定为 1，任务数多于 1 时，会放入队列排队。任务执行完毕，这唯一的线程也不会被释放。 优点： 自己创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施，而线程池还会新建一个线程，保证池的正常工作 Executors.newSingleThreadExecutor()线程个数始终为1，不能修改 FinalizableDelegatedExecutorService 应用的是装饰器模式，只对外暴露了 ExecutorService 接口，因此不能调用 ThreadPoolExecutor 中特有的方法。 Executors.newFixedThreadPool(1) 初始时为1，以后还可以修改 对外暴露的是 ThreadPoolExecutor 对象，可以强转后调用 setCorePoolSize 等方法进行修改 newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。 12345678910public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;//ScheduledThreadPoolExecutor():public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue());&#125; 《阿里巴巴开发手册》不建议直接使用 Executors 类中的线程池，而是通过 ThreadPoolExecutor 的方式，这样的处理方式=需要更加明确线程池的运行规则，规避资源耗尽的风险。 但如果对线程池非常熟悉，又确定业务规模不会大到资源耗尽的程度（比如线程数量或任务队列长度可能达到Integer.MAX_VALUE）时，其实是可以使用 JDK 提供的这几个接口的，它能让代码具有更强的可读性。 参考 线程池原理 黑马Java并发视频","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"Java并发","slug":"Java并发","permalink":"http://example.com/Tag/Java%E5%B9%B6%E5%8F%91/"}]},{"title":"AQS详解","slug":"Java/多线程/AQS详解","date":"2021-04-16T02:08:41.653Z","updated":"2021-04-18T13:27:18.613Z","comments":true,"path":"2021/04/16/Java/多线程/AQS详解/","link":"","permalink":"http://example.com/2021/04/16/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/AQS%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"概述AQS 的全称为 AbstractQueuedSynchronizer ，即抽象同步队列，这个类在 java.util.concurrent.locks 包下。 抽象：抽象类，只实现一些主要逻辑，有些方法由子类实现； 队列：使用先进先出（FIFO）队列存储数据； 同步：实现了同步的功能。 AQS 是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出应用广泛的大量的同步器，比如 ReentrantLock ，Semaphore ，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于 AQS 的。也能利用 AQS 非常轻松容易地构造出符合自己需求的同步器。 AQS 基本数据结构AQS 内部定义了一个 volatile 变量 state 来标识资源的状态，state 的值没有统一的定义，不同的锁实现对state的定义和操作不同。对于 AQS 来说， 线程同步的关键就是对状态值 state 进行操作。 1private volatile int state; AQS 提供了 3 个方法来操作 state ： 123getState()setState()compareAndSetState() 其中，第 3 个方法基于 Unsafe.compareAndSwapInt() 方法保证原子性。 AQS 类本身实现的是一些竞争资源时排队和阻塞的机制，比如具体线程等待队列的维护（如获取资源失败入队/唤醒出队等）。其内部使用一个 FIFO 的双端阻塞队列，并用了两个指针标识队头队尾，注意两个变量都使用 volatile 修饰，这两个变量可能同时会有多个线程访问，所以修改 head、tail 的操作都使用 cas 操作： 12private transient volatile Node head;private transient volatile Node tail; 队列并不是直接储存线程，而是储存拥有线程的 Node 节点。 Node 内部类的源码： 12345678910111213141516171819202122232425262728293031323334353637383940static final class Node &#123; // 标记一个结点（对应的线程）在共享模式下等待 static final Node SHARED = new Node(); // 标记一个结点（对应的线程）在独占模式下等待 static final Node EXCLUSIVE = null; // waitStatus的4个值 static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; // 等待状态，取值范围是上面定义的 4 个静态常量 volatile int waitStatus; volatile Node prev; // 前驱结点 volatile Node next; // 后继结点 volatile Thread thread; // 结点对应的线程 // 连接下一个在condition里等待的结点 Node nextWaiter; // 判断共享模式的方法 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter // 要注意结点的模式是由nextWaiter记录的 this.nextWaiter = mode; this.thread = thread; &#125; //...&#125;// AQS里面的addWaiter私有方法private Node addWaiter(Node mode) &#123; // 使用了Node的这个构造函数 Node node = new Node(Thread.currentThread(), mode); // 其它代码省略&#125; Node 的 5 种状态含义： CANCELLED(1)：表示当前结点已取消调度，即不参与资源竞争。当 timeout 或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。 SIGNAL(-1)：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为 SIGNAL 。 CONDITION(-2)：表示结点等待在 Condition 上，当其他线程调用了 Condition 的 signal() 方法后，CONDITION 状态的结点将从条件等待队列转移到阻塞队列中，等待获取同步锁。 PROPAGATE(-3)：javadoc：waitStatus value to indicate the next acquireShared should unconditionally propagate。应该是表示：下一次共享模式下的资源请求会无条件传播？ 0：新结点入队时的默认状态。 由源码可知，通过 Node 可以实现两个队列： 一个是通过 prev 和 next 实现的 CLH 队列（线程同步队列，双向队列），即阻塞队列。 一个是通过 nextWaiter 实现 Condition 等待条件上的等待队列，这是一个单向队列。AQS 有个内部类 ConditionObject ， 一个 ConditioObject 对象就是一个条件变量，每个条件变量对应一个条件队列（单向链表队列），其用来存放调用条件变量的 await 方法后被阻塞的线程。这里的条件队列就是通过 nextWaiter 维护。 资源共享模式资源有两种共享模式，或者说两种同步方式： 独占模式（Exclusive）：资源是独占的，一次只能有一个线程获取到资源。如果一个线程获取到了资源，就会标记是这个线程获取到了。如 ReentrantLock。 共享模式（Share）：资源可以同时被多个线程获取，具体的资源个数可以通过参数指定。如 Semaphore/CountDownLatch。 AQS 针对不同的模式提供了不同的顶层 api ： 在独占方式下获取和释放资源使用的 API 为： 123void acquire(in arg)void acquireInterruptibly(int arg)boolean release(int arg) 在共享方式下获取和释放资源的 API 为： 123void acquireShared(int arg)void acquireSharedInterruptibly(int arg)boolean releaseShared(int arg) AQS 是基于模板方法模式的，其中获取资源/释放资源等方法需要由子类实现，主要有： isHeldExclusively()：该线程是否正在独占资源。只有用到 Condition 才需要去实现它。 独占模式相关方法： boolean tryAcquire(int)：独占方式。尝试获取资源，成功则返回 true，失败则返回 false。 boolean tryRelease(int)：独占方式。尝试释放资源，成功则返回 true，失败则返回 false。 共享模式相关方法： int tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0 表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 int tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回 true，否则返回 false。 这些方法都是定义成 protected 而不是 abastract，这样子类只需要实现需要的方法即可，比如独占模式下只用实现 tryAcquire-tryRelease 即可。 它们的方法体都是抛出一个异常： 1throw new UnsupportedOperationException(); 独占模式acquire() 源码解析accquire(int) 方法是独占模式下获取资源的底层入口，其总体逻辑是：首先尝试获取资源，若获取成功则返回；否则进入阻塞队列等待，直到获得资源为止，且等待过程是不响应线程打断的（interrunpt），若中途有被打断过，则作记录，获取资源成功后再补上打断。 acquire 方法源码： 12345678public final void acquire(int arg) &#123; if ( // 尝试获取资源 !tryAcquire(arg) &amp;&amp; // 失败时的操作 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 具体流程： tryAcquire() 尝试获取资源，成功则返回 true，否则 false。这里体现了非公平锁的特性，每个线程获取锁时会尝试直接抢占加塞一次（即与阻塞队列中的线程竞争）。 tryAcquire() 获取资源失败，则通过 addWaiter() 将线程加入阻塞队列队尾，并标记为独占模式（Node.EXCLUSIVE）。 acquireQueued() 将线程阻塞在阻塞队列直到线程获取到资源时返回，若等待过程中线程有被打断过，返回 true，否则 false 。 线程在等待过程中被中断是不响应的，所以若是有被打断过，则通过 selfInterrupt() 将打断补上。 tryAcquire()tryAcquire() 具体实现由子类提供。 123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; addWaiter()addWaiter() 将线程加入阻塞队列队尾，并返回当前线程所在的结点。 源码： 123456789101112131415161718192021222324252627282930313233343536private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // fast path 指如果队列不为空，通过 CAS 操作尝试直接加入队尾 Node pred = tail; if (pred != null) &#123; node.prev = pred; // 设置head需要通过CAS保证线程安全 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 若队列为空或 CAS 操作失败 enq(node); return node;&#125;private Node enq(final Node node) &#123; // cas自旋 for (;;) &#123; Node t = tail; // 队列为空，初始化一个空结点 if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; // 不为空，加入队尾 &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; acquireQueued() ★线程在阻塞队列中阻塞，直到获取到资源，若等待过程有被打断过，返回 true，否则 false 。 123456789101112131415161718192021222324252627282930313233343536373839final boolean acquireQueued(final Node node, int arg) &#123; // 标记是否获取资源成功 boolean failed = true; try &#123; // 标记等待过程是否有被打断过 boolean interrupted = false; // “自旋” for (;;) &#123; // 当前结点的前驱结点 final Node p = node.predecessor(); // 如果p是head，即node是队列第二个结点，且获取资源成功 // 这里可以看出只有node结点是队列的第二个结点，才有机会去竞争资源 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 将node设为头结点，即head指向的结点就是获取到资源的结点或为null setHead(node); // 将p从队列断开（node.prev已为null） p.next = null; // help GC failed = false;// 成功获取到资源 return interrupted; &#125; // 判断是否应该进行阻塞(shouldParkAfterFailedAcquire)，若是，通过park进入waiting状态，当被 // 唤醒时，判断线程是否被打断过(parkAndCheckInterrupt)，若是，将interrupted置为true // 即等待过程中被打断只是先做一下标记，最后再返回；这就是不响应打断的具体表现 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 如果等待过程中没有成功获取资源（抛出异常或其他情况？），那么取消结点在队列中的等待。 if (failed) cancelAcquire(node); &#125;&#125;private void setHead(Node node) &#123; head = node; node.thread = null;/// node.prev = null;&#125; 下面重点分析下 shouldParkAfterFailedAcquire() 源码： 1234567891011121314151617181920212223private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 前驱结点状态 int ws = pred.waitStatus; // 若为SIGNAL，返回true if (ws == Node.SIGNAL) return true; // 否则，若是大于0（大于0只有一种状态，就是CANCEL(1)，表示结点已放弃参与竞争） if (ws &gt; 0) &#123; // 往前一直找，找到一个状态小于0的结点 // 随后所有的CANCEL结点会从队列中断开，稍后会被gc掉 // 只有位于第二个结点的线程才能竞争资源，所以需要去掉状态为CANCEL的结点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 状态不是CANCEL，则通过CAS尝试设置为SIGNAL， // 允许失败，如其他线程在释放资源时 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; // 返回false，随后再进入该方法进行判断 return false;&#125; shouldParkAfterFailedAcquire() 方法的作用是判断是否应该进行阻塞，是则返回 true；判断的标准是前驱结点的状态是否是 SIGNAL(-1)。如果不是 CANCEL ，则通过 CAS 尝试修改为 SIGNAL，这样下次进入该方法可以直接返回不作处理。 将前驱结点状态置为 SIGNAL 的原因是： 在释放资源成功后，会唤醒阻塞中的结点（中的线程），而执行唤醒操作是有条件的，即：（代码在release 方法中） 12if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); 也就是如果结点是状态是 0 ，就不会执行唤醒操作。而一个结点被创建出来直到加入队列中时，并没有设置它的状态（即 Node 类的 waitStatus 成员变量），即一直是默认值 0 ，所以需要在 shouldParkAfterFailedAcquire() 方法中将前驱结点的状态设置为 SIGNAL，即让其状态不等于 0 ，以便让前驱结点在释放资源时会唤醒自己。 即一个结点的状态如果是 SIGNAL ，则该结点释放资源时会去唤醒后继结点。 同时shouldParkAfterFailedAcquire() 方法也会将当前结点前面状态为 CANCEL 的结点从队列中断开。 总结该方法作用：检查当前结点是否处于一个“安全状态”，即是否可以被唤醒，是则返回 true ，否则进行一些处理之后返回 false。 123456// 真正阻塞线程的方法（通过park），被唤醒(unpark)或打断(interrupt)后，返回当前线程是否有被打断过// 另外要注意的是 Thread.interrupted() 会清除打断标志private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; 小结总结下 acquireQueued() 的具体流程： 检查状态，找到安全休息点； 通过 park() 进入 waiting 状态，等待被 unpark() 或 interrupt() 唤醒。 被唤醒后记录打断状态，然后判断是否能尝试获取资源（是否是第二个结点），若能则尝试获取。 若获取资源成功，将当前结点设置为 head ，返回是否被中断过；若获取失败，回到 1 。 一些要注意的点： 阻塞队列中的结点，只有处于第二个结点的位置，才有机会去竞争资源。 若当前结点成功竞争到资源，则将 head 指针指向该结点，所以 head 指向的结点是获取到资源的结点或为 null 。 线程进入阻塞前需要进行状态检查，保证可以有进行资源竞争的机会。 若阻塞过程被 interrupt() ，只是做一个标记（acquireQueued() 中将 interrupted 置为 true），不会进行其他响应，当获取到资源时再返回是否被打断过，若有再在 acquire() 中通过 selfInterrupt() 补上。 release()此方法是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。 release() 源码： 1234567891011public final boolean release(int arg) &#123; // 通过tryRelease尝试释放资源，若成功，则唤醒阻塞队列的下一格线程， // 并返回true，否则返回false if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; tryRelease()123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; 该方法需要由子类提供具体实现。 一般情况下 tryRelease() 都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，所以其他线程不可能拿到资源，也就是只可能有一个线程来释放资源，所以直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。 但要注意它的返回值，release()是根据 tryRelease() 的返回值来判断该线程是否已经完成释放掉资源了。所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回 false。 unparkSuccessor()此方法的作用是：用 unpark() 唤醒等待队列中最靠前的非 CANCEL 线程。 源码： 1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; // 若当前结点状态小于0，置零当前线程所在的结点状态，允许失败。 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 找到下一个需要被唤醒的点，一般情况下nede.next就是要唤醒的结点 Node s = node.next; // 若s为null或状态是CANCEL if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从队尾往前，找到最靠前的状态 &lt;= 0的结点，将s指向它 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // s不为null if (s != null) LockSupport.unpark(s.thread);&#125; 此时，再和 acquireQueued() 联系起来： 某个结点 s 被唤醒后，进入 if (p == head &amp;&amp; tryAcquire(arg)) 的判断； 如果 s 是是老二结点，则直接可以竞争资源； 如果不是，通过 shouldParkAfterFailedAcquire() 方法调整后也会跑到 head 之后，在下一次自旋就可以满足 p==head 进而竞争资源； 如果竞争成功，就把自己设置成 head 结点，表示已经获取到资源了，acquire() 方法结束。 共享模式acquireShared()共享模式下获取资源的顶层入口，尝试获取指定资源数，若成功则方法结束；否则进入阻塞队列等待，直到获取到直到资源，同独占模式一样，等待过程不响应中断，过后再补上。 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; tryAcquireShared()该方法需要由子类实现，JDK 定义好了它的返回值含义： 返回负数，表示获取资源失败； 返回 0 ，表示获取资源成功，但剩余资源为 0 。 返回正数，表示获取资源成功，还有剩余资源可获取（正数不代表剩余资源数）。 doAcquireShared()获取资源失败后进入阻塞队列等待，直到获取到资源，等待过程不响应中断。 源码： 1234567891011121314151617181920212223242526272829303132private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);// 插入队尾 boolean failed = true;// 标记是否获取到了资源 try &#123; boolean interrupted = false;// 是否被中断过 for (;;) &#123; final Node p = node.predecessor();// 获取前驱结点 // 如果当前结点是老二 if (p == head) &#123; // 尝试获取资源，并记录返回值 int r = tryAcquireShared(arg); // 获取资源成功 if (r &gt;= 0) &#123; // 将当前结点置为head并根据r的值决定是否唤醒其他线程 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt();// 补上中断 failed = false; return; &#125; &#125; // 判断是否可以进入阻塞，与独占模式同 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; doAcquireShared() 的过程与 acquireQueued() 大致相同，主要区别是共享模式中若获取资源后还有剩余资源，则会继续唤醒阻塞的线程，唤醒线程的源码在 setHeadAndPropagate() 方法中： 123456789101112131415161718192021222324252627282930/**Sets head of queue, and checks if successor may be waiting in shared mode, if so propagating if either propagate &gt; 0 or PROPAGATE status was set.*/private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); // 设置node为新head /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don&#x27;t know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; // 符合条件，唤醒后继共享模式线程 Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; doReleaseShared() 分析方法见下文。 releaseShared()共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果成功释放会唤醒等待队列里的其他线程来获取资源。 源码： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; tryReleaseShared()释放指定资源数，成功返回 true，否则 false 。需要由子类实现。 doReleaseShared()源码： 12345678910111213141516171819202122232425262728293031private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ // 自旋，共享模式，持有同步状态的线程可能有多个，采用循环CAS保证线程安全 for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 可能同时有多个线程释放资源， if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 参考 https://www.cnblogs.com/waterystone/p/4920797.html https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"Java并发","slug":"Java并发","permalink":"http://example.com/Tag/Java%E5%B9%B6%E5%8F%91/"}]},{"title":"多线程-原理","slug":"Java/多线程/多线程-原理","date":"2021-04-15T16:36:11.645Z","updated":"2021-04-16T01:19:31.914Z","comments":true,"path":"2021/04/16/Java/多线程/多线程-原理/","link":"","permalink":"http://example.com/2021/04/16/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E5%8E%9F%E7%90%86/","excerpt":"","text":"Java内存模型并发编程模型在并发编程中，需要处理两个关键问题：线程之间如何通信及线程之间如何同步。通信是指线程之间以何种机制来交换信息。同步是指程序中用于控制不同线程间操作发生相对顺序的机制。 有两种并发模型可以解决这两个问题： 消息传递并发模型。线程之间没有公共状态，线程之间必须通过发送消息来显式进行通信；而由于消息的发送必须在消息的接收之前，即需要等待回应到达后再执行剩下步骤，因此同步是隐式进行的。 共享内存并发模型。线程之间共享程序的公共状态，通过写-读内存中的公共状态进行隐式通信；这种模型中，同步需要显式进行，即程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。 Java 的并发采用的是共享内存模型。 JMMJava 内存模型，即 Java Memory Model。 Java 内存模型是一个抽象概念，其主要目的是定义程序中各种共享变量的访问规则， 即关注在虚拟机中把共享变量值存储到内存和从内存中取出变量值这样的底层细节。这里的共享变量指实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数（即位于虚拟机栈的数据），因为后者是线程私有的，不会被共享，自然就不会存在竞争问题。 为了获得更好的执行效能， Java 内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器是否要进行调整代码执行顺序这类优化措施。 Java 内存模型规定了所有的共享变量都存储在主内存中。每个线程还有自己的工作内存，线程的工作内存中保存了被该线程使用过的共享变量的主内存副本，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。 所以如果线程 A 与线程 B 之间要通信的话，必须经历下面 2 个步骤： 线程 A 将本地内存中更新过的共享变量刷新到主内存中去。 线程 B 到主内存中去读取线程 A 之前已经更新过的共享变量。 线程、主内存、工作内存三者的交互关系如图所示：（图片仿制自《深入理解JVM》） 上述的主内存、工作内存都是抽象概念，并不真实存在，可以把它们跟一些区域作对应： 主内存可以对应 JVM 内存区域中堆的对象实例数据部分以及方法区的静态变量。在更底层，可以类比物理硬件的主内存，但物理上它仅是虚拟机内存的一部分。 工作内存则对应虚拟机栈的部分区域，在更底层，可与 CPU 的高速缓存（L1/L2 Cache）、寄存器对应。 内存间交互….（《深入理解JVM P442》） JMM 的特征….（《深入理解JVM P450》） 原子性 可见性 有序性 伪共享问题CPU与主内存之间会添加一级或多级高速缓冲存储器，即Cache。 在Cache内部是按行存储的， 其中每一行称为一个Cache行。Cache行是Cache与主内存进行数据交换的单位，Cache行的大小一般为2的幂次数字节。当CPU访问某个变量时， 首先会去看CPU Cache内是否有该变量， 如果有则直接从中获取，否则就去主内存里面获取该变量， 然后把该变量所在内存区域的一个Cache行大小的内存块（局部性原理）复制到Cache中。 由于存放到Cache行的是内存块而不是单个变量， 所以可能会把多个变量存放到一个Cache行中。当多个线程同时修改一个缓存行里面的多个变量时，由于同时只能有一个线程操作缓存行，所以相比将每个变量放到一个缓存行，性能会有所下降，这就是伪共享。 比如CPU1、CPU2读取了同一个缓存行，若CPU1对其中的一个变量修改，在缓存一致性协议下，CPU2中对应的缓存行就会失效，即破坏了CPU2的一级缓存，CPU2需要到二级缓存查找（甚至到主存），造成性能下降。 比如有4个变量： 1234long a;long b;long c;long d; 假设缓存行大小32字节，一个long类型8个字节，当CPU访问a时，会把a及附近的b、c、d一起放入缓存行。 也就是地址连续的多个变量才有可能会被放到一个缓存行中。比如创建数组时，数组里面的多个元素就会被放入同一个缓存行。 在正常情况下单线程访问时将数组元素放入一个或者多个缓存行对代码执行是有利的，因为数据都在缓存中，代码执行会更快。 测试缓存行demo见test/TestCacheLine。 JDK8之前使用声明多个填充变量的方法来避免伪共享问题，让一个缓存行只有一个有用变量： 该例中，若缓存行大小是64B，则value+p1-6是56B，对象头是8B，所以共64B。 1234public class FilledLong&#123; volatile long value = 0L; long p1,p2,p3,p4,p5,p6&#125; JDK8提供了一个注解@sun.misc.Contended解决伪共享问题，它可以自行执行填充。上面代码可以改为： 1234@sun.misc.Contendedpublic class FilledLong&#123; volatile long value = 0L;&#125; 需要注意的是， 在默认情况下， @Contended注解只用于Java核心类， 比如rt包下的类。如果用户类路径下的类需要使用这个注解， 则需要添加JVM参数：-XX:-RestrictContended。填充的宽度默认为128，要自定义宽度则可以设置 -XX:ContendedPaddingWidth参数。 内存可见性问题 Java 中共享变量存在内存可见性问题。 先看看多线程下处理共享变量时 Java 的内存模型：（来自《Java并发编程之美》） Java 内存模型规定，将所有的变量都存放在主内存中，当线程使用变量时，会把主内存里面的变量复制到自己的工作空间或者叫作工作内存，线程读写变量时操作的是自己工作内存中的变量。 Java 内存模型是一个抽象的概念， 在实际实现中线程的工作内存如下图： 以该 CPU 架构，一个 A、B 线程共享变量产生的内存不可见问题示例： 假设线程 A 和线程 B 使用不同 CPU 执行， 并且当前两级 Cache 都为空。 线程 A 首先获取共享变量 X 的值， 由于两级 Cache 都没有命中， 所以加载主内存中 X 的值，假如为 0。然后把 X=0 的值缓存到两级缓存，线程 A 修改 X 的值为 1，然后将其写入两级 Cache， 并且刷新到主内存。线程 A 操作完毕后， 线程 A 所在的CPU 的两级 Cache 内和主内存里面的 X 的值都是 1 。 线程 B 获取 X 的值，一级缓存没有命中，二级缓存命中，所以返回 X=1；这时候主内存中也是 X=1。然后线程 B 修改 X 的值为 2， 并将其存放到线程 2 所在的一级 Cache 和共享二级 Cache 中，最后更新主内存中X的值为 2；到这里一切都是好的。 随后线程 A 这次又需要修改 X 的值，获取时一级缓存命中，并且 X=1，到这里问题就出现了，明明线程B已经把X的值修改为了2，线程 A 获取的还是1。这就是共享变量的内存不可见问题，也就是线程 B 写入的值对线程 A 不可见。 总结下大概就是：A 改了 X，随后 B 改了 X，而 B 改 X 时不能刷新 X 在 A 线程中 Cache 的值，当 A 再次读取 X 在它的 L1 Cache 中命中，不能读取到新的值。即一个线程不能立刻感知到另一个线程对某变量的修改，导致读取了错误的数据。 另一种简洁的描述： 主内存中存在一个变量 X=1 ，线程 A、B 的工作内存都保存有 X 的副本，某时刻 A 改变了 X 的值为 X=2，并将其写入主内存，随后 B 要使用这个值，因为工作内存保留有 X 的副本，所以会直接使用工作内存中 X 的值（命中缓存），这时 X 的值还是 1 。即 B 感知不到 A 对变量 X 的修改，读取了错误的数据。 使用 synchronized 和 volatile 都可以避免这种问题。 一个 Java 代码示例： 1234567891011121314public class TestVisibility &#123; static boolean run = true; public static void main(String[] args) throws InterruptedException &#123; Thread t = new Thread(() -&gt; &#123; while (run) &#123; // .... &#125; &#125;); t.start(); sleep(1); System.out.println(&quot;在main线程中将run置为false&quot;); run = false; // 线程t不会如预想的停下来 &#125;&#125; 1s 后将 run 置 false ，线程t并没有停止。 其原因分析： 初始状态， t 线程刚开始从主内存读取了 run 的值到工作内存。 因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值缓存至自己工作内存中的高速缓存中， 减少对主存中 run 的访问，提高效率。 1 秒之后，main 线程修改了 run 的值，并同步至主存，而 t 依旧是从自己工作内存中的高速缓存中读取这个变量 的值，结果永远是旧值。 一种解决方法是为 run 加上volatile修饰符，加上该修饰符的变量在读写时都是从主存读写。volatile 能保证可见性但不能保证原子性。 Java 指令重排序Java 内存模型允许编译器和处理器对指令重排序以提高运行性能， 并且只会对不存在数据依赖性的指令重排序。在单线程下重排序可以保证最终执行的结果与程序顺序执行的结果一致，但是在多线程下就会存在问题。 示例： 123456789101112131415161718int num = 0;boolean ready = false; // 线程1 执行此方法public void actor1() &#123; while(true)&#123; if(ready) &#123; System.out.println(num + num); &#125; &#125;&#125;// 线程2 执行此方法public void actor2() &#123; num = 2; //--1-- ready = true; //--2--&#125; 启动线程 1 ，再启动线程 2 ，**当线程 2 执行了 actor2() 时，线程 1 不一定输出打印 4，而有可能是 0 **。这是因为 1、2处代码 不一定是按顺序执行，可能是先执行 ready = true; ，这时线程 1 判断 ready 为 true ，执行 System.out.println(num + num); ，而这时 num=2; 还未执行，num 的值还是 0 ，所以输出打印 0 。 使用 volatile 修饰 ready 变量可以解决该问题。 volatile关键字概述volatile 提供一种比锁更轻量级的线程间的通信机制。 volatile 可以避免内存可见性问题和指令重排序问题： volatile 可以确保对一个变量的更新对其他线程马上可见。当一个变量被声明为 volatile 时，线程在修改一个变量后，会同时把工作内存中的值同步回主内存；读取该变量时，会先从主内存把最新值加载到工作内存再进行读取，而不是直接使用当前线程的工作内存中的值。 volatile 会严格限制编译器和处理器对 volatile 变量与普通变量的重排序（JSR-133）。限制处理器的指令重排序是通过内存屏障来实现的。 硬件层面，内存屏障分两种：读屏障（Load Barrier）和写屏障（Store Barrier）。内存屏障有两个作用： 阻止屏障两侧的指令重排序； 强制把写缓冲区/高速缓存中的脏数据等写回主内存，或者让缓存中相应的数据失效。 volatile 的内存语义和 synchronized 有相似之处， 具体来说就是： 当线程写入了 volatile 变量值时就等价于线程退出 synchronized 同步块（把写入工作内存的变量值同步到主内存） 读取 volatile 变量值时就相当于进入同步块（先清空本地内存变量值，再从主内存获取最新值） 原理tobe….. double-checked locking 问题原始的单例模式存在线程安全问题，可以加上 synchronized ： 12345678910111213public final class Singleton &#123; private Singleton() &#123; &#125; private static Singleton INSTANCE = null; public static Singleton getInstance() &#123; // 首次访问会同步，而之后的使用不用进入synchronized synchronized(Singleton.class) &#123; if (INSTANCE == null) &#123; // t1 INSTANCE = new Singleton(); &#125; &#125; return INSTANCE; &#125;&#125; 但是上面的代码块的效率是有问题的，因为即使已经产生了单实例之后，之后调用了getInstance()方法之后还是会加锁，这会严重影响性能。 因此就有了double-checked locking： 123456789101112131415public final class Singleton &#123; private Singleton() &#123; &#125; private static Singleton INSTANCE = null; public static Singleton getInstance() &#123; if(INSTANCE == null) &#123; // t2 // 首次访问会同步，而之后的使用没有 synchronized synchronized(Singleton.class) &#123; if (INSTANCE == null) &#123; // t1 INSTANCE = new Singleton(); &#125; &#125; &#125; return INSTANCE; &#125;&#125; 但该代码在多线程环境下是有问题的。 在同步块内的 INSTANCE = new Singleton(); 语句对应的字节码是： 1234567810: monitorenter...17: new #3 // class .../Singleton20: dup21: invokespecial #4 // Method &quot;&lt;init&gt;&quot;:()V24: putstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;...28: monitorexit 其中的21、24指令不一定会按顺序执行，可能会先执行24，再执行21，执行24时，INSTANCE已不为null，所以其他线程调用getInstance()可以获取到INSTANCE，但此时INSTANCE的构造方法还未执行完毕，如果在构造方法中要执行很多初始化操作，那么拿到的是将是一个未初始化完毕的单例。 对 INSTANCE 使用 volatile 修饰即可，可以禁用指令重排。 volatile 屏蔽指令重排序的语义在 JDK 5 才被修复，也就是 JDK 5 之前 DCL 无法安全地使用。 先行发生规则先行发生规则即 happens-before 规则。 若两个操作满足先行发生原则，则可以有较好的可见性、顺序性和线程安全性（不能百分比保证）。它是判断操作间是否具备顺序性，线程是否安全的非常有用的手段。依赖这个原则，可以通过几条简单规则一揽子解决并发环境下两个操作之间是否可能存在冲突的所有问题，而不需要陷人 Java 内存模型苦涩难懂的定义之中。 定义： “先行发生”原则指的是两个操作之间的偏序关系，具体是：若操作 A 先行发生于操作 B，则在发生操作 B 之前，操作 A 产生的影响能被操作Ｂ观察到，“影响”包括修改共享变量的值、发送了消息、调用了方法等。（注意，操作 A、B 可以属于同一个线程也可以是不同线程） 下面是 Java 内存模型下一些“天然的”先行发生关系：（来自《深入理解JVM》） 程序次序规则（Program Order Rule） ：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 管程锁定规则（Monitor Lock Rule） ：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须强调的是“同一个锁”， “后面”是指时间上的先后。 volatile 变量规则（Volatile Variable Rule） ：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后。 线程启动规则（Thread Start Rule） ：Thread 对象的 start() 方法先行发生于此线程的每一个动作。 线程终止规则（Thread Termination Rule） ：线程中的所有操作都先行发生于对此线程的终止检测。 线程中断规则（Thread Interruption Rule） ：对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 对象终结规则（Finalizer Rule） ：一个对象的初始化完成（构造函数执行结束） 先行发生于它的 finalize() 方法的开始。 传递性（Transitivity） ：如果操作 A 先行发生于操作 B， 操作 B 先行发生于操作 C，那就可以得出操作 A 先行发生于操作 C 的结论。 这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用，Java 语言无须任何同步手段保障就能成立的先行发生规则有且只有这些。如果两个操作之间的关系不在此列，并且无法从这些规则推导出来，则它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。 另外，两个操作之间存在 happens-before 关系，并不意味着 JVM 必须要按照 happens-before 关系指定的顺序来执行。如果重排序之后的执行结果，与按 happens-before 关系来执行的结果一致，那么 JMM 也允许这样的重排序。 时间先后顺序与先行发生原则之间没有必然因果关系，衡量并发安全问题必须以先行发生原则为准，而不是以时间先后。 一个帮助理解的示例：（来自《深入理解JVM》） 线程 A 先执行 setValue(1) ，线程 B 后执行 getValue() 。 123456789private int value = 0;public void setValue(int value)&#123; this.value = value;&#125;public int getValue()&#123; return value;&#125; 依次分析先行发生原则中的各项规则。 由于两个方法分别由线程 A 和 B 调用，不在一个线程中，所以程序次序规则在这里不适用； 由于没有同步块，自然就不会发生 lock 和 unlock 操作， 所以管程锁定规则不适用； 由于 value 变量没有被 volatile 关键字修饰， 所以 volatile 变量规则不适用； 后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。 因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，因此可以判定，尽管线程 A 在操作时间上先于线程 B，但是无法确定线程 B 中 getValue() 方法的返回结果， 换句话说， 这里面的操作不是线程安全的，不能保证它们的执行顺序。 CAS原理CAS 的全称是：比较并交换（Compare And Swap）。在 CAS 中，有这样三个值： V：要更新的变量(var) E：预期值(expected) N：新值(new) 比较并交换的过程如下： 先获取预期值（也就是旧值），然后判断 V 的值是否等于 E，如果等于，则认为在此期间 V 没有被修改过，将 V 的值设置为 N；如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新，什么都不做。即若是要修改的变量的值为预期值，将其修改为新值，否则什么都不做。 这里的预期值 E 本质上指的是“旧值”。 CAS 是一种原子操作，在底层使用了一种系统原语，是一条 CPU 的原子指令，是从 CPU 层面保证其原子性的，所以当判断了变量的值为旧值要进行修改时，不会出现被其他线程抢先修改的情况。 当多个线程同时使用CAS操作一个变量时，只有一个可以成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，且一般会通过自旋不断尝试直到成功 。 优缺点CAS 操作是乐观锁的具体实现，可以实现无锁并发，操作失败时线程并不会被挂起，且一般会结合自旋（如while 循环） 不断尝试直到成功，自旋期间会占用 CPU，所以若是自旋时间过长，会浪费大量的 CPU 资源。所以 CAS 操作适用于“读多写少”的情况。 另外，CAS 只能保证一个共享变量的原子操作。 ABA 问题ABA 问题即：当前线程获取了某个变量的值为 A（expect值），在进行 CAS 操作之前，其他线程把该变量的值修改为 B，又修改为 A，这时当前线程在进行 CAS 操作时获取到的变量值为 A，会认为变量没有被修改过，但其实已被修改了 2 次。 ABA 问题的解决思路是为变量加上版本号或者时间戳。JDK 1.5 的 AtomicStampedReference 类和 AtomicMarkableReference 类可以解决 ABA 问题。 ThreadLocal概述通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。而通过 ThreadLocal ，可以实现针对某一个变量，每个线程访问的都是该变量在当前线程的副本。 ThreadLocal 类主要解决的就是让每个线程绑定自己的值，即创建一个变量，每一个线程访问该变量获取的都是该变量在该线程的副本。 如果创建了一个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是 ThreadLocal 变量名的由来。他们可以使用 get() 和 set() 方法来获取值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 示例 sleep(int i)表示睡眠i s 12345678910111213141516171819202122232425262728293031@Slf4j(topic = &quot;c.Test1&quot;)public class Test1 &#123; static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) &#123; Thread t1 = new Thread(()-&gt;&#123; String str = &quot;str from t1&quot;; threadLocal.set(str); log.debug(&quot;set str: &#123;&#125;&quot;, str); sleep(3); // 获取的是自己放置的str，获取不到t2放置的 String str1 = threadLocal.get(); log.debug(&quot;get str after 2s: &#123;&#125;&quot;, str1); &#125;, &quot;t1&quot;); Thread t2 = new Thread(()-&gt;&#123; sleep(1); // 获取的str为null，不能获取到t1放置的str String str = threadLocal.get(); log.debug(&quot;get str: &#123;&#125;&quot;, str); String str1 = &quot;str from t2&quot;; threadLocal.set(str1); log.debug(&quot;set str: &#123;&#125;&quot;, str1); &#125;, &quot;t2&quot;); t1.start(); t2.start(); &#125;&#125; 原理概述Thread 类包含一个 ThreadLocal.ThreadLocalMap 成员变量，其实质是一个 Map，映射关系是 ThreadLocal-Object，存放多个 ThreadLocal 的本地副本（一个 ThreadLocal 在多个线程中都有一个副本，对应的，一个线程可以拥有多个 ThreadLocal 的本地副本）。 从Thread类源码开始： 123456789public class Thread implements Runnable &#123; ......//与此线程有关的ThreadLocal值。由ThreadLocal类维护ThreadLocal.ThreadLocalMap threadLocals = null;//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ......&#125; 即 Thread 类中有一个 threadLocals 和一个 inheritableThreadLocals， 它们都是 ThreadLocalMap 类型（ThreadLocalMap 是 ThreadLocal 的静态内部类）的变量， 而 ThreadLocalMap 是一个定制化的 map，存放多个ThreadLocal 变量在当前线程的副本，ThreadLocalMap 存储以 ThreadLocal 为 key ，Object 对象为 value 的键值对。 在默认情况下， 每个线程中的这两个变量都为 null， 只有当前线程第一次调用 ThreadLocal 的 set() 或者 get() 方法时才会创建它们。 从上面可以看出，每个线程的本地变量不是存放在 ThreadLocal 实例里面，而是存放在对应线程的 threadLocals 变量里面。ThreadLocal 就是一个工具壳， 通过它来从当前线程的 threadLocals 中获取值或放入值。 如果线程一直不终止， 那么这个本地变量会一直存放在调用线程的 threadLocals 变量里面， 所以当不需要使用本地变量时可以通过调用 ThreadLocal 变量的 remove() 方法， 从当前线程的 threadLocas 里面删除该本地变量，避免内存泄漏。 set()、get()源码分析 基于 JDK8 set()： 12345678910111213141516171819public void set(T value) &#123; // 获取线程的threadLocalMap Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // threadLocalMap不为null，修改值 if (map != null) map.set(this, value); // 第一次调用则创建当前线程对应的threadLocalMap，并将value放进去 else createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; get()： 12345678910111213141516171819202122232425262728293031323334353637public T get() &#123; // 获取线程的threadLocalMap Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // 不为null则从中尝试获取值 if (map != null) &#123; // 将当前ThreadLocal对象为key，从线程的threadLocalMap中尝试获取值 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; // map为null或其中没有当前ThreadLocal对应的值 return setInitialValue();&#125;// 初始化（若未初始化）线程的 threadLocalMap ，并将 当前ThreadLocal-null 放入 mapprivate T setInitialValue() &#123; T value = initialValue();//该方法只是返回一个null Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // map不为null（表示其中没有当前ThreadLocal对应的值） // 放置一个 当前ThreadLocal对象-null 的键值对 if (map != null) map.set(this, value); // 否则创建一个ThreadLocalMap // 并同样放置一个 当前ThreadLocal对象-null 的键值对 else createMap(t, value); return value;&#125;protected T initialValue() &#123; return null;&#125; 可以看到set()、get()方法都是先从当前线程中获取ThreadLocalMap对象。 Thread、ThreadLoacal、ThreadLoacalMap 的关系图解：（图片来自 JavaGuide ） 内存泄露问题 内存泄漏（Memory Leak）是指程序中已动态分配的堆内存由于某种原因程序未释放或无法释放但又无法使用，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。 ThreadLocalMap 中的 key 是 ThreadLocal 的弱引用（继承了 WeakReference ），而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。 如图，假设 ThreadLocal 失去强引用，则只剩下 Entry 中 key 的弱引用，下一次 gc 时就会被回收，而 value 不会被清理。 （图片来自 ThreadLocal的内存泄露的原因分析 ） ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的 Entry。使用完 ThreadLocal 变量后最好手动调用remove()方法。 （清除的具体方法是 ThreadLocal.ThreadLocalMap#expungeStaleEntry ） ThreadLocalMap 的静态内部类 Entry ： 注意只有 key ，即 ThreadLocal 是弱引用，value 是强引用。 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 为什么使用弱引用？ 若使用强引用，则上图中的虚线改为实线，当外部的 Threadlocal 对象的强引用失去时，因为有 key 作为强引用，所以 ThreadLocal 对象不会被回收，而在外部又没有这个 ThreadLocal 对象的强引用，所以访问不了该 Entry ，即造成了 Entry 的内存泄漏。 InheritableThreadLocal(to be …) 副本指向同一个对象另外要注意的一个点是，一个 ThreadLocal 变量在各个线程的副本可以指向同一个对象： 定义 Stu 类： 12345class Stu&#123; String name; Integer age; // ...&#125; 测试：（线程 t1、t2 中的 ThreadLocal 变量指向的是同一个对象） 12345678910111213141516171819202122232425262728static ThreadLocal&lt;Stu&gt; threadLocal = new ThreadLocal&lt;&gt;();public static void main(String[] args) &#123; Stu stu = new Stu(&quot;zhangsan&quot;, 20); Thread t1 = new Thread(()-&gt;&#123; threadLocal.set(stu); try &#123; sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Stu stuCopy = threadLocal.get(); System.out.println(stuCopy); &#125;, &quot;t1&quot;); Thread t2 = new Thread(()-&gt;&#123; threadLocal.set(stu); Stu stu1 = threadLocal.get(); stu1.setName(&quot;lisi&quot;); &#125;, &quot;t2&quot;); t1.start(); t2.start();&#125;// 输出：// Stu&#123;name=&#x27;lisi&#x27;, age=20&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"Java并发","slug":"Java并发","permalink":"http://example.com/Tag/Java%E5%B9%B6%E5%8F%91/"}]},{"title":"synchronized 优化","slug":"Java/多线程/synchronized 优化","date":"2021-04-08T06:15:43.048Z","updated":"2021-04-17T06:23:04.985Z","comments":true,"path":"2021/04/08/Java/多线程/synchronized 优化/","link":"","permalink":"http://example.com/2021/04/08/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/synchronized%20%E4%BC%98%E5%8C%96/","excerpt":"","text":"对象头的Mark WordHotSpot 虚拟机对象的对象头包含两部分。 第一部分是用于存储对象自身的运行时数据， 如哈希码(HashCode) 、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32个比特和64个比特， 官方称它为“Mark Word”； 第二部分是类型指针，指向当前对象所属类的元数据。 如果是数组对象的话, 对象头还有一部分是存储数组的长度。 对象需要存储的运行时数据很多，考虑到虚拟机的空间效率， Mark Word被设计成一个有着动态定义的数据结构，以便根据对象的状态复用自己的存储空间。 不同状态的数据结构如下： 32位JVM的Mark Word不同状态下的结构： 64位： 当对象状态为偏向锁时，Mark Word 存储的是偏向的线程 ID ； 当状态为轻量级锁时，Mark Word 存储的是指向线程栈中 Lock Record 的指针； 当状态为重量级锁时，Mark Word 为指向堆中的 monitor 对象的指针。 锁优化概述Java 早期版本中，synchronized 属于 重量级锁，效率低下。Java的线程是映射到操作系统原生线程之上的，如果要阻塞或唤醒一个线程就需要操作系统的帮忙，这就要从用户态转换到核心态，因此状态转换需要花费很多的处理器时间，对于代码简单的同步块（如被synchronized 修饰的get 或set 方法）状态转换消耗的时间有可能比用户代码执行的时间还要长，所以说synchronized 是 java 语言中一个重量级的操纵。 Java 6 为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁“。在Java 6 以前，所有的锁都是”重量级“锁。在 Java 6 及其以后，一个对象其实有四种锁状态，它们级别由低到高依次是： 无锁状态。无锁就是没有对资源进行锁定，任何线程都可以尝试去修改它。 偏向锁状态 轻量级锁状态 重量级锁状态 一些文章说是锁可以升级, 但不能降级。在 synchronized与锁 中的观点是锁可以降级（Hotspot 支持锁降级）。 几种锁会随着竞争情况逐渐升级。 以下被 synchronized 上锁的对象称为 lockObj ，其关联的 monitor 对象则直接称为 monitor 偏向锁大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，于是引入了偏向锁，偏向锁适合一个线程的情况。 总的来说，偏向锁会偏向第一个访问锁的线程，当线程访问同步代码时，若发现 lockObj 的 Mark Word 中的线程 ID 是自己的，则直接执行同步代码，也就是说，偏向锁在资源无竞争情况下消除了同步语句，省略了 CAS 操作，只是执行一个简单的判断就可以执行同步代码，提高了程序的运行性能。 实现原理当线程第一次访问一个同步代码块时，会尝试将自己的线程 ID 设置在 lockObj 的 Mark Word 中和栈帧中的锁记录里，当再次访问该同步块时，会检测 lockObj 的 Mark Word 中放的是不是自己的线程 ID 。 如果是，则表示获取到了锁，直接进入同步代码块，无需进行其他操作。 如果不是，会撤销偏向锁，升级为轻量级锁。 而根据参考链接，以及网上大部分博客，都是写的这个时候会尝试使用 CAS 来替换 Mark Word 里面的线程 ID 为新线程的 ID，分两种情况： CAS 操作成功，表示另一个线程已经执行完并退出同步块。锁不会升级，仍然为偏向锁，只不过偏向了新的线程。 CAS 操作失败，表示之前的线程仍然存在，暂停之前的线程，设置偏向锁标识为0，并设置锁标志位为00，升级为轻量级锁，随后两个线程按照轻量级锁的方式进行竞争。 而通过实际例子进行验证，应该是第一种情况，即若是线程 id 不是当前线程的，升级为轻量级锁。 验证示例： 1234567891011121314151617181920212223public static void test4() &#123; Dog dog = new Dog(); new Thread(() -&gt; &#123; log.debug(ClassLayout.parseInstance(dog).toPrintable()); synchronized (dog) &#123; log.debug(ClassLayout.parseInstance(dog).toPrintable()); &#125; log.debug(ClassLayout.parseInstance(dog).toPrintable()); &#125;, &quot;t1&quot;).start(); new Thread(() -&gt; &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.debug(ClassLayout.parseInstance(dog).toPrintable()); synchronized (dog) &#123; log.debug(ClassLayout.parseInstance(dog).toPrintable()); &#125; log.debug(ClassLayout.parseInstance(dog).toPrintable()); &#125;, &quot;t2&quot;).start();&#125; 输出：(只保留部分对象头） 12345678910111213141516171819202113:28:36.480 c.TestBiased [t1] - lock.Dog object internals:// 00000101 表示为偏向锁05 00 00 00 (00000101 00000000 00000000 00000000)13:28:36.483 c.TestBiased [t1] - lock.Dog object internals:05 88 7d 1b (00000101 10001000 01111101 00011011)13:28:36.483 c.TestBiased [t2] - lock.Dog object internals:05 88 7d 1b (00000101 10001000 01111101 00011011)Space losses: 0 bytes internal + 4 bytes external = 4 bytes total13:28:36.493 c.TestBiased [t1] - lock.Dog object internals:05 88 7d 1b (00000101 10001000 01111101 00011011)// t2发现dog的对象头保留了其他线程的id，撤销偏向锁，升级为轻量级锁13:28:36.494 c.TestBiased [t2] - lock.Dog object internals:60 ef ec 1b (01100000 11101111 11101100 00011011)// 释放轻量级锁，变为无锁状态13:28:36.494 c.TestBiased [t2] - lock.Dog object internals:01 00 00 00 (00000001 00000000 00000000 00000000) 撤销偏向锁偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。 偏向锁升级为轻量级锁所需的开销是比较大的，大概的过程如下： 在一个安全点（在这个时间点上没有字节码正在执行）停止拥有锁的线程。 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Mark Word，使其变成无锁状态。 唤醒被停止的线程，将当前锁升级成轻量级锁。 所以，如果应用程序里所有的锁通常处于竞争状态，那么偏向锁就会是一种累赘 ，这时可以设置 JVM 参数关闭偏向锁：-XX:UseBiasedLocking=false 。 另外要注意的是：若是调用了 Object 类的 wait()/notify() 方法，会直接升级为重量级锁。 偏向锁的延迟特性jdk6默认开启偏向锁，但默认情况下是延时开启的，也就是说，程序刚启动创建的对象是不会开启偏向锁的，几秒后后创建的对象才会开启偏向锁的。 验证示例：（使用 jol 工具包打印对象头，使用 logback 打印日志信息，基于 jdk8，64 位 JVM，注意打印的字节是小端序） 创建一个Dog类： 1class Dog &#123;&#125; test1： 12345678public static void test1() &#123; Dog dog = new Dog(); log.debug(ClassLayout.parseInstance(dog).toPrintable()); synchronized (dog)&#123; log.debug(ClassLayout.parseInstance(dog).toPrintable()); &#125; log.debug(ClassLayout.parseInstance(dog).toPrintable());&#125; 输出： 对象刚创建时是normal状态（001） 由于对象是程序刚启动时就创建，所以进入临界区时是轻量级锁状态（LightWeight locked，00），不是偏向锁状态。 解锁后回复到normal状态。 test2： 1234567891011121314public static void test2() &#123; Dog dog = new Dog(); log.debug(ClassLayout.parseInstance(dog).toPrintable()); try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (dog)&#123; log.debug(ClassLayout.parseInstance(dog).toPrintable()); &#125; log.debug(ClassLayout.parseInstance(dog).toPrintable());&#125; 对象是刚启动时创建的，即使延迟5s后进入synchronized也是使用轻量级锁。输出结果与1同。 test3： 1234567891011121314public static void test3()&#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Dog dog = new Dog(); log.debug(ClassLayout.parseInstance(dog).toPrintable()); synchronized (dog)&#123; log.debug(ClassLayout.parseInstance(dog).toPrintable()); &#125; log.debug(ClassLayout.parseInstance(dog).toPrintable());&#125; 输出： 延迟5s后再创建dog对象，其初始时是Biased状态（101），只是没有记录线程id等信息。 进入synchronized后，记录线程id等信息。 退出synchronized后mark word仍不变。 批量重偏向如果对象虽然被多个线程访问，但没有竞争，这时偏向了线程 T1 的对象仍有机会重新偏向 T2，重偏向会重置对象 的 Thread ID当撤销偏向锁阈值到达 20 次（默认次数）时（即第20次开始），jvm会在给之后的对象加锁时重新使用偏向锁，而不是使用轻量级锁。 示例见 lock.TestBiased#test6 在t2的前19次（0-18），给对象加锁时都将偏向锁改为轻量级锁（即其他线程访问撤销偏向锁的情况），在第20次（19）及其之后的加锁中进行了重偏向（注意是加锁一个重偏向一个），将Mark Word的线程id改为t2线程。 重偏向的阈值是20次，而当到达40次时（即重偏向操作进行了20次），当前类的所有对象都会变为不可偏向。 demo见lock.TestBiased.test7。 在t2的19-38进行了重偏向，在t3的第1次（0）已不可偏向，又使用了轻量级锁。t3之后创建的dog对象不可偏向，而cat对象可以。 上述的撤销偏向锁，重偏向、批量撤销偏向锁都是只针对一个类而言。 锁消除 JIT编译器会对一些synchronized块进行优化，若加锁的对象不可能被共享（比如对局部变量加锁），那么JIT会将synchronized去掉，省去不必要的开销。 轻量级锁多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM 采用轻量级锁来避免线程的阻塞与唤醒。 加锁JVM 会为每个线程在当前线程的栈帧中创建用于存储锁记录（Lock Record）的空间，称为Displaced Mark Word。（当一个线程对一个锁多次重入时，会对应有多个锁记录） 如果一个线程发现 lockObj 处于轻量级锁状态，则会先把锁（lockObj）的 Mark Word 复制到锁记录，然后尝试用 CAS 操作将 Mark Word 替换为锁记录地址，如果成功，表示获取到锁；如果失败，表示已有其他线程占有轻量级锁，当前线程用自旋尝试获取锁。 若是自旋失败，则会升级为重量级锁，这时当前线程会将 lockObj 的 Mark Word 标志位置为 10，并设置 monitor 对象的地址，然后线程进入 monitor 的 EntryList 进行阻塞，等待竞争锁。 关于自旋： 自旋是线程占用 CPU 并不断尝试获取锁，一般使用循环。若是持锁线程在自旋结束前释放了锁，那么当前线程就可以成功获取到锁，避免升级为重量级锁，减少开销。JVM 采用了适应性自旋——线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。 自旋会占用 CPU 时间，单核 CPU 自旋就是浪费（即暂停持锁线程让当前线程自旋，显然必定是自旋失败的），多核 CPU 自旋才能发挥优势。 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会 高，就多自旋几次；反之，就少自旋甚至不自旋。 Java 7 之后不能控制是否开启自旋功能（默认开启） 释放锁释放锁时，当前线程会将用 CAS 操作将锁记录中的内容换回 lockObj 的 Mark Word 中，若没有竞争，该过程会成功，这时 lockObj 变为无锁状态；若有其他线程自旋失败将锁升级为重量级锁，则操作失败，此时会释放锁并唤醒在 monitor 的 EntryList 中阻塞的线程。 一张图说明加锁和释放锁的过程：（来自参考链接） 重量级锁重量级锁也就是 monitor 锁，不再赘述。 总结锁的升级流程（来自参考链接） 每一个线程在准备获取共享资源时： 第一步，检查 MarkWord 里面是不是放的自己的 ThreadId ,如果是，表示当前线程是处于 “偏向锁” 。 第二步，如果 Mark Word 不是自己的 ThreadId ，锁升级，这时候，用 CAS 来执行切换，新的线程根据 Mark Word 里面现有的 ThreadId，通知之前线程暂停，之前线程将 Mark Word 的内容置为空。 第三步，两个线程都把锁对象的HashCode复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作， 把锁对象的MarKword的内容修改为自己新建的记录空间的地址的方式竞争MarkWord。 第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋 。 第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于 轻量级锁的状态，如果自旋失败 。 第六步，进入重量级锁的状态，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己。 各种锁的优缺点对比来自《Java并发编程的艺术》： 锁 优点 缺点 适用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。 重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量。同步块执行时间较长。 参考 synchronized与锁","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"Java并发","slug":"Java并发","permalink":"http://example.com/Tag/Java%E5%B9%B6%E5%8F%91/"}]},{"title":"Comparable和Comparator用法小结","slug":"Java/其他/Comparable和Comparator用法小结","date":"2021-03-29T03:01:14.672Z","updated":"2021-03-29T03:09:59.764Z","comments":true,"path":"2021/03/29/Java/其他/Comparable和Comparator用法小结/","link":"","permalink":"http://example.com/2021/03/29/Java/%E5%85%B6%E4%BB%96/Comparable%E5%92%8CComparator%E7%94%A8%E6%B3%95%E5%B0%8F%E7%BB%93/","excerpt":"","text":"概述Comparable 接口和 Comparator 接口都是用来比较两个对象。一个类实现 Comparable 表示该类的对象之间可以比较；Comparator 则表示一个比较器，传入两个对象，返回比较结果。 它们的代码定义： 123public interface Comparable&lt;T&gt; &#123; public int compareTo(T o);&#125; 12345@FunctionalInterfacepublic interface Comparator&lt;T&gt; &#123; int compare(T o1, T o2); // ...&#125; 数组工具类和集合工具类中提供的 sort 排序方法就要求被排序的类实现 Comparable 接口或需要传入一个 Comparator 对象。 比较规则compareTo 或 compare 都是返回一个 int 类型值。 对于 o1.compareTo(o2) 或 compare(o1, o2) ，返回不同 int 值时的意义： 返回 0 ，表示两个值相等。 返回 负数，表示 o1 会排在 o2 前面。即若是返回负数，o1、o2 位置不变。 返回 正数，表示 o1 会排在 o2 后面。即若是返回正数，o1、o2 位置交换。 根据这 3 个点，在定义比较规则时，从 “返回负数表示两个值位置不变” 这个点入手： 若是要按某个值升序排序，即返回负数的情况（o1，o2 位置不变）是 o1&lt;o2 ，则应该 return o1-o2 。这样当返回负数时，o1、o2 是升序的，位置不用变；返回正数，表示 o1 大于 o2，此时是降序的，应该交换位置。 而若是降序，返回负数的情况应是 o1&gt;o2 ，则应该 return o2-o1 。同理。 示例： 定义类： 12345678910111213141516171819class A implements Comparable&lt;A&gt;&#123; String name; Integer num; public A(String name, Integer num) &#123; this.name = name; this.num = num; &#125; // 排序时按 num 值递增进行 @Override public int compareTo(A o) &#123; // 递增（升序），对应上面所说的 return o1-o2 return this.num - o.num; &#125; @Override public String toString() &#123; return &quot;A&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 将 A 的多个对象加入 List ，用 sort 方法进行排序： 12345678910111213public static void main(String[] args) &#123; A a1 = new A(&quot;a1&quot;, 1); A a2 = new A(&quot;a2&quot;, 3); A a3 = new A(&quot;a3&quot;, 2); List&lt;A&gt; list = new ArrayList&lt;&gt;(); list.add(a1); list.add(a2); list.add(a3); System.out.println(list); Collections.sort(list); System.out.println(list);&#125; 123输出：before sort: [A&#123;name=&#x27;a1&#x27;&#125;, A&#123;name=&#x27;a2&#x27;&#125;, A&#123;name=&#x27;a3&#x27;&#125;]after sort: [A&#123;name=&#x27;a1&#x27;&#125;, A&#123;name=&#x27;a3&#x27;&#125;, A&#123;name=&#x27;a2&#x27;&#125;] 再看一个复杂一点的例子，对一个 nx2 的数组按第一个值升序排序，若第一个值相等，第二个值倒序排序： 123456789101112131415161718192021public static void main(String[] args) &#123; int[][] array = new int[][]&#123; &#123;5,4&#125;, &#123;6,4&#125;, &#123;6,7&#125;, &#123;2,3&#125; &#125;; System.out.println(&quot;before sort: &quot;); for (int[] ints : array) &#123; System.out.println(Arrays.toString(ints)); &#125; // （这里使用 Lambda 表达式， o1、o2 是一个一维数组） // 第一个值相等时，第二个值倒序排序；否则第一个值升序排序 Arrays.sort(array, (o1, o2)-&gt; o1[0] == o2[0] ? o2[1] - o1[1] : o1[0] - o2[0]); System.out.println(&quot;\\nafter sort: &quot;); for (int[] ints : array) &#123; System.out.println(Arrays.toString(ints)); &#125;&#125; 1234567891011before sort: [5, 4][6, 4][6, 7][2, 3]after sort: [2, 3][5, 4][6, 7] [6, 4]","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"其他","slug":"Java/其他","permalink":"http://example.com/categories/Java/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/Tag/Java/"}]},{"title":"HashSet和LinkedHashSet简单分析-JDK1.8","slug":"Java/集合源码/HashSet和LinkedHashSet-JDK1.8","date":"2021-03-23T08:26:37.432Z","updated":"2021-03-23T08:26:23.762Z","comments":true,"path":"2021/03/23/Java/集合源码/HashSet和LinkedHashSet-JDK1.8/","link":"","permalink":"http://example.com/2021/03/23/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/HashSet%E5%92%8CLinkedHashSet-JDK1.8/","excerpt":"","text":"HashSet概述HashSet 实质上仍是一个 HashMap ，它通过组合的方式内部封装了一个 HashMap： 1private transient HashMap&lt;E,Object&gt; map; 其所有的操作都是基于这个 HashMap。且 HashSet 只使用 HashMap 的 key，value 使用一个静态成员变量来填充： 1private static final Object PRESENT = new Object(); HashMap 拥有无序性、唯一性的特点，HashSet 自然也继承了这些特点。 构造方法HashSet 的构造方法： 12345678910111213141516171819202122public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;//-------------------------------------public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 可以看到前 3 个构造方法和 HashMap 的 3 个方法一一对应，都使用对应的 HashMap 构造方法来初始化 map。 另外，最后一个构方法多了一个 boolean 参数，它只是为了跟第 3 个构造方法区分，且初始化的是一个 LinkedHashMap 。这个构造方法是包访问级别的，它是为了给 LinkedHashSet 使用的。 add 和 remove12345678public boolean add(E e) &#123; // value 使用 PRESENT 静态变量填充 return map.put(e, PRESENT)==null;&#125;public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; 可以看到都是调用 HashMap 对应的方法。所以 HashSet 的数据操作都是对其中的 map 进行操作的。 LinkedHashSetHashSet 和 LinkedHashSet 的继承关系如下： 可以看到 LinkedHashSet 是 HashSet 的子类。 LinkedHashSet 的构造方法： 1234567891011public LinkedHashSet(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor, true);&#125;public LinkedHashSet(int initialCapacity) &#123; super(initialCapacity, .75f, true);&#125;public LinkedHashSet() &#123; super(16, .75f, true);&#125; 可以看到 LinkedHashSet 都是调用父类的最后一个构造方法来创建，即初始化了一个 LinkedHashMap。LinkedHashSet 的操作同样都是基于这个 LinkedHashMap，所以其拥有元素的唯一性，又能保持元素的顺序。 总结这两个 Set 集合实质上都一个 Map，其所有操作都是基于这个 map，所以它们的特性跟 HashMap 基本一样。 所以 HashSet 检查元素重复的过程是： 计算元素的 hash 值； 计算对应的桶索引； 将元素跟桶上的元素比较： 若 hash 值不同，则判断两个元素不同 若 hash 值相同，则继续比较， 若 == 或 equals() 比较返回 true，则认为相同； 否则认为不同。 即两个元素相同的标准是：hash 值相同，且 == 或 equals() 比较仍相同。","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"集合源码","slug":"Java/集合源码","permalink":"http://example.com/categories/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"LinkedHashMap-JDK1.8","slug":"Java/集合源码/LinkedHashMap - JDK1.8","date":"2021-03-21T09:11:45.718Z","updated":"2021-03-21T09:11:27.033Z","comments":true,"path":"2021/03/21/Java/集合源码/LinkedHashMap - JDK1.8/","link":"","permalink":"http://example.com/2021/03/21/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/LinkedHashMap%20-%20JDK1.8/","excerpt":"","text":"概述LinkedHashMap 继承自 HashMap，在 HashMap 的基础上维护了一个双向链表，解决了 HashMap 遍历顺序和插入顺序不一致的问题。除此之外，LinkedHashMap 对访问顺序也提供了相关支持。在一些场景下，该特性很有用，比如实现 LRU 缓存。 在实现上，LinkedHashMap 很多方法直接继承自 HashMap，仅为维护双向链表覆写了部分方法。 原理概述先看Entry 继承体系： Map 中 Entry 的继承关系如下： 1HashMap.TreeNode -&gt; LinkedHashMap.Entry -&gt; HashMap.Node -&gt; Map.Entry 它们对应的成员变量： 可以看到 LinkedHashMap.Entry 中的 before 和 after 变量，它们提供了双向链表的特性。同时 TreeNode 继承自 LinkedHashMap.Entry，所以它也可以作为双向链表的结点。LinkedHashMap 中使用的就是这两类结点，它在原本的链表、红黑树基础上通过 before、after 引用维护了一个双向链表，如下图（图片来自参考链接）： 关于 Entry 继承体系更多细节：Entry 继承体系 链表建立过程LinkedHashMap 中有两个引用：head、tail，指向双向链表的头和尾。 在通过 put 方法加入元素的时候就同时将新增结点链入链表尾部。但 LinkedHashMap 并没有覆盖 HashMap 的 put 方法，使用的都是父类的 put 。其维护双向链表的关键方法在于插入结点时调用的 newNode() 方法。 如下（标 ★★ 处）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// HashMap 中的 put 方法public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;// HashMap 中的 putVal 方法final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null);// ★★ else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null);// ★★ if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; LinkedHashMap 覆盖了父类的 newNode() 方法，它们的区别如下： 12345678910111213141516171819202122232425262728// HashMapNode&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; // 创建的是 Node 类型结点 return new Node&lt;&gt;(hash, key, value, next);&#125;// LinkedHashMapNode&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; // 创建的是 LinkedHashMap.Entry 类型结点 LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); // 将 p 链入双向链表尾部 linkNodeLast(p); return p;&#125;// LinkedHashMap// 将 p 链入双向链表尾部private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125;&#125; 所以关键点是 LinkedHashMap 覆盖了父类的 newNode() 方法，在创建结点时使用的是这个覆盖方法，在该方法中创建的是 LinkedHashMap.Entry 类型的结点，并将其链入双向链表尾部。 通过维护双向链表，在遍历时只要顺着链表遍历就可以保证遍历顺序跟插入顺序一致。 另外，在 put 方法的最后还有一个 afterNodeInsertion(evict); 方法，在 JDK 1.8 HashMap 的源码中，相关的方法有3个： 1234// Callbacks to allow LinkedHashMap post-actionsvoid afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; 这些方法的用途是在增删查等操作后，通过回调的方式，让 LinkedHashMap 有机会做一些后置操作。上述三个方法的具体实现在 LinkedHashMap 中。即 LinkedHashMap 覆盖了这 3 个回调方法。 删除与插入操作一样，LinkedHashMap 的删除操作也是直接使用父类的实现。在删除节点时，父类的删除逻辑并不会修复 LinkedHashMap 所维护的双向链表，这不是它的职责。LinkedHashMap 删除结点后维护链表的操作是通过上述的回调方法实现的。 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// HashMap 中实现public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;// HashMap 中实现final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node);// ----删除结点后调用回调方法---- return node; &#125; &#125; return null;&#125;// LinkedHashMap 中覆盖// 将指定结点从链表中断开void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink // 结点向下转型为 LinkedHashMap.Entry LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b;&#125; 维护访问顺序上文讲的是 LinkedHashMap 如何维护插入顺序，而除了插入顺序， LinkedHashMap 还可以维护访问顺序， LinkedHashMap 有一个成员变量： 1final boolean accessOrder; 该变量为 true 时表示启用访问顺序维护。该值默认为 false ，可通过该构造方法指定为 true： 123456public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; 所谓维护访问顺序就是：当调用get/getOrDefault/replace等访问了结点的方法时，将这些方法访问的结点移动到链表的尾部。 代码：（注意 LinkedHashMap 重写了两个 get 方法） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// LinkedHashMap 中覆写public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; // 若 accessOrder 为 true，调用 afterNodeAccess if (accessOrder) afterNodeAccess(e); return e.value;&#125;// LinkedHashMap 中覆写public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return defaultValue; if (accessOrder) afterNodeAccess(e); return e.value;&#125;void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; // 若 accessOrder 为 true 且当前结点不是尾结点 if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; // 讲 p 从原位置移除 if (b == null) head = a; else b.after = a; if (a != null) a.before = b; else last = b; // 讲 p 链入尾部 if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125; 实现缓存LinkedHashMap 的最后一个回调方法： 12345678void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; // 根据条件判断是否移除最近最少被访问的节点（头结点） if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125; 其中，removeEldestEntry 方法是一个空实现： 123protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 可以通过继承 LinkedHashMap ，并重写该方法、自实现判断逻辑来实现 LRU 缓存。比如根据结点数量或结点存货时间来判断是否要移除。 参考 LinkedHashMap 源码详细分析（JDK1.8） - 田小波","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"集合源码","slug":"Java/集合源码","permalink":"http://example.com/categories/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"HashMap-JDK1.7","slug":"Java/集合源码/HashMap - JDK1.7","date":"2021-03-21T02:39:00.462Z","updated":"2021-03-21T02:38:42.292Z","comments":true,"path":"2021/03/21/Java/集合源码/HashMap - JDK1.7/","link":"","permalink":"http://example.com/2021/03/21/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/HashMap%20-%20JDK1.7/","excerpt":"","text":"底层存储结构内部包含了一个 Entry 类型的数组 table。Entry 存储着键值对。且每个 Entry 是一个链表。即数组中的每个位置被当成一个桶，一个桶存放一个链表。JDK1.7 的 HashMap 使用拉链法来解决冲突，同一个链表中存放 哈希值和数组取模运算 结果相同（即桶索引相同）的 Entry。 123456789transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; // ...&#125; 构造方法JDK1.7 的构造方法机制与 JDK1.8 大致相同，都只是先初始化 threshold、loadFactor，存储元素的数组等到第一次插入键值时才根据 threshold、loadFactor 的值创建。 put 操作123456789101112131415161718192021222324252627282930public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 若 key 为 null，作另外处理 if (key == null) return putForNullKey(value); // 计算 hash int hash = hash(key); // 根据 hash 和 table 长度计算桶索引 int i = indexFor(hash, table.length); // 先遍历索引所在的链表 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 若 hash 相同，且key相同（== 或 equals ），则进行 value 的替换 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 否则使用头插法插入新结点 addEntry(hash, key, value, i); return null;&#125; key 为 null 时，因为无法调用其 hashCode() 计算 hash 值，所以 HashMap 把 key 为 null 的值放在 table[0] 。 12345678910111213private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null;&#125; addEntry： 123456789101112131415161718void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 扩容检查 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; // 扩容后重新计算索引 bucketIndex = indexFor(hash, table.length); &#125; // 创建新结点 createEntry(hash, key, value, bucketIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 另外要注意的是开头的判断： 123if (table == EMPTY_TABLE) &#123; inflateTable(threshold);&#125; 当 table 为空，说明其还未初始化，调用 inflateTable 方法初始化，会根据 threshold 找到一个大于它的最小的 2 的幂次方的数作为 table 的长度。 确定桶下标put() 方法中的一段代码： 12345// 计算 hashint hash = hash(key);// 根据 hash 和 table 长度计算桶索引int i = indexFor(hash, table.length);//======================================== hash 方法（扰动函数）： 123456789101112final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // 对 h 值进行 4 次扰动，减少哈希碰撞 h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; indexFor 方法： 若一个正整数 x 是 2 的 n 次方，则对于 任一整数 y，有 y % x = y &amp; (x - 1)。 所以 indexFor 方法实际上是进行了 % 运算，使用 y &amp; (x - 1) 形式的原因是对于计算机来说，位运算效率更高。 HashMap 的容量总是 2 的 n 次方，所以总是满足该关系。 1234static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1);&#125; 扩容原理在添加结点时，会先判断 size 是否到达阈值，到达则扩容，新容量指定为原来的 2 倍。 1234567891011void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 扩容逻辑在 resize 方法中： 1234567891011121314151617181920212223242526272829303132333435void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; // if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 创建新数组 Entry[] newTable = new Entry[newCapacity]; // 将原数组的元素转移到新数组 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; // 重新计算阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; // 根据新容量重新计算桶索引 int i = indexFor(e.hash, newCapacity); // 头插法插入 e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"集合源码","slug":"Java/集合源码","permalink":"http://example.com/categories/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"ArrayList-JDK1.8","slug":"Java/集合源码/ArrayList - JDK1.8","date":"2021-03-20T14:20:41.630Z","updated":"2021-03-20T14:19:59.381Z","comments":true,"path":"2021/03/20/Java/集合源码/ArrayList - JDK1.8/","link":"","permalink":"http://example.com/2021/03/20/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/ArrayList%20-%20JDK1.8/","excerpt":"","text":"一些重要成员变量123456789101112131415161718public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; // 实现了 RandomAccess ，表示具有随机访问的特性 implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; // 默认长度 private static final int DEFAULT_CAPACITY = 10; // 存储数据的数组 transient Object[] elementData; // 数组最大长度 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; // 指定容量为 0 时 elementData 的初始值 private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; // 使用无参构造器时 elementData 的初始值（默认大小时） private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;&#125; 构造方法12345678910111213141516171819// 指定长度的构造器public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 指定为 0 时，赋值一个空数组 this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125;&#125;// 默认构造器// 默认长度是 10，但调用构造器并不会将 elementData 初始化为长度为 10 的数组，// 而是赋值一个空数组public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; addArrayList 提供了两个 add 方法： 1234567891011121314151617181920212223// 将元素插入到尾部public boolean add(E e) &#123; // 容量检查 ensureCapacityInternal(size + 1); // 将新元素插入序列尾部 elementData[size++] = e; return true;&#125;// 将元素插入到 index 位置public void add(int index, E element) &#123; // 检查索引合法性 rangeCheckForAdd(index); // 检查容量 ensureCapacityInternal(size + 1); // 将 index 及其之后的所有元素都向后移一位 System.arraycopy(elementData, index, elementData, index + 1, size - index); // 插入元素 elementData[index] = element; size++;&#125; add(int index, E element) 每次都需要移动元素，时间复杂度是 O(n) ，若是频繁使用会影响效率，应尽量少使用。 扩容机制调用 add 方法时，插入元素之前都会先进行容量检查，若容量不够，则需要进行扩容。扩容的新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，大约是旧容量的 1.5 倍。扩容的具体实现在 grow() 方法，扩容时使用 Arrays.copyOf() ，这个操作代价很高。 如果能确定元素个数，则最好在创建 ArrayList 对象时就指定容量大小，减少扩容操作的次数。 扩容逻辑： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public boolean add(E e) &#123; ensureCapacityInternal(size + 1); elementData[size++] = e; return true;&#125;--&gt;private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;--&gt; // 如果使用的是默认构造器，elementData 会被赋值为 DEFAULTCAPACITY_EMPTY_ELEMENTDATA（空数组），// 在第一次添加元素时（没有使用ensureCapacity主动扩容），会将数组扩容到长度为 10（即默认长度 - DEFAULT_CAPACITY）private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;--&gt;// 若指定的最小容量大于 当前数组的长度 ，进行扩容。private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 若所需最小容量大于当前数组长度，进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;--&gt; // 扩容的核心方法private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 新容量，为旧容量的 1.5 倍左右 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 边界检查 // 如果 1.5 倍新容量小于最小所需容量，将新容量置为 minCapacity if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 若 newCapacity 大于 MAX_ARRAY_SIZE，计算新容量 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // elementData = Arrays.copyOf(elementData, newCapacity);&#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); // 若最小所需容量大于 MAX_ARRAY_SIZE ，返回 Integer.MAX_VALUE ， 否则 MAX_ARRAY_SIZE return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; ArrayList 还提供一个主动扩容的方法，该方法将数组扩容为指定大小： 123456789101112public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It&#x27;s already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125; 最好在 add 大量元素之前用 ensureCapacity 方法，以减少重新分配的次数。 若是使用无参构造器创建一个 ArrayList（即默认长度为 10），并不会一开始就将 elementData 初始化为长度为 10 的数组，只是赋值一个空数组，如下： 123public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125; 会等到第一次添加元素时，才会将数组长度扩容为 10（会在 calculateCapacity 方法中判断 elementData 是否是 DEFAULTCAPACITY_EMPTY_ELEMENTDATA，若是，指定 minCapacity 为 10）。 removeArrayList 有两个 remove 方法： 它们的操作的时间复杂度为 O(N)，所以 ArrayList 删除元素的代价是非常高的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 删除指定索引处的元素public E remove(int index) &#123; // 索引检查 rangeCheck(index); modCount++; // 要删除的元素 E oldValue = elementData(index); // 计算要移动元素的个数 int numMoved = size - index - 1; if (numMoved &gt; 0) // 从数组的 index+1 位置开始，将 numMoved 个元素依次向前移动一位，覆盖被删除值 System.arraycopy(elementData, index+1, elementData, index, numMoved); // 将最后一个元素置空，并将 size 值减1 elementData[--size] = null; // clear to let GC do its work return oldValue;&#125;public boolean remove(Object o) &#123; if (o == null) &#123; // 删除所有 null 值 for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;// 快速删除，即不用进行索引检查，不返回被删除元素值private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; trimToSize往 ArrayList 插入大量元素后，又删除很多元素，此时底层数组会空闲出大量的空间。因为 ArrayList 没有自动缩容机制，导致底层数组大量的空闲空间不能被释放，造成浪费。对于这种情况，ArrayList 也提供了相应的处理方法，即 trimToSize 方法： 123456789101112public void trimToSize() &#123; modCount++; // 如果当前元素个数小于数组长度 if (size &lt; elementData.length) &#123; elementData = // size 为 0 直接赋值为空数组 (size == 0) ? EMPTY_ELEMENTDATA // 否则只保留前 size 个元素 : Arrays.copyOf(elementData, size); &#125;&#125; 遍历ArrayList 实现了 RandomAccess 接口（该接口是个标志性接口），表明它具有随机访问的能力。在遍历 ArrayList 时，使用 for 循环的效率会比使用 foreach 效率要高，即： 123for (int i = 0; i &lt; list.size(); i++) &#123; list.get(i);&#125; 使用 foreach 会转化为使用迭代器遍历，效率不如使用 for 循环。 关于序列化ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。 保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。 ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 序列化时会调用 writeObject() 方法，该方法在传入的对象存在 writeObject() 方法时会去反射调用该对象的 writeObject() 来实现序列化。反序列化原理类似。 modCountArrayList 有一个继承自 AbstractList 的成员变量 modCount ，记录 ArrayList 被改变的次数（添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小时），在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。在 writeObject() 方法中有所体现。 1protected transient int modCount = 0; 参考 ArrayList 源码分析 - 田小波 ArrayList 源码+扩容机制分析 - JavaGuide Java 容器 - CyC","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"集合源码","slug":"Java/集合源码","permalink":"http://example.com/categories/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"LinkedList-JDK1.8","slug":"Java/集合源码/LinkedList - JDK1.8","date":"2021-03-20T14:20:41.629Z","updated":"2021-03-20T14:04:20.679Z","comments":true,"path":"2021/03/20/Java/集合源码/LinkedList - JDK1.8/","link":"","permalink":"http://example.com/2021/03/20/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/LinkedList%20-%20JDK1.8/","excerpt":"","text":"概述LinkedList 的继承体系： LinkedList 底层是基于双向链表实现的，所以 LinkedList 的容量上限是物理内存或 JVM 内存上限，它无需像 ArrayList 般进行扩容，且支持高效的插入和删除操作，但是存储元素的节点需要额外的空间存储前驱和后继的引用，且不支持 O(1) 的随机访问，虽然实现了 List 接口，有 get(int) 方法，但其时间复杂度是 O(n) 。 LinkedList 中有两个引用 first、last 分别指向头结点和尾结点，所以在链表头部和尾部插入效率比较高，但在其他指定位置进行插入时，效率一般。因为在指定位置插入需要先定位到该位置处的节点，此操作的时间复杂度为 O(n)。另外，LinkedList 是非线程安全的集合类。 LinkedList 可以作为队列、栈来使用。需要使用栈时应优先使用 LinkedList ，而避免使用 Stack 类。 关于 AbstractSequentialList 抽象类：AbstractSequentialList 提供了一套基于顺序访问的接口。通过继承此类，子类仅需实现部分代码即可拥有完整的一套访问某种序列表（比如链表）的接口。但 LinkedList 并没有直接该类的方法，而是重新实现了一套方法。 LinkedList 内的结点类： 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 查找12345678910111213141516171819202122public E get(int index) &#123; // 检查索引 checkElementIndex(index); return node(index).item;&#125;// 返回索引 index 对应的结点（即第 index+1 个结点）Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 根据 index 是否小于 size 的一半决定从 first 还是 last 开始遍历 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 可见 LinkedList 因为是基于链表实现，索引不能随机访问元素。这里有一个小优化：会根据 index 离哪一端近来决定从 first 还是 last 开始遍历。 此外，LinkedList 还有针对队列和栈的一些方法：getFirst() getLast() poll() pop() 等，都是直接返回头结点或尾结点的值。 关于遍历的问题遍历 LinkedList 应该使用 iterator 或者 foreach 循环（会转换为使用 iterator ），应该避免如下形式的遍历： 1234for (int i = 0; i &lt; list.size(); i++) &#123; Integet item = list.get(i); // do something&#125; LinkedList 的 get(int) 方法时间复杂度是 O(n) ，若是集合中的元素数量较大，效率会很低。 LinkedList 的迭代器实现： 调用 iterator() 方法时最终会调用 listIterator(0) 1234567891011121314151617181920212223242526272829303132333435public ListIterator&lt;E&gt; listIterator(int index) &#123; checkPositionIndex(index); return new ListItr(index);&#125;private class ListItr implements ListIterator&lt;E&gt; &#123; private Node&lt;E&gt; lastReturned; private Node&lt;E&gt; next; private int nextIndex; private int expectedModCount = modCount; // 从指定索引开始迭代 ListItr(int index) &#123; // assert isPositionIndex(index); next = (index == size) ? null : node(index); nextIndex = index; &#125; public boolean hasNext() &#123; return nextIndex &lt; size; &#125; public E next() &#123; checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); lastReturned = next; next = next.next; nextIndex++; return lastReturned.item; &#125; // ....&#125; 插入LinkedList 继承和实现了多个类和接口，有很多插入元素的方法，如下： 针对队列和栈的一些方法大都是在头结点和尾结点操作，逻辑较简单，这里主要分析前 add 方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 在链表尾部插入元素public boolean add(E e) &#123; linkLast(e); return true;&#125;// 将元素插入到指定位置public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) // 直接插入到链表尾 linkLast(element); else // 先找到 index 位置的结点（node(index)），再把 element 插入到该结点之前 linkBefore(element, node(index));&#125;void linkLast(E e) &#123; final Node&lt;E&gt; l = last; // 创建节点，并指定节点前驱为链表尾节点 last，后继引用为空 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); // last 后移 last = newNode; // 判断尾节点是否为空，为空表示当前链表还没有节点 if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; final Node&lt;E&gt; pred = succ.prev; // 新结点的 prev 指向 succ 的 prev，next 指向 succ final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); // succ 的 prev 指向新结点 succ.prev = newNode; // 若 succ 原本是头结点，则插入新结点后将 first 指向 newNode if (pred == null) first = newNode; else // 否则 pred 的 next 连接 newNode pred.next = newNode; size++; modCount++;&#125; 这些操作都是典型的链表操作，不难理解。 add(index, element) 的逻辑是： 若 index 等于 size，表示要插入链表尾部，直接调用 linkLast 即可； 否则需要先定位到 index 处的结点，再把新结点插入到该结点之前。 删除相对 LinkedList 的插入方法，它也有很多对应的删除方法，这里主要分析 remove(index) 和 remove(obj) 方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 删除指定位置的元素，返回该元素public E remove(int index) &#123; checkElementIndex(index);// 检查索引 return unlink(node(index));&#125;// 删除指定元素，删除成功返回 true，否则 false// 若是有多个相同的值，则只删除找到的第一个（unlink 后立即 return）public boolean remove(Object o) &#123; // o 为 null 值 if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; // 不为 null。使用 equals 比较 &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125;// 将指定节点从链表中移除E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // prev 为空表示 x 是头结点 if (prev == null) &#123; // 将 first 指向 next 即可 first = next; &#125; else &#123; prev.next = next; x.prev = null;/// &#125; // 类似的，判断 x 是不是尾结点 if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null;/// &#125; x.item = null;//将 x 的 item 引用置 null size--; modCount++; return element;&#125; unlink 方法的逻辑如下（假设删除的节点既不是头节点，也不是尾节点）： 将待删除节点 x 的前驱的后继指向 x 的后继 将待删除节点 x 的前驱引用置空，断开与前驱的链接 将待删除节点 x 的后继的前驱指向 x 的前驱 将待删除节点 x 的后继引用置空，断开与后继的链接 参考 LinkedList 源码分析(JDK 1.8) - 田小波","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"集合源码","slug":"Java/集合源码","permalink":"http://example.com/categories/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"MySQL概述","slug":"MySQL/MySQL概述","date":"2021-03-20T12:57:38.415Z","updated":"2021-03-20T12:59:33.744Z","comments":true,"path":"2021/03/20/MySQL/MySQL概述/","link":"","permalink":"http://example.com/2021/03/20/MySQL/MySQL%E6%A6%82%E8%BF%B0/","excerpt":"","text":"概述​ MySQL很牛逼。 MySQL是属于C/S架构的软件。 MySQL的优点：可将数据持久化到本地；可用sql语言进行查询，便于管理。 MySQL的卸载及安装MySQL卸载MySQL的卸载：https://www.bilibili.com/video/BV12b411K7Zu?p=249 第6集 MySQL8.0.22的安装https://blog.csdn.net/qq_43715354/article/details/109354222 按照该教程至第八步。 启动cmd。 输入mysql -u root -p 输入上述随机生成的密码进入数据库。进入后需要修改密码，因为随机生成的密码在登录后会过期。（这时若不修改密码，执行一切sql语句都会报错，提醒修改密码） 修改密码的命令： alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;newPassword&#39;; flush privileges; my.ini文件MySQL的安装目录下的my.ini文件是MySQL的配置文件，在其中可配置相关信息（#开头的为注释），其中的[mysqld]下可配置服务端的相关信息，如下： 12345678910111213141516171819202122232425[mysqld]# 设置3306端口port=3306# 设置mysql的安装目录basedir=D:\\\\Program Files\\MySQL\\mysql-8.0.22# 设置mysql数据库的数据的存放目录datadir=D:\\\\Program Files\\MySQL\\mysql-8.0.22\\data# 允许最大连接数max_connections=200# 允许连接失败的次数。max_connect_errors=10# 服务端使用的字符集默认为utf8mb4character-set-server=utf8mb4# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB# 默认使用“mysql_native_password”插件认证#mysql_native_passworddefault_authentication_plugin=mysql_native_password[mysql]# 设置mysql客户端默认字符集default-character-set=utf8mb4[client]# 设置mysql客户端连接服务端时默认使用的端口port=3306default-character-set=utf8mb4 MySQL服务的启动和关闭可通过 【右键我的电脑】-》【管理】-》【服务和应用程序】-》【服务】-》【找到MySQL】-》【双击，选择启动/关闭】 或者： 以【管理员身份运行命令行】-》【输入命令net stop/start mysqlServerName】 登录MySQL及环境变量登录MySQL​ 可通过MySQL自带的命令行（只能登录root用户）。 ​ 也可通过命令行： ​ mysql -h localhost -P 3306 -u root -p ​ mysql -h localhost -P 3306 -u root -padmin （用于连接远程） ​ mysql -u root -pPassword （连接本地MySQL） MySQL环境变量​ 若以上命令不可用，可能原因是没有配置环境变量（若是使用msi安装包安装则MySQL会自动配置）。 ​ 手动配置过程：在Path环境变量中添加MySQL的安装目录中的bin目录路径即可。 MySQL语法规范及常用命令语法规范 MySQL中的命令以;或\\g结束。 MySQL命令不区分大小写。 注释 单行注释：#注释或-- 注释(空格必需) 多行注释：/* 注释 */ 常用命令进入MySQL后，可使用以下相关命令： 显示所有数据库：show databases; ---------------------------------- 使用指定数据库：use dababaseName; ---------------------------------- 显示当前数据库中的所有表：show tables; ---------------------------------- 显示指定数据库的所有表（使用该命令后，当前数据库位置不变）：show tables from databaseName ---------------------------------- 查看表结构：desc tableName ---------------------------------- 查看MySQL版本： 在MySQL中：select version(); 在MySQL外：mysql --version或mysql -V ----------------------------------","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/Tag/MySQL/"}]},{"title":"事务","slug":"MySQL/事务","date":"2021-03-20T12:55:23.154Z","updated":"2021-03-20T12:59:41.520Z","comments":true,"path":"2021/03/20/MySQL/事务/","link":"","permalink":"http://example.com/2021/03/20/MySQL/%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"（以下部分内容摘抄自javaGuide博客文档） 基本概念​ 事务是逻辑上的一组操作，即一个或多个SQL语句，要么都执行，要么都不执行。如果单元中某条SQL语句一旦执行失败或产生错误，整个单元将会回滚。所有受到影响的数据将返回到事物开始以前的状态；如果单元中的所有SQL语句均执行成功， 则事物被顺利执行。 ​ 事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。 事物的四大特性(ACID) 原子性（Atomicity）： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的； ACID里的AID都是数据库的特征,也就是依赖数据库的具体实现.而唯独这个C,实际上它依赖于应用层,也就是依赖于开发者.这里的一致性是指系统从一个正确的状态,迁移到另一个正确的状态.什么叫正确的状态呢?就是当前的状态满足预定的约束就叫做正确的状态.而事务具备ACID里C的特性是说通过事务的AID来保证我们的一致性。 （来自https://www.zhihu.com/question/31346392/answer/362597203 作者：孟波） 隔离性（Isolation）： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间是独立的； 持久性（Durability）： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 事务的创建​ 事务可分为隐式事务和显式事务。隐式事务如DML语言（insert、update、delete），每一个语句都是一个事务；而显式事务通过sql语句开启事务跟关闭事务，一个事务可有多条语句。 ​ msyql默认关闭事务，通过SHOW VARIABLES LIKE &#39;%autocommit%&#39;;命令可看到``autocommit=ON`，即自动提交默认开启。创建事务前需关闭自动提交。事务中不能包括DDL语句。 显示事务的创建： 1234567891011--1.开启事务SET autocommit=0;START TRASACTION; #可选--编写事务语句语句1语句2...--结束事务COMMIT;#或者ROLLBACK; 一个转账的例子： 12345678910111213141516#先建表CREATE TABLE account( username VARCHAR(10), money DOUBLE);INSERT INTO account VALUES(&#x27;zhangsan&#x27;, 1000),(&#x27;xiaoming&#x27;, 1000);#转账例子#开启事务（关闭事务自动提交）SET autocommit=0;START TRANSACTION;#事务语句UPDATE account SET money=500 WHERE username=&#x27;zhangsan&#x27;;UPDATE account SET money=1500 WHERE username=&#x27;xiaoming&#x27;;#提交事务COMMIT; 回滚点SAVEPOINT​ 回滚点跟ROLLBACK搭配使用，其作用是设置一个保存点，当执行ROLLBACK时回滚到保存点。 eg： 1234567SET autocommit=0;START TRANSACTION;DELETE FROM account WHERE id=2;SAVEPOINT a;DELETE FROM account WHERE id=3;ROLLBACK TO a; 执行以上语句后查询account表，可发现只删除了id为2的记录。 事务并发问题​ 在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。 脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的，比如可能出现错误而回滚事务，导致修改后的数据没有存入数据库。 丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如： 事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。（即结果应该是A=18，但因为事务2的修改覆盖了事务1的修改，使事务1丢失） 考虑飞机订票系统中的一个活动序列: 甲售票点（甲事务）读出某航班的机票余额A,设A=16. 乙售票点（乙事务）读出同一航班的机票余额A,也为16. 甲售票点卖出一张机票,修改余额A←A-1.所以A为15,把A写回数据库. 乙售票点也卖出一张机票,修改余额A←A-1.所以A为15,把A写回数据库. 结果明明卖出两张机票，数据库中机票余额只减少1。 不可重复读（Unrepeatableread）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的结果可能不一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。（事务1读数据的过程中，事务2把数据给改了，导致事务1两次读的数据不同） 幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。（在同一事务下，连续执行两次同样的SQL语句第二次的SQL语句可能返回之前不存在的行） 不可重复读和幻读区别： 不可重复读的重点是数据的值被修改，比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。 MySQL的事务隔离级别SQL 标准定义了四个隔离级别： READ-UNCOMMITTED(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。 READ-COMMITTED(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 REPEATABLE-READ(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 SERIALIZABLE(可串行化)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但效率极低。该标准类似于线程锁。 可总结为下表（打勾表示可能发生） 隔离级别 脏读 不可重复读 幻影读 READ-UNCOMMITTED √ √ √ READ-COMMITTED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。可以通过SELECT @@tx_isolation;命令来查看 123456mysql&gt; SELECT @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+ ​ 这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ（可重读） 事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server) 是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化) 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 READ-COMMITTED(读取提交内容) ，但是InnoDB 存储引擎默认使用 REPEAaTABLE-READ（可重读）， 并不会有任何性能损失。 InnoDB 存储引擎在 分布式事务 的情况下一般会用到 SERIALIZABLE(可串行化) 隔离级别。 设置事务隔离级别： 12SET SESSION/GLOBAL TRANSACTION ISOLATION LEVEL read uncommitted | read committed | repeatable read(默认) | serializable; 锁机制与InnoDB锁算法（to be continue）","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/Tag/MySQL/"}]},{"title":"HashMap-JDK1.8","slug":"Java/集合源码/HashMap - JDK1.8","date":"2021-03-20T04:12:49.715Z","updated":"2021-04-17T04:24:07.449Z","comments":true,"path":"2021/03/20/Java/集合源码/HashMap - JDK1.8/","link":"","permalink":"http://example.com/2021/03/20/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/HashMap%20-%20JDK1.8/","excerpt":"","text":"概述HashMap 最早出现在 JDK1.2 ，底层基于哈希表实现，JDK1.8 之前处理哈希碰撞使用的是拉链法，在 JDK1.8 引入了红黑树优化，即当链表过长时会转换为红黑树，提高查询效率。HashMap 允许 null 键和 null 值，null 键对应的哈希值是 0。HashMap 不保证键值对的顺序，在某些操作后，键值对的顺序会改变（比如扩容时）。 HashMap 不是线程安全集合。 原理概述HashMap 使用拉链法哈希算法，在 JDK1.8 引入红黑树来优化过长链表。 HashMap 定位元素的过程是： 计算桶索引。 在桶所在链表（或红黑树）查找元素。 当链表长度大于阈值（默认为 8）时，会首先调用 treeifyBin()方法。这个方法会根据 HashMap 数组来决定是否转换为红黑树。只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，只执行 resize() 方法对数组扩容。 构造方法分析HashMap 的 4 个构造方法： 12345678910111213141516171819202122232425262728293031323334static final float DEFAULT_LOAD_FACTOR = 0.75f;// 默认装载因子static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;// 默认初始容量// 1public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125;// 2public HashMap(int initialCapacity) &#123; // 调用了第 3 个构造方法 this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;// 3public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); // 以上皆是参数检查 this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;// 4public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 可以看到，构造方法只是初始化一些重要变量，而其他数据结构是延迟到插入键值对时再进行初始化。 初始容量、负载因子、阈值 名称 用途 initialCapacity HashMap 初始容量 loadFactor 负载因子 threshold 当前 HashMap 所能容纳键值对数量的最大值（阈值），超过这个值，则需扩容 源码： 123456789static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;/** The load factor used when none specified in constructor. */static final float DEFAULT_LOAD_FACTOR = 0.75f;final float loadFactor;/** The next size value at which to resize (capacity * load factor). */int threshold; HashMap 中并没有定义 capacity 这个属性，它只是构造方法中用一次，没必要定义一个变量保存。 其中，threshold=capacity*loadFactor，这里要注意的一个点是，上面的 tableSizeFor 方法并不是这么初始化 threshold 的值的。 在构造方法 3 中，可以看到使用了 tableSizeFor 方法来初始化 threshold 值，其源码如下： 123456789101112static final int tableSizeFor(int cap) &#123; // 将 cap 减 1 int n = cap - 1; // 进行 5 次移位、或运算 n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; // 最后 + 1 return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 方法的目的是找到大于或等于 cap 的最小的 2 的幂次方的数，将该值赋值给 threshold 。这里其实不是计算 threshold ，而是根据指定的 cap 计算 table 的容量，只是将值暂存在 threshold 。 负载因子的作用是规定了可使用的容量比例，通过调节负载因子，可使 HashMap 时间和空间复杂度上有不同的表现： 将负载因子调小，即所能容纳的数据表少，但相应的会减少键之间的哈希碰撞，链表长度减少，使得增删查改效率变高，这就是典型的拿空间换时间； 反之，将负载因子调大，能提高空间利用率，但哈希碰撞概率增大，性能相对下降。 查找get 方法： 123456789101112131415161718192021222324252627282930313233343536public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; // (n - 1) &amp; hash 计算得出 key 对应的桶索引 (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断桶第一个元素是不是目标 // hash 值相同 if (first.hash == hash &amp;&amp; // always check first node // 且通过 == 比较相同或 equals 比较相同 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 第一个元素不是目标 if ((e = first.next) != null) &#123; // 若是红黑树，在红黑树中查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 否则在链表中查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125;// 总结一下查找 key 的过程（省略一些 null 检查）：// 1. 先计算 key 对应的桶索引// 2. 获取桶的第一个结点，判断该结点是否是目标，// 其中，判断标准是：hash 相同且使用 == 或 equals 比较相同// 3. 否则再根据 first 是红黑树还是链表进行查找，判断标准跟上同 计算桶索引分析其中计算桶索引的过程： 1first = tab[(n - 1) &amp; hash] HashMap 中桶数组的大小 length 保证总是 2 的 n 次幂，此时，(n - 1) &amp; hash 等价于 hash 值对 length 取余，即计算桶索引实质上是 hash 值对桶数组取模，使用位运算计算方式的原因是对于计算机来说，位运算效率更高。 若一个正整数 x 是 2 的 n 次方，则对于 任一整数 y，有 y % x = y &amp; (x - 1) 。 再看看计算 hash 值的方法： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 可以看到并不是直接使用 key 的 hashCode() 方法返回值，而是会再进行一次异或操作。 &gt;&gt;&gt; 是右移补零操作符，int 类型值是 4 个字节，即 32 位，通过 (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) 的方式可以让高 16 位值与低 16 位值进行异或，即让高位数据与低位数据进行异或，以此加大低位信息的随机性，变相的让高位数据参与到计算中，加大 hash 值的复杂度。 重新计算 hash 可以增加 hash 的复杂度，当覆写 hashCode 方法时，可能会写出分布性不佳的 hashCode 方法，进而导致 hash 的冲突率比较高。通过移位和异或运算，可以让 hash 变得更复杂，进而影响 hash 的分布性。这也就是为什么 HashMap 不直接使用键对象原始 hash 的原因。 还要注意的一个点是：HashMap 是允许 key 为 null 的，当 key 为 null 时，由 hash 方法可看出返回的是 0 ，则 key 为 null 的键值对总是对应桶索引 0 。 插入核心逻辑在 putVal 方法中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 若 table 为空或长度为 0 ，进行扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 计算对应的桶索引，若索引处为空，直接插入键值对即可 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 桶索引处已有键值对 else &#123; Node&lt;K,V&gt; e; K k; // 先判断第一个键值对，若 hash 相同，且 == 或 equals 比较相等，将 e 指向 p if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果桶中引用类型是 TreeNode，则调用红黑树的插入方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 否则遍历链表 for (int binCount = 0; ; ++binCount) &#123; // 链表中不包含要插入的键值对，将该结点插入到链表最后 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 若链表长度到达树化阈值，则进行树化操作 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // hash 相同，且 == 或 equals 比较相等，停止循环（此时 e 指向 p.next） if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 判断要插入的键值对是否存在 HashMap 中 if (e != null) &#123; // existing mapping for key V oldValue = e.value; // onlyIfAbsent 表示是否仅在 oldValue 为 null 的情况下更新键值对的值 // 通过 put(k, v) 调用该方法时，onlyIfAbsent 为 false ，所以只要 e 不为 null 就会更新 // 若 onlyIfAbsent 为 true，则 oldValue 为 null 才指向更新 if (!onlyIfAbsent || oldValue == null) e.value = value; // HashMap 中该方法为空方法 afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 插入后若 size 到达阈值，扩容 if (++size &gt; threshold) resize(); // HashMap 中该方法为空方法 afterNodeInsertion(evict); return null;&#125; putVal 方法总结： 当桶数组 table 为空时，通过扩容的方式初始化 table（初始化 HashMap 后第一次插入值就会通过扩容初始化 table）。 计算桶索引，若对应的桶为 null，直接插入即可。 若桶已存有值 先比较第一个结点的 key 是否相同，是则更新。 判断结点类型是否是树结点，是则按红黑树的方式插入键值对。 否则将键值对插入链表尾部或更新 key 相同的结点的值，如果是前者，则链入链表后需要根据链表长度决定是否将链表转为红黑树。 插入新键值对后判断键值对数量是否大于阈值，大于的话则进行扩容操作。 两个 key “相同”的标准是两个 key 的 hash 相同且通过 == 或 equals() 比较返回 true 。HashMap 中可以存在两个 hash 相同，但 key 通过 equals 比较不相同的键值对。 扩容概述扩容逻辑位于 resize 方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 1. 计算新容量(newCap)和新阈值(newThr) // table 不为空，已经初始化过 if (oldCap &gt; 0) &#123; // 当 table 容量超过容量最大值，则不再扩容 // 将阈值置为 Integer.MAX_VALUE ，直接返回 oldTab if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 尝试按旧容量和阈值的 2 倍计算新容量和阈值的大小 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // table 为空，且 oldThr 大于 0 // 调用 HashMap(int) 和 HashMap(int, float) 构造方法时会产生这种情况 // 此时 threshold 存的是 capacity else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // table 为空，且 oldThr 也为 0，对应调用 HashMap() 的情况 else &#123; // zero initial threshold signifies using defaults // 置为默认容量大小 newCap = DEFAULT_INITIAL_CAPACITY; // threshold = capacity * loadfactor newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 按阈值计算公式进行计算 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; ///============================= // 2. 创建新 table @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 3. 将旧table的值映射到新table // 旧 table 不为空，则需要将其中的元素重新映射到新 table if (oldTab != null) &#123; // 遍历桶数组，并将键值对映射到新的桶数组中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; // 当前桶只有一个元素 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 当前桶存的是红黑树 else if (e instanceof TreeNode) // 对红黑树进行拆分 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 链表 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; // 遍历链表，并将链表节点按原顺序进行分组 do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; resize 方法的逻辑概括： 计算新桶数组的容量 newCap 和新阈值 newThr。 根据计算出的 newCap 创建新的桶数组，桶数组 table 也是在这里进行初始化的 将键值对节点重新映射到新的桶数组里。如果节点是 TreeNode 类型，则需要拆分红黑树。如果是普通节点，则节点按原顺序进行分组。 计算 newCap 和 newThr 逻辑分析分析计算 newCap 和 newThr 的两个分支： 123456789101112// 第一个条件分支if ( oldCap &gt; 0) &#123; // 嵌套条件分支 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;...&#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) &#123;...&#125;&#125; else if (oldThr &gt; 0) &#123;...&#125;else &#123;...&#125;// 第二个条件分支if (newThr == 0) &#123;...&#125; 分支一： oldCap &gt; 0：桶数组 table 已经被初始化。 oldCap &gt;= 230：这时如果旧容量到达 MAXIMUM_CAPACITY(230) ，则将阈值置为Integer.MAX_VALUE，即 231-1，且这时不进行扩容，直接返回旧 table。 newCap &lt; 230 &amp;&amp; oldCap &gt; 16：这时会先将 newCap x 2，若满足条件，将新阈值 newThr = oldThr &lt;&lt; 1，**这时若是传入的 loadFactor 的值（HashMap(int, float) 构造方法）大于 8 且为 2 的幂次方，则此操作可能造成溢出，这时 newThr 为 0** 。大多数情况下都是这种情况，即将容量扩大一倍。 (oldCap==0 &amp;&amp;)oldThr &gt; 0：threshold &gt; 0，且桶数组未被初始化 调用 HashMap(int) 和 HashMap(int, float) 构造方法时会产生这种情况，这种情况下 threshold 存的并不是阈值，而是暂存容量（this.threshold = tableSizeFor(initialCapacity);），此种情况下 newCap = oldThr，newThr 在第二个条件分支中算出。 oldCap == 0 &amp;&amp; oldThr == 0：桶数组未被初始化，且 threshold 为 0 调用 HashMap() 构造方法会产生这种情况。该构造方法中只是初始化了 loadFacotr 变量。这时使用默认值计算 newCap 和 newThr 。（即默认容量 16， 默认负载因子 0.75） 分支二：分支一中 oldCap &gt; 0 时 newThr 出现溢出，或 (oldCap==0 &amp;&amp;)oldThr &gt; 0时，newThr 会为 0，根据容量和装载因子计算。 映射到新 table(链表)若旧 table 不为空，需要将键值对映射到新 table 中，对旧 table 进行遍历，若桶不为空，有 3 种情况： 桶中只有一个元素，直接将该元素映射到新 table 。（e.hash &amp; (newCap - 1)） 桶类型是红黑树，则拆分红黑树。 桶类型是链表，遍历链表，并将链表节点按原顺序进行分组再映射到新 table，注意映射到新 table 后结点的相对顺序没变。 这里分析第 3 种情况。 往底层数据结构中插入节点时，一般都是先通过模运算计算桶位置，接着把节点放入桶中即可。事实上可以把重新映射看做插入操作。在 JDK 1.7 中，也确实是这样做的。但在 JDK 1.8 中，则对这个过程进行了一定的优化，逻辑上要稍微复杂一些。 优化逻辑分析见参考链接。 总的来说就是： 若 e.hash &amp; oldCap 的值为 0 ，则 e 在新 table 的桶索引跟在旧 table 中的一样。 若不为 0 ，则在新 table 的桶索引为 旧索引 + oldCap 。 这样就不用使用 e.hash &amp; (newCap - 1) 来计算桶索引，效率更高。 resize 中根据这个逻辑把链表分成两个队列，将两个队列分别插入新 table 对应的桶。 代码： 1234567891011121314151617181920212223242526272829303132333435else &#123; // preserve order // 两个队列（链表） Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; // 插入 lo 队列 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; // 否则插入 hi 链队列 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 将整个 lo 链表插入到新 table 的 j 桶即可 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 插入到 j + oldCap 桶 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125;&#125; JDK 1.8 版本下 HashMap 扩容效率要高于之前版本。比如相对于 JDK1.7 ，JDK 1.7 为了防止因 hash 碰撞引发的拒绝服务攻击，在计算 hash 过程中引入随机种子。以增强 hash 的随机性，使得键值对均匀分布在桶数组中。在扩容过程中，相关方法会根据容量判断是否需要生成新的随机种子，并重新计算所有节点的 hash。而在 JDK 1.8 中，则通过引入红黑树替代了该种方式。从而避免了多次计算 hash 的操作，提高了扩容效率。 树相关树结点内部类： 1234567891011static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; // ...&#125; TreeNode 的继承关系是： 1TreeNode -&gt; LinkedHashMap.Entry -&gt; HashMap.Node -&gt; Map.Entry HashMap.Node 即链表类型结点。 链表树化在将键值对插入链表后，会判断是否需要树化： 123456789101112131415161718192021222324252627282930313233343536373839// ====== putVal 中的代码片段if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash);// =======================static final int TREEIFY_THRESHOLD = 8;static final int MIN_TREEIFY_CAPACITY = 64;final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; // 若 table 为空或长度不到 MIN_TREEIFY_CAPACITY，则优先扩容，不进行树化 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; // hd 为头节点（head），tl 为尾节点（tail） TreeNode&lt;K,V&gt; hd = null, tl = null; // 按顺序将普通链表转成 树形节点链表（注意还不是红黑树） do &#123; // 将普通节点替换成树形节点 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); // p 接入尾部 if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); // 先将树型链表赋值到 index 处的桶 if ((tab[index] = hd) != null) // 将树形链表转换成红黑树 hd.treeify(tab); &#125;&#125;TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);&#125; treeifyBin 中并不是直接将链表树化，要树化要满足两个条件： 链表长度大于等于 TREEIFY_THRESHOLD（在 putVal 方法中判断） 桶数组容量大于等于 MIN_TREEIFY_CAPACITY 即链表长度到达 8 ，且桶数组容量大于等于 64 时才会进行树化，若只是链表长度到 8 ，则优先进行扩容。 优先进行扩容的原因：（来自参考链接） 当桶数组容量比较小时，键值对节点 hash 的碰撞率可能会比较高，进而导致链表长度较长。这个时候应该优先扩容，而不是立马树化。毕竟高碰撞率是因为桶数组容量较小引起的，这个是主因。容量小时，优先扩容可以避免一些列的不必要的树化过程。同时，桶容量较小时，扩容会比较频繁，扩容时需要拆分红黑树并重新映射。所以在桶容量比较小的情况下，将长链表转成红黑树是一件吃力不讨好的事。 另外，树化前会先将链表转为树型链表，TreeNode 继承自 Node 类，所以 TreeNode 仍然包含 next 引用，在这个过程中原链表的节点顺序最终通过 next 引用被保存下来。 树化的方法： 123final void treeify(Node&lt;K,V&gt;[] tab) &#123;...&#125; （摘自参考链接） HashMap 在设计之初，并没有考虑到以后会引入红黑树进行优化。所以并没有像 TreeMap 那样，要求键类实现 comparable 接口或提供相应的比较器。但由于树化过程需要比较两个键对象的大小，在键类没有实现 comparable 接口的情况下，怎么比较键与键之间的大小了就成了一个棘手的问题。为了解决这个问题，HashMap 是做了三步处理，确保可以比较出两个键的大小，如下： 比较键与键之间 hash 的大小，如果 hash 相同，继续往下比较 检测键类是否实现了 Comparable 接口，如果实现调用 compareTo 方法进行比较 如果仍未比较出大小，就需要进行仲裁了，仲裁方法为 （大家自己看源码吧） 链表转成红黑树后，原链表的顺序通过 next 引用被保留了（红黑树的根节点会被移动到链表的第一位），仍然可以按遍历链表的方式去遍历上面的红黑树。这样的结构为后面红黑树的切分以及红黑树转成链表做好了铺垫。 红黑树拆分扩容后需要将旧 table 中的键值对映射到新 table，若是存在红黑树结点，需要进行拆分重新映射。 拆分红黑树按照一般思路，可以先将红黑树转换为链表，再将链表按 resize() 方法中分组的方式进行重新映射。由上已知红黑树中通过 next 引用仍然保留着原来链表的顺序，所以对红黑树进行重新映射时，直接按照映射链表的方式进行即可，不用先转换为链表，无形中提高了效率。 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// == resize() 中代码片段else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);// ==================// 注意 tab 是 newTab final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // 两个队列 // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; // 计数 int lc = 0, hc = 0; /** * 红黑树节点仍然保留了 next 引用，故仍可以按链表方式遍历红黑树。 * 下面的循环是对红黑树节点进行分组，与 resize 中类似 */ for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; // 如果 loHead 不为空 if (loHead != null) &#123; // 链表长度小于等于 6(UNTREEIFY_THRESHOLD)，则将红黑树转成链表 if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; /* 否则需要树化 * hiHead == null 时，表明扩容后， * 所有节点仍在原位置，树结构不变，无需重新树化 */ tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; // 同上 if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125; 重新映射红黑树逻辑总结： 与映射链表的逻辑基本一致（红黑树中保存了原链表的顺序） 不同的地方在于，重新映射后，会将红黑树拆分成两条由 TreeNode 组成的链表。这时若是链表的长度小于等于UNTREEIFY_THRESHOLD，则需要将 TreeNode 链表转换为 Node 链表（见下一小节）。 否则根据条件还需要将 TreeNode 链表树化。 也就是说，红黑树拆分是先将树拆成两个链，再根据条件判断是否需要树化。 红黑树链化红黑树链化的方法是 untreeify() ，因为红黑树中仍然保留了原链表节点顺序，所以只需将 TreeNode 结点转换为 Node 结点即可。 123456789101112131415161718final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; // 遍历 TreeNode 链表，并用 Node 替换 for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; // 替换节点类型 Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125;Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next);&#125; 删除1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;public boolean remove(Object key, Object value) &#123; return removeNode(hash(key), key, value, true, true) != null;&#125;// matchValue 表示是否 value 相同才删除，若是使用 remove(key) 方法时，是要删除指定 key 的键值对，所以// matchValue 指定为 false；若是使用 remove(key, value)，则指定为 true（需要同时匹配 value）final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; // 定位桶位置 (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; // 如果 key 与第一个结点相同，将 node 指向第一个结点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; else if ((e = p.next) != null) &#123; // 如果是 TreeNode 类型，调用红黑树的查找逻辑定位待删除节点 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); // 链表，则遍历找到指定 key // 找到结点时，node 指向待删除结点， p 指向 node 的前驱结点 else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // 删除结点（若找不到则 node 为 null） // 对于 remove(key,value) 方法，matchValue 为 true，所以需要匹配 value 值 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; // 删除树结点 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); // node 是桶的第一个结点 else if (node == p) tab[index] = node.next; // node 指向待删除结点， p 指向 node 的前驱结点 else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; transient table 被 transient 所修饰 table 变量 HashMap 中 table 数组被 transient 修饰，表示 table 不会被默认的序列化机制序列化。HashMap 通过实现readObject/writeObject两个方法自定义了序列化的内容。 为什么不直接将整个 table 序列化即可？ table 多数情况下是无法被存满的，序列化未使用的部分，浪费空间。 同一个键值对在不同 JVM 下，所处的桶位置可能是不同的，在不同的 JVM 下反序列化 table 可能会发生错误。 HashMap 的 get/put/remove 等方法第一步就是根据 hash 找到键所在的桶位置，但如果键没有覆写 hashCode 方法，计算 hash 时最终调用 Object 中的 hashCode 方法。但 Object 中的 hashCode 方法是 native 型的，不同的 JVM 下，可能会有不同的实现，产生的 hash 可能也是不一样的。也就是说同一个键在不同平台下可能会产生不同的 hash，此时再对在同一个 table 继续操作，就会出现问题。 与 JDK1.7 的主要区别链表&amp;红黑树JDK1.8 的 HashMap 相比于 JDK1.7，最大的区别肯定是红黑树优化，在插入元素后，若链表的长度大于阈值且数组长度大于 64 时会将链表树化。（数组长度不够则优先扩容） JDK1.7 插入新结点时使用的是头插法，而 JDK1.8 则是插入到链表尾部。 扩容JDK1.7 计算元素在新 table 中的索引时都是使用 hash 对长度取模的原始方式；JDK1.8 中则进行了优化，使用链表分组的方式（具体见上文），避免了多次重新计算 hash 值。 扩容后将旧 table 的元素转移到新 table 时，JDK1.7 依旧是使用头插法，所以一个链表上的元素的相对顺序会颠倒。而 JDK1.8 因为链表分组的方式保存了原来的顺序。（有啥用勒？） JDK1.8 的扩容逻辑相对较复杂，计算 newThr 和 newCap 时兼顾了 table 未初始化的情况；且转移元素时需要针对链表和红黑树作不同的处理。 计算hashJDK1.7： 12345678910final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; JDK1.8： 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; JDK 1.8 的 hash 方法 相比于 JDK 1.7 hash 方法更加简化，且相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。 （摘自参考连接） JDK 1.7 为了防止因 hash 碰撞引发的拒绝服务攻击，在计算 hash 过程中引入随机种子。以增强 hash 的随机性，使得键值对均匀分布在桶数组中。在扩容过程中，相关方法会根据容量判断是否需要生成新的随机种子，并重新计算所有节点的 hash。而在 JDK 1.8 中，则通过引入红黑树替代了该种方式。从而避免了多次计算 hash 的操作，提高了扩容效率。 参考 主要参考：HashMap 源码详细分析(JDK1.8) - 田小波 JavaGuide - HashMap底层分析","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"集合源码","slug":"Java/集合源码","permalink":"http://example.com/categories/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"包装类总结","slug":"Java/基础/包装类总结","date":"2021-03-16T08:37:06.898Z","updated":"2021-03-20T06:05:44.447Z","comments":true,"path":"2021/03/16/Java/基础/包装类总结/","link":"","permalink":"http://example.com/2021/03/16/Java/%E5%9F%BA%E7%A1%80/%E5%8C%85%E8%A3%85%E7%B1%BB%E6%80%BB%E7%BB%93/","excerpt":"","text":"基本数据类型Java中有 8 种基本数据类型，分别为： 6 种数字类型 ：byte、short、int、long、float、double 1 种字符类型：char 1 种布尔型：boolean。 它们占的字节大小： 基本类型 字节 int 4 short 2 long 8 byte 1 char 2 float 4 double 8 boolean 对于 boolean，官方文档未明确定义，它依赖于 JVM 厂商的具体实现。逻辑上理解是占用 1 位，但是实际中会考虑计算机高效存储因素。 &emsp;&emsp; 包装类八种基本类型都有对应的包装类分别为：Byte、Short、Integer、Long、Float、Double、Character、Boolean。 为什么要有包装类Java 是号称面向对象的语言，所有的类型都是引用类型。但是基本类型如 int 等不是引用类型，也不是继承自 Object，所以 Java 需要一个这样的包装类来使其具有对象的特性： 比如可以赋值为 null；且Java 集合中也只能放入包装类型，而不支持基本类型；可以创建一些特定的方法等。 &emsp;&emsp; 自动装箱/自动拆箱及其原理 装箱：将基本类型用它们对应的引用类型包装起来（转换为对应的包装类）； 拆箱：将包装类型转换为基本数据类型； 自动装箱/自动拆箱是如何实现的？ 编写代码： 123456public class Test &#123; public static void main(String[] args) &#123; Integer a = 2;// 装箱 int b = a;// 拆箱 &#125;&#125; 执行 javap -verbose 指令，查看 main 方法的反编译字节码： 12345678910111213public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=3, args_size=1 0: iconst_2 1: invokestatic #2 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 4: astore_1 5: aload_1 6: invokevirtual #3 // Method java/lang/Integer.intValue:()I 9: istore_2 10: return 可以看到，自动装箱实际上是调用对应包装类的 static valueOf() 方法；而对于自动拆箱，调用的是包装类对象的 xxxValue() ，其中，xxx代表对应的基本数据类型。 &emsp;&emsp; Integer 中的这两个方法： 123456789101112private final int value;//...public int intValue() &#123; return value;&#125;public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; &emsp;&emsp; 缓存Java 基本类型的包装类的大部分都实现了常量池技术，即 Byte,Short,Integer,Long,Character,Boolean 中，前面 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据，Character 创建了数值在 [0,127] 范围的缓存数据，Boolean 直接返回 True Or False。如果超出对应范围仍然会去创建新的对象。 对以上包装类调用 valueOf() 方法会首先尝试从 cache 中获取值，若不能命中，则使用 new 创建对象 。 如上面所示 Integer 的 valueOf() 方法中的： 12if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; 其中 cache 的定义为： 1static final Integer cache[]; 其在 static 静态块中被初始化（摘取部分代码）： 1234cache = new Integer[(high - low) + 1];int j = low;// low 为 -128for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); 对于 Byte,Short,Long,Character 类似。 对于 Double、Float 的 valueOf() 则是直接使用 new 创建对象返回。 &emsp;&emsp; 一个例子: 123456789101112131415161718Integer i1 = 40;Integer i2 = 40;Integer i3 = 0;Integer i4 = new Integer(40);Integer i5 = new Integer(40);Integer i6 = new Integer(0);System.out.println(&quot;i1=i2 &quot; + (i1 == i2)); //trueSystem.out.println(&quot;i1=i2+i3 &quot; + (i1 == i2 + i3)); //trueSystem.out.println(&quot;i1=i4 &quot; + (i1 == i4)); //falseSystem.out.println(&quot;i4=i5 &quot; + (i4 == i5)); //falseSystem.out.println(&quot;i4=i5+i6 &quot; + (i4 == i5 + i6)); //true System.out.println(&quot;40=i5+i6 &quot; + (40 == i5 + i6)); //trueDouble d1 = 1.2;Double d2 = 1.2;System.out.println(d1 == d2);// false &emsp;&emsp; 使用 == 比较时要注意的点： 当 “==”运算符的两个操作数都是包装器类型的引用，则是比较指向的是否是同一个对象； 如果其中有一个操作数是表达式（即包含算术运算）或有一边是基本类型，则比较的是数值（即会触发自动拆箱的过程）。例如对于 i4 == i5 + i6，首先 i5 和 i6 进行自动拆箱操作，进行数值相加，即 i4 == 40，再将 i4 拆箱，即 40==40 。 &emsp;&emsp; equals() 方法所有包装类（注意是所有）的 equals() 方法在进行比较时，都是先判断参数值是不是当前包装类类型， 若不是直接返回 false。 若是，则比较两者中封装的 value 成员变量值是否相等。 例如对于 Integer： 123456public boolean equals(Object obj) &#123; if (obj instanceof Integer) &#123; return value == ((Integer)obj).intValue(); &#125; return false;&#125; &emsp;&emsp; 示例： 123456public static void main(String[] args) &#123; Long g = 3L; Integer i = 3; System.out.println(g.equals(i));// false ，g 和 i 的类型不同&#125; 若是 equlas 传入的参数是基本类型，则会转换为对应的包装类 12345678public static void main(String[] args) &#123; Long g = 3L; Integer a = 1; Integer b = 2; System.out.println(g.equals(a+b));// false System.out.println(g.equals(3));// false&#125; &emsp;&emsp; 参考 javaGuide 深入剖析Java中的装箱和拆箱","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"http://example.com/categories/Java/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"总结 equals 和 hashCode","slug":"Java/基础/equals和hashCode","date":"2021-03-16T03:26:05.349Z","updated":"2021-03-20T12:06:15.135Z","comments":true,"path":"2021/03/16/Java/基础/equals和hashCode/","link":"","permalink":"http://example.com/2021/03/16/Java/%E5%9F%BA%E7%A1%80/equals%E5%92%8ChashCode/","excerpt":"","text":"这篇文章主要是总结自： Java hashCode() 和 equals()的若干问题解答 概述hashCode() 的作用是获取哈希码，也称为散列码；它实际上是返回一个 int 整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。 hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode() ，则一个 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） &emsp;&emsp; 该方法主要是为了支持如 HashSet 、 HashMap 等基于哈希表实现的集合。 也就是说：hashCode() 在散列表中才有用，在其它情况下没用。在散列表中 hashCode() 的作用是获取对象的散列码，进而确定该对象在散列表中的位置。 讨论 equals() 和 hashCode() 的关系应该分两种情况进行： 不会创建“类对应的散列表”第一种是不会在 HashSet, Hashtable, HashMap 等基于哈希表实现的数据结构中用到该类，这种情况下 equals() 和 hashCode() 没有关系，如果要比较对象，只需使用 equals() 来进行比较，而并不需要用到 hashCode() ，**所以重写 equals() 时不需要重写 hashCode()**。 比如只是要比较两个 Person 对象的 name 是否相同，但没有要将其放到 HashSet 等集合，只需重写 equals() 即可，如： （来自参考链接） 123456789101112131415161718public boolean equals(Object obj)&#123; if(obj == null)&#123; return false; &#125; //如果是同一个对象返回true，反之返回false if(this == obj)&#123; return true; &#125; //判断是否类型相同 if(this.getClass() != obj.getClass())&#123; return false; &#125; Person person = (Person)obj; return name.equals(person.name); &#125; &emsp;&emsp; 会创建“类对应的散列表”第二种情况则是会在 HashSet, Hashtable, HashMap 等基于哈希表实现的数据结构中用到该类。 这时需要注意两者的关系： 若是两个对象使用 equals() 比较返回 true，那么使用 hashCode() 应该返回相同的哈希值。否则会出现 “ 两个对象是相同的(equals 返回 true)，但却可以放进同一个哈希表 ” 的情况。 hashCode() 的 javaDoc ：If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result. 但如果使用 equals() 比较返回 false ，并不要求 hashCode() 返回不同的值。因为在哈希表中，即使两个哈希值相同（两个 key 相同），它们的值不一定相同（value 不一定相同），这种情况即哈希碰撞。 hashCode() 的 javaDoc ：It is not required that if two objects are unequal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce distinct integer results 一个要注意的点是：在 HashSet 、 HashMap 等基于哈希表的集合中，若是两个对象使用 equals() 比较返回 false，但 hashCode() 返回相同的值（即产生哈希碰撞时），还是会将两个对象都放进集合（这时会使用哈希碰撞解决方法，如拉链法，红黑树等）。 &emsp;&emsp; 所以若是要在哈希表实现的数据结构中使用到某个类，则需要重写这个类的 equals() 和 hashCode() ，并保证它们满足上述关系。 示例：（来自参考链接） 定义 Person 类： 1234567891011121314151617181920212223242526272829303132333435363738394041class Person &#123; int age; String name; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String toString() &#123; return name + &quot; - &quot; +age; &#125; @Override public int hashCode()&#123; // 两个对象的 name 的大写相同且年龄相同时，返回相同的哈希值 int nameHash = name.toUpperCase().hashCode(); return nameHash ^ age; &#125; @Override public boolean equals(Object obj)&#123; if(obj == null)&#123; return false; &#125; //如果是同一个对象返回true，反之返回false if(this == obj)&#123; return true; &#125; //判断是否类型相同 if(this.getClass() != obj.getClass())&#123; return false; &#125; // name 相同（区分大小写）且年龄相同返回 true Person person = (Person)obj; return name.equals(person.name) &amp;&amp; age==person.age; &#125;&#125; 测试： 123456789101112131415161718192021222324252627public static void main(String[] args) &#123; // 新建Person对象， Person p1 = new Person(&quot;eee&quot;, 100); Person p2 = new Person(&quot;eee&quot;, 100); Person p3 = new Person(&quot;aaa&quot;, 200); Person p4 = new Person(&quot;EEE&quot;, 100); // 新建HashSet对象 HashSet set = new HashSet(); set.add(p1); set.add(p2); set.add(p3); set.add(p4); // 比较p1 和 p2， 并打印它们的hashCode() System.out.printf(&quot;p1.equals(p2) : %s; p1(%d) p2(%d)\\n&quot;, p1.equals(p2), p1.hashCode(), p2.hashCode()); // 比较p1 和 p4， 并打印它们的hashCode() System.out.printf(&quot;p1.equals(p4) : %s; p1(%d) p4(%d)\\n&quot;, p1.equals(p4), p1.hashCode(), p4.hashCode()); // p1.equals(p2) : true; p1(68545) p2(68545) // p1.equals(p4) : false; p1(68545) p4(68545) // 打印set，可以看到 p1 p4 equals返回 false，但 hashcode 相同，所以都被放进集合 System.out.printf(&quot;set:%s\\n&quot;, set); // set:[eee - 100, EEE - 100, aaa - 200]&#125; 如果不重写 hashCode() ，那么 p1、p2 都可以被放进 set 。 &emsp;&emsp; 参考 Java hashCode() 和 equals()的若干问题解答 hashCode() 与 equals()","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"http://example.com/categories/Java/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"synchronized","slug":"Java/多线程/synchronized","date":"2021-03-10T16:35:28.790Z","updated":"2021-04-17T06:23:08.993Z","comments":true,"path":"2021/03/11/Java/多线程/synchronized/","link":"","permalink":"http://example.com/2021/03/11/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/synchronized/","excerpt":"","text":"i++,i–同步问题代码： 12345678910111213static int counter;public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; for (int i = 0; i &lt; 5000; i++) &#123; counter++; &#125; &#125;, &quot;t1&quot;); Thread t2 = new Thread(() -&gt; &#123; for (int i = 0; i &lt; 5000; i++) &#123; counter--; &#125; &#125;, &quot;t2&quot;); t1.start(); t2.start(); t1.join(); t2.join(); log.debug(&quot;&#123;&#125;&quot;,counter);&#125; 两个线程执行完后，结果是不确定的。 因为 Java 中对静态变量的自增，自减并不是原子操作，假设 i 为静态变量，i++，i– 的字节码如下： i++： 1234getstatic //获取静态变量iconst_1 //准备常量1iadd //加操作putstatic //将修改后的值存入静态变量 i--： 1234getstatic //获取静态变量iconst_1 //准备常量1isub //减操作putstatic //将修改后的值存入静态变量 两个操作都需要先通过 getstatic 获取值，若一个操作没有等另一个操作完成，则其中一个 putstatic 必定会覆盖掉另一个，不能保证结果为 0 ，会造成丢失修改。 synchronized 的内存语义synchronized 的这个内存语义就可以解决共享变量内存可见性问题。 进入和退出 synchronized 块的语义： 进入 synchronized 块的内存语义是把在 synchronized 块内使用到的变量从线程的工作内存中清除， 这样在synchronized块内使用到该变量时就不会从线程的工作内存中获取， 而是直接从主内存中获取。 退出 synchronized 块的内存语义是把在 synchronized 块内对共享变量的修改刷新到主内存。 这也是加锁和释放锁的语义，当获取锁后会清空锁块内本地内存中将会被用到的共享变量，在使用这些共享变量时从主内存进行加载，在释放锁时将本地内存中修改的共享变量刷新到主内存。 除可以解决共享变量内存可见性问题外， synchronized 经常被用来实现原子性操作。另外要注意，synchronized关键字会引起线程上下文切换并带来线程调度开销。 synchronized 的使用 临界区指的是一个访问共用资源的程序片段，而这些共用资源又无法同时被多个线程线程访问的特性。当有线程进入临界区段时，其他线程或是进程必须等待。 竞态条件（Race Condition）：多个线程在临界区内执行，由于代码的执行序列不同而导致结果无法预测，称之为发生了竞态条件。 synchronized 关键字解决的是多个线程之间访问资源的同步性，它是一种互斥锁，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 下面是 synchronized 的 3 种使用方式。 修饰代码块123synchronized(obj)&#123; //obj为要锁定的资源（对象） ---//同步代码块（临界区） &#125; 进入临界区需要获取指定对象的锁。 修饰实例方法上锁的对象是方法所在对象。 123synchronized void method() &#123; //...&#125; 进入临界区需要获取方法所属对象的锁。 修饰静态方法123synchronized static void method() &#123; //...&#125; 进入临界区需要获取当前类的 class 对象的锁。 synchronized可以修饰方法、代码块，不能修饰构造器、成员变量。 示例，对上述i++，i–问题：多次执行，可保证结果为0。 123456789101112131415161718192021222324252627@Slf4j(topic = &quot;c.SimpleDemo&quot;)public class SimpleDemo &#123; static Integer counter = 0; static Object lock = new Object(); public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(() -&gt; &#123; for (int i = 0; i &lt; 5000; i++) &#123; synchronized (lock)&#123; counter++; &#125; &#125; &#125;, &quot;t1&quot;); Thread t2 = new Thread(() -&gt; &#123; for (int i = 0; i &lt; 5000; i++) &#123; synchronized(lock)&#123; counter--; &#125; &#125; &#125;, &quot;t2&quot;); t1.start(); t2.start(); t1.join(); t2.join(); log.debug(&quot;&#123;&#125;&quot;, counter); &#125;&#125; 从字节码看 synchronizedsynchronized代码块Test类： 123456789public class Test &#123; static final Object lock = new Object(); static int counter = 0; public static void main(String[] args) &#123; synchronized (lock)&#123; counter++; &#125; &#125;&#125; 对该类的class文件执行 javap -c （或 javap -verbose ）指令，得到反编译的指令码： 1234567891011121314151617181920212223public static void main(java.lang.String[]); Code: 0: getstatic #2 // （lock引用）进入临界区 3: dup // 4: astore_1 5: monitorenter // 将lock对象的 MarkWord 置为Monitor指针 6: getstatic #3 // Field counter:I 9: iconst_1 10: iadd 11: putstatic #3 // Field counter:I 14: aload_1 15: monitorexit // 将lock对象的 MarkWord 重置，唤醒EntryList 16: goto 24 19: astore_2 // 19-23为异常处理指令 20: aload_1 21: monitorexit // ----!----- 22: aload_2 23: athrow 24: return Exception table: //异常表 from to target type 6 16 19 any // 6-16行的指令发生异常时，调用19行的指令处理异常 19 22 19 any monitorenter 和 monitorexit 指令的文档介绍： monitorenter Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows: If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor. If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count. If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership. monitorexit The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref. The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so. 每个对象都关联一个 monitor ，当且仅当一个 monitor 拥有一个所有者时它是被锁住的（即某个线程获取到了该 monitor 锁）。执行 monitorenter 的线程会尝试获得与 objectref 关联的 monitor 的所有权。执行 monitorexit 指令的线程必须是 objectref 关联的 monitor 的所有者。 synchronized 修饰的代码块对应的字节码指令在一对 monitorenter/monitorexit 之间，monitorenter 表示线程对 monitor 对象加锁，monitorexit 则表示释放锁。 每个 monitor 会有一个 entry count，当该值为 0 ，线程可以获取到锁，若获取成功，则将 count 加 1，成为 monitor 的所有者。若是线程再次获取锁（重入），将 count 自增。 当线程释放锁时，count 减一，若为 0 ，表示锁被释放，其他线程可以竞争该锁。 另外，还会对应有一个异常表，用于当执行临界区代码发生异常时，可以保证锁的释放（异常处理指令中有 monitorexit 指令）。 synchronized方法对于 synchronized 方法（包括实例方法和静态方法），其方法字节码中没有 monitorenter 和 monitorexit ，而是使用一个方法标志位： 0x0020 ，对应 ACC_SYNCHRONIZED 。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 例如对于方法： 123public synchronized void info()&#123; System.out.println(&quot;Test.info&quot;);&#125; 其访问标志： MonitorMonitor，又叫管程，监视器。是操作系统的一个概念，其具体含义： 可以利用共享数据构抽象地表示系统中的共享资源并且将对该共享数据结构实施的特定操作定义为一组过程。进程对共享资源的申请、释放和其它操作必须通过这组过程接地对共享数据结构实现操作。 代表共享资源的数据结构以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序共同构成了一个操作系统的资源管理模块，称之为管程。管程被请求和释放资源的进程所调用。 管程相比于信号量等机制，把共享资源的操作统一了起来，更方便管理。 JVM 中也实现了管程机制。 使用 synchronized 时，所谓对指定对象上锁实际上是获取该对象对应的 monitor 对象的所有权。由上文 monitorenter 的文档已知 JVM 中每个对象会关联一个 monitor 对象。当要执行 synchronized 中的代码时，必须先获取 monitor 对象所有权，否则线程被阻塞，直到拥有 monitor 锁的线程释放锁再重新竞争。 Hotspot 虚拟机中，monitor 是基于 C++ 实现，具体的对象是 ObjectMonitor，其数据结构如下： 123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ;&#125; 其中的几个关键属性： _owner：指向持有 ObjectMonitor 对象的线程。 _WaitSet：处于 wait 状态的线程队列。 _EntryList：处于等待锁 block 状态的线程队列（竞争不到锁）。 _count：用来记录该线程获取锁的次数。 当多个线程同时访问一段同步代码时（monitorenter），首先会进入 _EntryList 队列中进行竞争，竞争成功的线程将 monitor 的 _owner 指向当前线程，同时 _count 变量加 1 。即当前线程获得了对象锁。其他获取不到锁的线程阻塞在 _EntryList 队列。 当线程执行完同步代码块并释放锁时（monitorexit），_owner 置为 null，_count 减 1， _EntryList 队列中的线程重新竞争锁。若是持有 monitor 的线程调用了 wait() 方法（monitor 对应的对象的 wait 方法），则线程释放锁（同样是_owner 置为 null，_count 减 1），并进入 _WaitSet 队列，且同样 _EntryList 队列中的线程竞争锁。 当执行 monitorenter 指令时，实际上是调用 ObjectMonitor 对象的 enter 方法，执行 monitorexit 指令则是调用 exit 方法。只有在 JDK1.6 之前， synchronized 的实现才会直接调用 enter 和 exit，这种锁被称之为重量级锁。JDK 1.6 及之后对 synchronized 进行了优化。 参考 synchronized与锁 Java6 及以上版本对 synchronized 的优化 Java并发进阶常见面试题总结 [译]Java虚拟机是如何执行线程同步的 Synchronized的实现原理（一） Moniter的实现原理","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"Java并发","slug":"Java并发","permalink":"http://example.com/Tag/Java%E5%B9%B6%E5%8F%91/"}]},{"title":"计算机网络笔记","slug":"计网笔记","date":"2021-03-10T16:33:27.913Z","updated":"2021-03-10T16:31:11.780Z","comments":true,"path":"2021/03/11/计网笔记/","link":"","permalink":"http://example.com/2021/03/11/%E8%AE%A1%E7%BD%91%E7%AC%94%E8%AE%B0/","excerpt":"","text":"&emsp; 运输层概述​ 运输层的任务就是负责向两台主机中进程之间的通信提供通用的数据传输服务。应用进程利用该服务传送应用层报文。由于一台主机可同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程（把信息传上去）。 ​ 运输层主要使用以下两种协议： 传输控制协议TCP（Transmission Control Protocol） 提供面向连接的、可靠的数据传输服务，其数据传输的单位是报文段（segment）。 用户数据报协议UDP（User Datagram Protocol）提供无连接的、尽最大努力的数据传输服务（不保证数据传输的可靠性），其数据传输的单位是用户数据报。 从通信和信息处理的角度看，运输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层。当网络的边缘部分中的两台主机使用网络的核心部分的功能进行端到端的通信时，只有主机的协议栈才有运输层，而网络核心部分中的路由器在转发分组时都只用到下三层的功能。 为什么需要运输层IP层的IP地址只是标识了两台主机，只能实现两个主机间的通信，而真正进行通信的是两个主机中的实体（进程），运输层通过端口来标识主机中的进程，实现进程间的通信。 UDPUDP，User Datagram Protocol，用户数据报协议。 用户数据报协议UDP只在IP的数据报服务之上增加了很少一点的功能， 这就是复用分用的功能以及差错检测的功能。UDP的主要特点是： 无连接。即发送数据之前不用建立连接。 UDP使用尽最大努力交付。 UDP是面向报文的。即应用层交下来的报文，UDP既不合并，也不拆分，只加上UDP首部后直接发送；相应的，接收时去除首部后直接上交应用层。 没有拥塞控制。即网络的拥塞不会使源主机发送速率降低。但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信） 支持一对一、一对多、多对一和多对多的交互通信。 首部开销小，8B。 TCP概述TCP，Transmission Control Protocol，传输控制协议。 TCP的主要特点： 面向连接。即使用tcp之前（通信之前）需要建立可靠连接，通信完毕后释放连接。 每一个TCP连接只能有两个端点。 TCP连接的端点叫做套接字（socket），一个套接字由IP地址:端口号组成。一个TCP连接由两个套接字唯一确定。 TCP提供可靠交付的服务。通过TCP连接传送的数据， 无差错、不丢失、不重复，并且按序到达。 TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。 TCP连接的两端都设有发送缓存和接收缓存， 用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后， 就可以做自己的事， 而TCP在合适的时候把数据发送出去。在接收时， TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。 面向字节流。TCP中的“流”(stream) 指的是流入到进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块(大小不等) ， 但TCP把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。TCP并不知道所传送的字节流的含义。TCP不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系。但接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。 TCP可靠传输原理（来自JavaGuide） 概述： 应用数据被分割成 TCP 认为最适合发送的数据块。 TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 TCP 的接收端会丢弃重复的数据。 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） 拥塞控制： 当网络拥塞时，减少数据的发送。 ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 停止等待协议停止等待协议的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。 优缺点： 优点： 简单 缺点： 信道利用率低，等待时间长 1) 无差错情况: 发送方发送分组，接收方在规定时间内收到，并且回复确认。发送方再次发送。 2) 出现差错情况（超时重传）: 停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 自动重传请求 ARQ 。 若收到重复分组，就丢弃该分组，但同时还要发送确认。连续 ARQ 协议 可提高信道利用率。 3) 确认丢失和确认迟到 确认丢失 ：确认消息在传输过程丢失。当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：1. 丢弃这个重复的M1消息，不向上层交付。 2. 向A发送确认消息。 确认迟到 ：确认消息在传输过程中迟到。A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：1. A收到重复的确认后，直接丢弃。2. B收到重复的M1后，也直接丢弃重复的M1。 连续ARQ协议连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。 优缺点： 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。 滑动窗口实现流量控制TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 ​ 拥塞控制在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。 为了进行拥塞控制，TCP 发送方要维持一个 拥塞窗口(cwnd) 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 TCP的拥塞控制采用了四种算法，即 慢开始 、 拥塞避免 、快重传 和 快恢复。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。 cwnd指拥塞窗口长度 慢开始： 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。每当出现超时的时候重新开始发送时即使用慢开始。 拥塞避免： 拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1。 快重传与快恢复（fast retransmit and recovery，FRR）：采用快重传算法可以让发送方尽早知道发生了个别报文段的丢失。快重传算法首先要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认，即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认（这里已收到的报文段是指失序段之前的报文段）。 如图（来自《计算机网络》所示，接收方收到了M1和M2后都分别及时发出了确认。现假定接收方没有收到M3；但却收到了M4。本来接收方可以什么都不做。但按照快重传算法，接收方必须立即发送对M2的重复确认（注意是M2），以便让发送方及早知道接收方没有收到报文段M3。发送方接着发送Ms和M6。接收方收到后也仍要再次分别发出对M2的重复确认。这样，发送方共收到了接收方的4个对M的确认，其中后3个都是重复确认。快重传算法规定，发送方只要一连收到3个重复确认，就知道接收方确实没有收到报文段M3，因而应当立即进行重传(即“快重传”)，这样就不会出现超时，发送方也不就会误认为出现了网络拥塞。 相应的，发送方知道只是丢失个别报文段，重新发送数据时不会启动慢开始，而是执行快恢复算法，即适当调整cwnd大小（如除以2），并执行拥塞避免。 TCP报文段首部格式 其中部分字段含义： 序号（seq）。TCP 是面向字节流的。在一个TCP连接中传送的字节流中的每一个字节都按顺序编号。整个要传送的字节流的起始序号必须在连接建立时设置。序号字段值指的是本报文段所发送的数据的第一个字节的序号。 确认号（ack）。期望收到对方下一个报文段的第一个数据字节的序号。若确认号为 N ，则标识序号 1 ~ N-1 的字节都已正确收到。 确认 ACK （控制位） 。仅当ACK=1时确认号字段才有效。当ACK=0时， 确认号无效。TCP规定，在连接建立后所有传送的报文段都必须把ACK置1。 同步 SYN （控制位）。在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1。因此， SYN置为1就表示这是一个连接请求或连接接受报文。 终止 FIN （控制位）。用来释放一个连接。当FIN=1时， 表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。 三次握手《计算机网络 第7版》中称为“三报文握手”。 图片来自《计算机网络 第7版》 A 为客户端，B 为服务器端。 ack 指确认号字段，ACK 是6个控制位之一。 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。 A 向 B 发送连接请求报文，（同步字段）SYN=1，（ACK=0），选择一个初始的序号 x，即 SYN=1, seq=x 。 B 收到连接请求报文，如果同意建立连接，则向 A 发送连接确认报文，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。即 SYN=1, ACK=1, seq=y, ack=x+1 。 A 收到 B 的连接确认报文后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。即 ACK=1, ack=y+1, seq=x+1 。 B 收到 A 的确认后，连接建立。 为什么需要最后一次握手（确认）？ 第三次握手是为了防止失效的连接请求到达服务器，让服务器错误打开连接。 客户端发送的连接请求如果在网络中滞留，那么就会隔很长一段时间才能收到服务器端发回的连接确认。客户端等待一个超时重传时间之后，就会重新请求连接。但是这个滞留的连接请求最后还是会到达服务器，如果不进行三次握手，那么服务器就会打开两个连接。如果有第三次握手，客户端会忽略服务器之后发送的对滞留连接请求的连接确认，不进行第三次握手，服务器接不到确认也就不会打开连接。 四次挥手 A 发送连接释放报文，FIN=1，并停止发送数据。 FIN=1, seq=u 。A进入“终止等待状态1”。 B 收到之后发出确认：ACK=1, ack=u+1, seq=v 。此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据，即从 A -》B 这个方向的连接释放了。此时 B 进入“关闭等待”状态 A收到确认后，进入“终止等待状态2”。等待B的连接释放报文段。 B 发出确认后会发送还没发送完的数据，当 B 已经没有要向 A 发送的数据时，发送连接释放报文，FIN=1。 FIN=1, ACK=1, seq=w, ack=u+1 。B 进入“最后确认”状态。 A 收到后发出确认： ACK=1, seq=u+1, ack=w+1 ，进入 TIME-WAIT （时间等待）状态，此时连接还没有释放，A 会等待 2 MSL（Maximum Segment Lifetime，最大报文存活时间）后释放连接。 B 收到 A 的确认后释放连接。 客户端接收到服务器端的 FIN 报文后还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由： 确保最后一个确认报文能够到达。如果 B 没收到 A 发送来的确认报文，会超时重传连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生，这时 A 会重新发送确认报文，并将计时重新设置为 2 MSL。 等待一段时间是为了让本连接持续时间内所产生的所有报文都从网络中消失使得下一个新的连接不会出现旧的连接请求报文，如已失效的连接请求报文段。 参考 运输层 《计算机网络 第7版》","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/Tag/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"类文件结构","slug":"Java/JVM/类文件结构(to be..)","date":"2021-03-05T06:25:56.673Z","updated":"2021-03-20T12:07:13.525Z","comments":true,"path":"2021/03/05/Java/JVM/类文件结构(to be..)/","link":"","permalink":"http://example.com/2021/03/05/Java/JVM/%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84(to%20be..)/","excerpt":"","text":"class文件结构概述Class文件是一组以字节为基础单位的二进制流， 各个数据项目严格按照顺序紧凑地排列在文件之中，中间没有添加任何分隔符， 这使得整个Class文件中存储的内容几乎全部是程序运行的必要数据，没有空隙存在，当遇到需要占用单个字节以上空间的数据项时，则会按照高位在前的方式分割成若干个字节进行存储。 Class文件格式采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构中只有两种数据类型：“无符号数”和“表”。 无符号数属于基本的数据类型，以ul、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。 表是由多个无符号数或者其他表作为数据项构成的复合数据类型，表的命名习惯以“info”结尾。表用于描述有层次关系的复合结构的数据。 整个Class文件本质上也可以视作是一张表， 这张表由下图所示的数据项按严格顺序排列构成。该格式中的数据项，无论是顺序还是数量，都是被严格限定的。(【】内表示数量，第一列表示数据类型） 123456789101112131415161718ClassFile &#123; u4 magic;【1】 //Class文件的标志（魔数） u2 minor_version;【1】//Class 的小版本号 u2 major_version;【1】//Class 的大版本号 u2 constant_pool_count;【1】//常量池的数量 cp_info constant_pool【constant_pool_count-1】;//常量池 数量是constant_pool_count-1，0号 u2 access_flags;【1】//Class 的访问标记 u2 this_class;【1】//当前类 u2 super_class;【1】//父类 u2 interfaces_count;【1】//接口 u2 interfaces;【interfaces_count】//一个类可以实现多个接口 u2 fields_count;【1】//Class 文件的字段属性 field_info fields;【fields_count】//一个类会可以有多个字段 u2 methods_count;【1】//Class 文件的方法数量 method_info methods;【methods_count】//一个类可以有个多个方法 u2 attributes_count;【1】//此类的属性表中的属性数 attribute_info attributes;【attributes_count】//属性表集合&#125; class文件中，当需要描述同一类型但数量不定的多个数据项时，使用一个前置的容量计数器（u2无符号数，即两个字节）加若干个连续的数据项的形式来表示。 魔数1u4 magic;【1】 每个Class文件的头4个字节称为魔数，用于标志这是一个能被JVM接受的class文件。其值为0xCAFEBABE。 版本号12u2 minor_version;【1】u2 major_version;【1】 紧接的4个字节是class文件的版本号，第5、6为次版本号（Minor Version），第7、8为主版本号（Major Version）。 高版本的 Java 虚拟机可以向下兼容执行低版本编译器生成的 Class 文件，但是低版本的 Java 虚拟机不能执行高版本编译器生成的 Class 文件。 jdk1.1对应45（十进制），往上依次递增1。如jdk1.8对应52（0x34） 常量池12u2 constant_pool_count;【1】//常量池的数量cp_info constant_pool【constant_pool_count-1】;//常量池 数量是constant_pool_count-1，0号 紧接着主、次版本号之后的是常量池， 常量池可以比喻为Class文件里的资源仓库， 它是Class文件结构中与其他项目关联最多的数据。 常量池中常量的数量是不固定的。constant_pool_count指定常量数量。这个容量计数是从1而不是0开始的，例如，若是0x0018（十进制24），即表示有24-1=23个常量。将第0项常量空出来的目的在于：如果后面某些指向常量池的索引值的数据在特定情况下需要表达“不引用任何一个常量池项目”的含义， 可以把索引值设置为0来表示。 对于其他集合类型，包括接口索引集合、字段表集合、方法表集合等的容量计数都是从0开始。 常量池中主要存放两大类常量：字面量和符号引用。 字面量比较接近于Java语言层面的常量概念， 如文本字符串、被声明为final的常量值等。 符号引用则属于编译原理方面的概念，主要包括下面几类常量： 被模块导出或者开放的包 类和接口的全限定名 **字段的名称和描述符 ** 方法的名称和描述符 方法句柄和方法类型 动态调用点和动态常量 Java代码在进行Javac编译的时候， 并不像C和C++那样有“连接”这一步骤， 而是在虚拟机加载Class文件的时候进行动态连接的 。也就是说， 在Class文件中不会保存各个方法、字段最终在内存中的布局信息，这些字段、方法的符号引用不经过虚拟机在运行期转换的话是无法得到真正的内存人口地址，也就无法直接被虚拟机使用的。当虚拟机做类加载时，将会从常量池获得对应的符号引用，再在类创建时或运行时解析、翻译到具体的内存地址之中。 常量池中每一项常量都是一个表，截至JDK13， 常量表中分别有17种不同类型的常量。这些表都有一个共同的特点， 表结构起始的第一位是个u1类型的标志位(tag， 见下表标志列)，代表着当前常量属于哪种常量类型。17种类型如下表： 类型 标志（tag） 描述 CONSTANT_utf8_info 1 UTF-8编码的字符串 CONSTANT_Integer_info 3 整形字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info ５ 长整型字面量 CONSTANT_Double_info ６ 双精度浮点型字面量 CONSTANT_Class_info ７ 类或接口的符号引用 CONSTANT_String_info ８ 字符串类型字面量 CONSTANT_Fieldref_info ９ 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段或方法的符号引用 CONSTANT_MethodHandle_info 15 表示方法句柄 CONSTANT_MothodType_info 16 标志方法类型 CONSTANT_Dynamic_info 17 表示一个动态计算常量 CONSTANT_InvokeDynamic_info 18 表示一个动态方法调用点 CONSTANT_Module_info 19 表示一个模块 CONSTANT_Package_info 20 表示一个模块中开发或者导出的包 常见的11种类型的结构表：（index表示指向第几个常量项） 在读取常量池时，只要读取每个项的第一个字节（tag）就可得知其类型，得知其类型后就能知道该项占多少字节，也就可以知道下一项从哪里开始，以此类推。 访问标志1u2 access_flags;【1】//Class 的访问标记 常量池结束之后紧接着的两个字节代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，即一个类或接口使用了哪些访问修饰符（public、abstract等）。 一个类或接口可拥有多个标志，这时标志值应该为这多个标志值取或。如 ACC_PUBLIC | ACC_SUPER = 0x0021。 类索引、父类索引与接口索引集合u2 this_class;【1】//当前类 u2 super_class;【1】//父类 u2 interfaces_count;【1】//接口数量 u2 interfaces;【interfaces_count】//一个类可以实现多个接口 类索引和父类索引都是一个u2类型的数据， 而接口索引集合是一组u2类型的数据的集合， Class文件中由这三项数据来确定该类型的继承关系。 类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名。Java不允许多继承， 所以父类索引只有一个， 除了java.lang.Object之外， 所有的Java类都有父类， 因此除了java.lang.Object外， 所有Java类的父类索引都不为0。这是两个索引值，指向常量池的对应项。 接口索引集合描述这个类实现了哪些接口，集合第一个项是接口计数器，之后是对应数量的接口索引（若计数器为0则不再占用任何字节）。这些接口索引将按implements关键字（如果该Class文件表示接口， 则是extends）后的接口顺序从左到右排列在接口索引集合中。 字段表集合u2 fields_count;【1】//Class 文件的字段属性 field_info fields;【fields_count】//一个类会可以有多个字段 字段表用于描述接口或类中声明的变量。字段包括类级变量以及实例变量，但不包括在方法内部声明的局部变量。 一个字段表的结构（来自javaGuide）： 各字段解释： access_flags: 字段的作用域（public ，private，protected修饰符），是实例变量还是类变量（static修饰符），可否被序列化（transient 修饰符），可变性（final），可见性（volatile 修饰符，是否强制从主内存读写）。 name_index: 对常量池的引用，表示的字段的简单名称； descriptor_index: 对常量池的引用，表示字段和方法的描述符； attributes_count: 一个字段还会拥有一些额外的属性，attributes_count 存放属性的个数； attributes[attributes_count]: 存放具体属性具体内容。 上述这些信息中，各个修饰符都是布尔值，要么有某个修饰符，要么没有，适合使用标志位来表示。而字段叫什么名字、字段数据类型都是无法固定的，只能引用常量池中常量来描述。 字段表中不会列出继承自父类或父接口的字段。 关于描述符：描述符用来描述字段的数据类型，或方法的参数列表（包括数量、类型和顺序）和返回值。基本数据类型以及无返回值void都用一个大写字符表示，对应关系： B- byte， C-char， D- double， F- float， I- int， J- long， s- short， z-boolean， v- void， L-对象类型，如Ljava.lang.String 对于数组，一个维度对应一个 [， + L + 元素类型，如[[I，[[Ljava.lang.String。 描述符描述方法时，按照先参数列表后返回值的顺序，如()V 、(I)Ljava.lang.String。 access_flags表示访问标志，即字段的修饰符，其取值如下： 方法表集合u2 methods_count;【1】 method_info methods;【methods_count】 分别表示方法数量和方法表。 Class 文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方式。方法表的结构与字段表一样，如下： Java方法里的代码，经Javac编译成字节码之后，放在方法属性表集合中一个名为“Code”的属性里面。 标志位取值： synchronized关键字 的字节码相关： P46 属性表集合12u2 attributes_count;//此类的属性表中的属性数attribute_info attributes[attributes_count];//属性表集合 在 Class 文件，字段表，方法表中都可以携带自己的属性表集合，以用于描述某些场景专有的信息。与 Class 文件中其它的数据项目要求的顺序、长度和内容不同，属性表集合的限制稍微宽松一些，不再要求各个属性表具有严格的顺序，并且只要不与已有的属性名重复，任何人实现的编译器都可以向属性表中写 入自己定义的属性信息，Java 虚拟机运行时会忽略掉它不认识的属性。 一些常见属性1.Code属性 结构： attribute_length表示attribute所包含的字节数，不包含 attribute name index和attribute length字段。 max_stack表示这个方法运行的任何时刻所能达到的操作数栈的最大深度 max_locals表示方法执行期间创建的局部变量的数目，包含用来表示传入的参数的局部变量 2.LineNumberTable属性 用于表示Code中的字节码与源码的行号对应关系（一行对应一个指令） 3.LocalVariableTable 局部变量表，记录局部变量信息，其中的变量名等会引用常量池中的utf8字符串常量。 对于实例方法，在class文件中，每个方法内至少会有一个局部变量：this，即所属对象的引用 To be continue参考 《深入理解JVM》 JavaGuide文档","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"http://example.com/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/Tag/JVM/"}]},{"title":"单例模式","slug":"设计模式/单例模式","date":"2021-03-03T16:01:09.711Z","updated":"2021-03-03T16:00:39.449Z","comments":true,"path":"2021/03/04/设计模式/单例模式/","link":"","permalink":"http://example.com/2021/03/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"概述定义：在当前进程中，通过单例模式创建的类有且只有一个实例。 单例有如下几个特点： 在Java应用中，单例模式需要保证在一个JVM中，该对象只有一个实例存在。 构造器必须是私有的，外部类无法通过调用构造器方法创建该实例。 没有公开的set方法，外部类无法调用set方法创建该实例。 提供一个公开的get方法获取唯一的这个实例。 单例模式的好处： 某些类创建比较频繁，对于一些大型的对象，节省很大的系统开销。 省去了new操作符，降低了系统内存的使用频率，减轻GC压力 系统中某些类，如spring里的controller，控制着处理流程，如果该类可以创建多个，会造成系统混乱。 避免了对资源的重复占用 饿汉式在程序启动或单例模式类被首次主动使用的时候，单例模式实例被创建。总之，饿汉式体现的是想提前把对象创建好。 12345678910public class Singleton &#123; private static Singleton instance = new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return instance; &#125;&#125; 饿汉式没有线程安全问题，instance是在Singleton类初始化时创建的，JVM可以保证线程安全。 懒汉式懒汉式单例在第一次调用getInstance才创建实例。 线程不安全实现123456789101112public class Singleton &#123; private static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(instance==null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 测试： 1234567public static void main(String[] args) throws ClassNotFoundException &#123; for (int i = 0; i &lt; 100; i++) &#123; new Thread(()-&gt;&#123; System.out.println(Singleton2.getInstance()); &#125;).start(); &#125;&#125; 执行多次，可以看到获取对象不是同一个。 应用场景：如果这个数据是经常访问的热点数据，那我就可以在系统启动的时候使用饿汉模式提前加载（类似缓存的预热）这样哪怕是第一个用户调用都不会存在创建开销，而且调用频繁也不存在内存浪费了；反之，数据使用频率较低，则使用懒汉式，避免资源浪费。 线程安全实现getInstance加锁： 123456789101112public class Singleton &#123; private static Singleton instance; private Singleton()&#123;&#125; public static synchronized Singleton getInstance()&#123; if(instance==null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 这样能保证线程安全，但是效率过低，实例被创建后调用getInstance依然需要加锁。 通过双检锁（double-checked）做两次判断优化： 123456789101112131415public final class Singleton &#123; private Singleton() &#123; &#125; private volatile static Singleton INSTANCE = null; public static Singleton getInstance() &#123; if(INSTANCE == null) &#123; // 首次访问会同步，而之后的使用没有 synchronized synchronized(Singleton.class) &#123; if (INSTANCE == null) &#123; INSTANCE = new Singleton(); &#125; &#125; &#125; return INSTANCE; &#125;&#125; 注意INSTANCE需要加上volatile关键字，避免指令重排序问题。INSTANCE = new Singleton();并不是原子操作，JVM可能会先执行赋值操作再执行初始化操作， 没加volatile时线程不安全的情况： A、B同时进入第一个if。 A首先进入synchronized块，由于instance为null，所以它执行instance = new Singleton(); 由于JVM内部的优化机制，JVM可能会先画出了一些分配给Singleton实例的空白内存，并赋值给instance成员（注意此时JVM没有开始初始化这个实例），然后A离开了synchronized块。 随后B进入synchronized块，由于instance此时不是null，因此它马上离开了synchronized块并将结果返回给调用该方法的程序。 此时若B线程马上使用Singleton实例，却发现它没有被初始化，于是错误发生了。 缺点：由于volatile关键字可能会屏蔽掉虚拟机中一些必要的代码优化，所以运行效率并不是很高。 可以使用静态内部类实现。 静态内部类实现12345678910111213141516171819public class Singleton &#123; private Singleton() &#123; &#125; /* 使用一个内部类来维护单例 */ private static class SingletonFactory &#123; private static Singleton instance = new Singleton(); &#125; /* 获取实例 */ public static Singleton getInstance() &#123; return SingletonFactory.instance; &#125; /* 如果该对象被用于序列化，可以保证对象在序列化前后保持一致 */ public Object readResolve() &#123; return getInstance(); &#125; &#125; 使用内部类来维护单例的实现，JVM内部的机制能够保证当一个类被加载的时候，这个类的加载过程是线程互斥的。 枚举实现123public enum Singleton &#123; Instance;&#125; 使用枚举来实现单实例控制会更加简洁，而且JVM从根本上提供保障，绝对防止多次实例化，是更简洁、高效、安全的实现单例的方式。 为什么不用静态方法而用单例模式？（来自参考连接） 两者其实都能实现我们加载的最终目的，但是他们一个是基于对象，一个是面向对象的，就像我们不面向对象也能解决问题一样，面向对象的代码提供一个更好的编程思想。 参考 原文：设计模式系列 - 单例模式","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/Tag/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"UML类图六种关系","slug":"设计模式/UML类图六种关系","date":"2021-03-03T16:01:09.700Z","updated":"2021-03-03T16:00:56.608Z","comments":true,"path":"2021/03/04/设计模式/UML类图六种关系/","link":"","permalink":"http://example.com/2021/03/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/UML%E7%B1%BB%E5%9B%BE%E5%85%AD%E7%A7%8D%E5%85%B3%E7%B3%BB/","excerpt":"","text":"概述UML类图用于描述系统中的类（对象）本身的组成和类（对象）之间的各种静态关系。 类之间的关系有：泛化（继承）、实现、关联、聚合、组合、依赖。 六种关系的耦合度大小是：泛化 = 实现 &gt; 组合 &gt; 聚合 &gt; 关联 &gt; 依赖。 泛化（Generalization）泛化就是指继承关系。 代码体现：子类继承父类。 UML符号：实线+空心箭头，箭头指向父类 如图： 实现（Realization）实现关系即实现类实现接口。 代码体现：A类实现B接口。 UML符号：一条虚线+空心箭头 关联（Association）关联关系指类和类之间的联系，如一对一、一对多、多对多。其中有单向关联，双向关联。 代码体现：成员变量 UML符号：双向关联，一条实线或一条实线+两个箭头；单向关联，一条实线+一个箭头 一对一 其他：（图片来自https://www.zhihu.com/question/419192424/answer/1471808645） 聚合（Aggregation）聚合关系（Aggregation）表示的是整体和部分的关系，整体与部分可以分开，即部分能脱离整体而独立存在。 代码体现：成员变量 UML符号：一条实线+空心菱形 组合（Composition）组合也是整体与部分的关系，但是整体与部分不可以分开，部分不能脱离整体而独立存在。 代码体现：成员变量 UML符号：一条实线+实心菱形 依赖（Dependency）是一种使用关系，一个类的实现需要另一个类的协助。即在一个类中使用了另外一个类。尽量不要使用双向依赖。以上关系都是依赖关系的特例。 代码体现：局部变量、方法的参数或者对静态方法的调用。 UML符号：一条虚线+箭头 参考https://www.cnblogs.com/vic_/p/8057851.html https://www.zhihu.com/question/419192424/answer/1471808645","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/Tag/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"设计模式七大基本原则","slug":"设计模式/设计模式七大基本原则","date":"2021-03-03T16:00:06.237Z","updated":"2021-03-03T15:59:54.574Z","comments":true,"path":"2021/03/04/设计模式/设计模式七大基本原则/","link":"","permalink":"http://example.com/2021/03/04/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B8%83%E5%A4%A7%E5%9F%BA%E6%9C%AC%E5%8E%9F%E5%88%99/","excerpt":"","text":"概述设计模式的七大原则如下： 单一职责原则 (Single Responsibility Principle) 接口隔离原则 (Interface Segregation Principle) 开放-关闭原则 (Open-Closed Principle) 里氏替换原则 (Liskov Substitution Principle) 依赖倒转原则 (Dependence Inversion Principle) 迪米特法则（Law Of Demeter） 组合/聚合复用原则 (Composite/Aggregate Reuse Principle) 单一职责原则（SRP）通俗地说，单一职责原则即一个类只负责一项职责（不是只有一个方法）。 假设某个类 P 负责两个不同的职责：职责 P1 和 职责 P2，那么当职责 P1 需求发生改变而需要修改类 P，有可能会导致原来运行正常的职责 P2 功能发生故障。 在实际编程中比较难严格的遵守该原则，可以作一些折中处理，比如若是一个类中方法个数比较少，可以在方法级别上遵守该原则（此时在类级别上可能不遵守）。只有逻辑足够简单，才可以在代码级别上违背单一职责原则。 单一职责原则的作用和细节： 降低类的复杂度，一个类只负责一项职责。 提高类的可读性，可维护性 降低变更引起的风险 通常情况下，应当遵守单一职责原则，只有逻辑足够简单，才可以在代码级违反单一职责原则；只有类中方法数量足够少，可以在方法级别保持单一职责原则 接口隔离原则（ISP）接口隔离原则指：客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上： 被依赖的类实现一个接口，就需要实现接口的所有方法，但这个类在被使用时可能只用到其中部分方法。也就是只要接口中出现的方法，不管依赖于它的类是否需要该方法，实现类都必须去实现这些方法，这就不符合接口隔离原则。可以对接口进行拆分，让实现类只实现需要的接口。 示例（见来自https://zhuanlan.zhihu.com/p/24614363）： 类 A 依赖于 接口 I 中的方法 1，2，3 ，类 B 是对类 A 的具体实现。类 C 依赖接口 I 中的方法 1，4，5，类 D 是对类 C 的具体实现。对于类B和类D来说，虽然他们都存在着用不到的方法（也就是图中红色字体标记的方法），但由于实现了接口I，所以也必须要实现这些用不到的方法。 用代码表示: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576interface I &#123; public void method1(); public void method2(); public void method3(); public void method4(); public void method5(); &#125; class A&#123; public void depend1(I i)&#123; i.method1(); &#125; public void depend2(I i)&#123; i.method2(); &#125; public void depend3(I i)&#123; i.method3(); &#125; &#125; class B implements I&#123; // 类 B 只需要实现方法 1，2, 3，而其它方法它并不需要，但是也需要实现 public void method1() &#123; System.out.println(&quot;类 B 实现接口 I 的方法 1&quot;); &#125; public void method2() &#123; System.out.println(&quot;类 B 实现接口 I 的方法 2&quot;); &#125; public void method3() &#123; System.out.println(&quot;类 B 实现接口 I 的方法 3&quot;); &#125; public void method4() &#123;&#125; public void method5() &#123;&#125; &#125; class C&#123; public void depend1(I i)&#123; i.method1(); &#125; public void depend2(I i)&#123; i.method4(); &#125; public void depend3(I i)&#123; i.method5(); &#125; &#125; class D implements I&#123; // 类 D 只需要实现方法 1，4，5，而其它方法它并不需要，但是也需要实现 public void method1() &#123; System.out.println(&quot;类 D 实现接口 I 的方法 1&quot;); &#125; public void method2() &#123;&#125; public void method3() &#123;&#125; public void method4() &#123; System.out.println(&quot;类 D 实现接口 I 的方法 4&quot;); &#125; public void method5() &#123; System.out.println(&quot;类 D 实现接口 I 的方法 5&quot;); &#125; &#125; public class Client&#123; public static void main(String[] args)&#123; A a = new A(); a.depend1(new B()); a.depend2(new B()); a.depend3(new B()); C c = new C(); c.depend1(new D()); c.depend2(new D()); c.depend3(new D()); &#125; &#125; 可以对接口根据下图进行拆分： 代码可修改为如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061interface I1 &#123; public void method1(); &#125; interface I2 &#123; public void method2(); public void method3(); &#125; interface I3 &#123; public void method4(); public void method5(); &#125; class A&#123; public void depend1(I1 i)&#123; i.method1(); &#125; public void depend2(I2 i)&#123; i.method2(); &#125; public void depend3(I2 i)&#123; i.method3(); &#125; &#125; class B implements I1, I2&#123; public void method1() &#123; System.out.println(&quot;类 B 实现接口 I1 的方法 1&quot;); &#125; public void method2() &#123; System.out.println(&quot;类 B 实现接口 I2 的方法 2&quot;); &#125; public void method3() &#123; System.out.println(&quot;类 B 实现接口 I2 的方法 3&quot;); &#125; &#125; class C&#123; public void depend1(I1 i)&#123; i.method1(); &#125; public void depend2(I3 i)&#123; i.method4(); &#125; public void depend3(I3 i)&#123; i.method5(); &#125; &#125; class D implements I1, I3&#123; public void method1() &#123; System.out.println(&quot;类 D 实现接口 I1 的方法 1&quot;); &#125; public void method4() &#123; System.out.println(&quot;类 D 实现接口 I3 的方法 4&quot;); &#125; public void method5() &#123; System.out.println(&quot;类 D 实现接口 I3 的方法 5&quot;); &#125; &#125; 总结： 接口隔离原则的思想在于建立单一接口，尽可能地去细化接口，接口中的方法尽可能少。 但是凡事都要有个度，如果接口设计过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。 依赖倒转原则（DIP）定义：高层模块不应该依赖低层模块，二者都应该依赖于抽象。进一步说，抽象不应该依赖于细节，细节应该依赖于抽象。依赖倒转原则的核心思想就是面向接口编程。 依赖倒转原则是基于这样的设计理念：相对于细节的多变性，抽象的东西要稳定的多。以抽象为基础搭建的架构比以细节为基础的架构要稳定的多。使用接口或抽象类的目的是制定好规范，而不涉及任何具体的操作，把展现细节的任务交给实现类去完成。 示例：（来自https://zhuanlan.zhihu.com/p/24614363） 一个场景：母亲给孩子讲故事，只要给她一本书，她就可照着书给孩子讲故事了。代码如下： 12345678910111213141516171819class Book&#123; public String getContent()&#123; return &quot;这是一个有趣的故事&quot;; &#125; &#125; class Mother&#123; public void say(Book book)&#123; System.out.println(&quot;妈妈开始讲故事&quot;); System.out.println(book.getContent()); &#125; &#125; public class Client&#123; public static void main(String[] args)&#123; Mother mother = new Mother(); mother.say(new Book()); &#125; &#125; 假如有一天，给的是一份报纸，而不是一本书，让这个母亲讲下报纸上的故事，报纸的代码如下： 12345class Newspaper&#123; public String getContent()&#123; return &quot;这个一则重要的新闻&quot;; &#125; &#125; 显然这个母亲完成不了这个任务。只有将Mother类中的Book换成Newspaper才能完成。但若是以后换成杂志等其他读物，又得进行修改。原因是 Mother 和 Book之间的耦合度太高了。可以引入一个抽象接口 IReader表示读物，让书和报纸去实现这个接口，那么无论提供什么样的读物，该母亲都能读。 代码如下： 1234567891011121314151617181920212223242526272829interface IReader&#123; public String getContent(); &#125; class Newspaper implements IReader &#123; public String getContent()&#123; return &quot;这个一则重要的新闻&quot;; &#125; &#125; class Book implements IReader&#123; public String getContent()&#123; return &quot;这是一个有趣的故事&quot;; &#125; &#125; class Mother&#123; public void say(IReader reader)&#123; System.out.println(&quot;妈妈开始讲故事&quot;); System.out.println(reader.getContent()); &#125; &#125; public class Client&#123; public static void main(String[] args)&#123; Mother mother = new Mother(); mother.say(new Book()); mother.say(new Newspaper()); &#125; &#125; 在这个例子中，Mother类代表高层模块，读物相关的类则代表低层模块，在修改示例之前，是高层依赖于低层代码，Mother类要按着Book类来；修改后则符合依赖倒转原则，低层的读物依着高层的Mother来。 实际情况中，代表高层模块的 Mother 类将负责完成主要的业务逻辑，一旦需要对它进行修改，引入错误的风险极大。所以遵循依赖倒转原则可以降低类之间的耦合性，提高系统的稳定性，降低修改程序造成的风险。 里氏替换原则（LSP）面向对象中继承性的问题：有一功能 P1, 由类 A 完成，现需要将功能 P1 进行扩展，扩展后的功能为 P，其中P由原有功能P1与新功能P2组成。新功能P由类A的子类B来完成，则子类B在完成新功能P2的同时，有可能会导致原有功能P1发生故障。 里氏替换原则： 所有引用基类的地方必须能透明地使用其子类的对象。 里氏替换原则的重点在不影响原功能，而不是不覆盖原方法。 子类中尽量不要重写父类的方法。 继承包含这样一层含义：父类中凡是已经实现好的方法（相对于抽象方法而言），实际上是在设定一系列的规范和契约，虽然它不强制要求所有的子类必须遵从这些契约，但是如果子类对这些非抽象方法任意修改，就会对整个继承体系造成破坏。而里氏替换原则就是表达了这一层含义。 根据该原则，对于上述的继承性问题：当使用继承时候，类 B 继承类 A 时，除添加新的方法完成新增功能 P2，尽量不要修改父类方法预期的行为。 开放-关闭原则（OCP）**开放-关闭原则表示软件实体 (类、模块、函数等等) 应该是可以被扩展的，但是不可被修改。(Open for extension, close for modification，对扩展开放，对修改关闭)**。 一个软件满足 OCP 原则后的两项优点： 能够扩展已存在的系统，能够提供新的功能满足新的需求，因此该软件有着很强的适应性和灵活性。 已存在的模块，特别是那些重要的抽象模块，不需要被修改，那么该软件就有很强的稳定性和持久性。 示例： 有个生产电脑的公司，根据输入的类型，生产出不同的电脑，代码如下: 1234567891011121314interface Computer &#123;&#125;class Macbook implements Computer &#123;&#125;class Surface implements Computer &#123;&#125;class Factory &#123; public Computer produceComputer(String type) &#123; Computer c = null; if(type.equals(&quot;macbook&quot;))&#123; c = new Macbook(); &#125;else if(type.equals(&quot;surface&quot;))&#123; c = new Surface(); &#125; return c; &#125; &#125; 显然上面的代码违背了开放 - 关闭原则，如果需要添加新的电脑产品，需要修改 produceComputer 原本已有的方法，正确的方式如下： 12345678910111213141516interface Computer &#123;&#125;class Macbook implements Computer &#123;&#125;class Surface implements Computer &#123;&#125;interface Factory &#123; public Computer produceComputer();&#125;class AppleFactory implements Factory &#123; public Computer produceComputer() &#123; return new Macbook(); &#125;&#125;class MSFactory implements Factory &#123; public Computer produceComputer() &#123; return new Surface(); &#125;&#125; 正确的方式应该是将 Factory 抽象成接口，让具体的工厂(如苹果工厂，微软工厂)去实现它，生产它们公司相应的产品，这样写有利于扩展，如果这是需要新增加戴尔工厂生产戴尔电脑，我们仅仅需要创建新的电脑类和新的工厂类，而不需要去修改已经写好的代码。 总结： OCP 可以具有良好的可扩展性，可维护性。 不可能让一个系统的所有模块都满足 OCP 原则，我们能做到的是尽可能地不要修改已经写好的代码，已有的功能，而是去扩展它。 迪米特法则（LOD）迪米特法则又称为最少知道原则，它表示一个对象应该对其它对象保持最少的了解。**通俗来说就是，只与直接的朋友通信**。 什么是直接的朋友：每个对象都会与其他对象有耦合关系，只要两个对象之间有耦合关系，我们就说这两个对象之间是朋友关系。耦合的方式很多，依赖、关联、组合、聚合等。其中，称出现在成员变量、方法参数、方法返回值中的类为直接的朋友，而出现在局部变量中的类则不是直接的朋友。根据迪米特法则，**陌生的类最好不要作为局部变量的形式出现在类的内部**。 对于被依赖的类来说，无论逻辑多么复杂，都尽量的将逻辑封装在类的内部，对外提供 public 方法，不对泄漏任何信息。 示例： 客户端： 12345678public class Demeter1 &#123; public static void main(String[] args) &#123; //创建了一个 SchoolManager 对象 SchoolManager schoolManager = new SchoolManager(); //输出学院员工id和学校员工id schoolManager.printAllEmployee(new CollegeManager()); &#125; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667//学校员工类 class Employee &#123; private String id; public void setId(String id) &#123; this.id = id; &#125; public String getId() &#123; return id; &#125; &#125;//学院员工类 class CollegeEmployee &#123; private String id; public void setId(String id) &#123; this.id = id; &#125; public String getId() &#123; return id; &#125; &#125;//学院员工管理类 class CollegeManager &#123; //返回学院的所有员工 public List&lt;CollegeEmployee&gt; getAllEmployee() &#123; List&lt;CollegeEmployee&gt; list = newArrayList&lt;CollegeEmployee&gt;(); for (int i = 0; i &lt; 10; i++) &#123; //这里我们增加了 10 个员工到 list CollegeEmployee emp = new CollegeEmployee(); emp.setId(&quot;学院员工 id= &quot; + i); list.add(emp); &#125; return list; &#125;&#125;//学校管理类class SchoolManager &#123; //返回所有学校员工 public List&lt;Employee&gt; getAllEmployee() &#123; List&lt;Employee&gt; list = newArrayList&lt;Employee&gt;(); for (int i = 0; i &lt; 5; i++) &#123; list Employee emp = new Employee(); emp.setId(&quot;学校总部员工 id= &quot; + i); list.add(emp); &#125; return list; &#125; //输出学校和学院员工id public void printAllEmployee(CollegeManager sub) &#123; //获取到学院员工 List&lt;CollegeEmployee&gt; list1 = sub.getAllEmployee(); System.out.println(&quot;------------学院员工------------&quot;); for (CollegeEmployee e : list1) &#123; System.out.println(e.getId()); &#125; //获取到学校总部员工 List&lt;Employee&gt; list2 = this.getAllEmployee(); System.out.println(&quot;------------学校总部员工------------&quot;); for (Employee e : list2) &#123; System.out.println(e.getId()); &#125; &#125;&#125; 可以看到SchoolManager的printAllEmployee方法中，CollegeEmployee并不是SchoolManager的直接朋友，不符合迪米特法则。 可以将打印CollegeEmployee部分的代码封装进CollegeManager中： CollegeManager中添加新的public方法 12345678public void printEmployee() &#123; //获取到学院员工 List&lt;CollegeEmployee&gt; list1 = getAllEmployee(); System.out.println(&quot;------------学院员工------------&quot;); for (CollegeEmployee e : list1) &#123; System.out.println(e.getId()); &#125; &#125; 从而可以在SchoolManager中通过CollegeManager调用该方法来打印所有学院员工id，SchoolManager.printAllEmployee方法改为： 1234567891011//输出学校和学院员工idpublic void printAllEmployee(CollegeManager sub) &#123; sub.printEmployee(); //获取到学校总部员工 List&lt;Employee&gt; list2 = this.getAllEmployee(); System.out.println(&quot;------------学校总部员工------------&quot;); for (Employee e : list2) &#123; System.out.println(e.getId()); &#125;&#125; 组合/聚合复用原则（CRP）组合/聚合复用原则指的是在实际开发设计中，尽量使用组合/聚合，不要使用类继承。 在面向对象的设计中，如果直接继承基类，会破坏封装，因为继承将基类的实现细节暴露给子类，如果基类的实现发生了改变，则子类的实现也不得不改变。 总体说来，组合或者聚合好过于继承。 聚合组合是一种 “黑箱” 复用，因为细节对象的内容对客户端来说是不可见的。 参考 https://zhuanlan.zhihu.com/p/24614363 https://www.bilibili.com/video/BV1G4411c7N4","categories":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/Tag/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"IDEA快捷键大全","slug":"IDEA快捷键大全","date":"2021-02-24T16:26:06.369Z","updated":"2021-02-24T16:28:01.532Z","comments":true,"path":"2021/02/25/IDEA快捷键大全/","link":"","permalink":"http://example.com/2021/02/25/IDEA%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%A4%A7%E5%85%A8/","excerpt":"","text":"以下绝大部分copy自：https://blog.csdn.net/qq_38963960/article/details/89552704 Ctrl 快捷键 介绍 Ctrl + F 在当前文件进行文本查找 （必备） Ctrl + R 在当前文件进行文本替换 （必备） Ctrl + Z 撤销 （必备） Ctrl + Y 删除光标所在行 或 删除选中的行 （必备） Ctrl + X 剪切光标所在行 或 剪切选择内容 Ctrl + C 复制光标所在行 或 复制选择内容 Ctrl + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 （必备） Ctrl + W 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 （必备） Ctrl + E 显示最近打开的文件记录列表 Ctrl + N 根据输入的 类名 查找类文件 Ctrl + G 在当前文件跳转到指定行处 Ctrl + J 插入自定义动态代码模板 Ctrl + P 方法参数提示显示 Ctrl + Q 光标所在的变量 / 类名 / 方法名等上面（也可以在提示补充的时候按），显示文档内容 Ctrl + U 前往当前光标所在的方法的父类的方法 / 接口定义 Ctrl + B 进入光标所在的方法/变量的接口或是定义出，等效于 Ctrl + 左键单击 Ctrl + K 版本控制提交项目，需要此项目有加入到版本控制才可用 Ctrl + T 版本控制更新项目，需要此项目有加入到版本控制才可用 Ctrl + H 显示当前类的层次结构 Ctrl + O 选择可重写的方法 Ctrl + I 选择可继承的方法 Ctrl + + 展开代码 Ctrl + - 折叠代码 Ctrl + / 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 （必备） Ctrl + [ 移动光标到当前所在代码的花括号开始位置 Ctrl + ] 移动光标到当前所在代码的花括号结束位置 Ctrl + F1 在光标所在的错误代码出显示错误信息 Ctrl + F3 调转到所选中的词的下一个引用位置 Ctrl + F4 关闭当前编辑文件 Ctrl + F8 在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点 Ctrl + F9 执行 Make Project 操作 Ctrl + F11 选中文件 / 文件夹，使用助记符设定 / 取消书签 Ctrl + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选 Ctrl + Tab 编辑窗口切换，如果在切换的过程又加按上delete，则是关闭对应选中的窗口 Ctrl + Enter 智能分隔行 Ctrl + End 跳到文件尾 Ctrl + Home 跳到文件头 Ctrl + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl + 逗号 （必备） Ctrl + Delete 删除光标后面的单词或是中文句 Ctrl + BackSpace 删除光标前面的单词或是中文句 Ctrl + 1,2,3…9 定位到对应数值的书签位置 Ctrl + 左键单击 在打开的文件标题上，弹出该文件路径 Ctrl + 光标定位 按 Ctrl 不要松开，会显示光标所在的类信息摘要 Ctrl + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 Ctrl + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 Ctrl + 前方向键 等效于鼠标滚轮向前效果 Ctrl + 后方向键 等效于鼠标滚轮向后效果 Alt 快捷键 介绍 Alt + ` 显示版本控制常用操作菜单弹出层 Alt + Q 弹出一个提示，显示当前类的声明 / 上下文信息 Alt + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 Alt + F2 对于前面页面，显示各类浏览器打开目标选择弹出层 Alt + F3 选中文本，逐个往下查找相同文本，并高亮显示 Alt + F7 查找光标所在的方法 / 变量 / 类被调用的地方 Alt + F8 在 Debug 的状态下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果 Alt + Home 定位 / 显示到当前文件的 Navigation Bar Alt + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同 （必备） Alt + Insert 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 Alt + 左方向键 按左方向切换当前已打开的文件视图 Alt + 右方向键 按右方向切换当前已打开的文件视图 Alt + 前方向键 当前光标跳转到当前文件的前一个方法名位置 Alt + 后方向键 当前光标跳转到当前文件的后一个方法名位置 Alt + 1,2,3…9 显示对应数值的选项卡，其中 1 是 Project 用得最多 Shift 快捷键 介绍 Shift + F1 如果有外部文档可以连接外部文档 Shift + F2 跳转到上一个高亮错误 或 警告位置 Shift + F3 在查找模式下，查找匹配上一个 Shift + F4 对当前打开的文件，使用新Windows窗口打开，旧窗口保留 Shift + F6 对文件 / 文件夹 重命名 Shift + F7 在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法 Shift + F8 在 Debug 模式下，跳出，表现出来的效果跟 F9 一样 Shift + F9 等效于点击工具栏的 Debug 按钮 Shift + F10 等效于点击工具栏的 Run 按钮 Shift + F11 弹出书签显示层 Shift + Tab 取消缩进 Shift + ESC 隐藏当前 或 最后一个激活的工具窗口 Shift + End 选中光标到当前行尾位置 Shift + Home 选中光标到当前行头位置 Shift + Enter 在当前行的下一行另起新行 Shift+Alt+Enter 在当前行的上一行另起新行 Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 Shift + 滚轮前后滚动 当前文件的横向滚动轴滚动 Ctrl + Alt 快捷键 介绍 Ctrl + Alt + L 格式化代码，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + O 优化导入的类，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + I 光标所在行 或 选中部分进行自动代码缩进，有点类似格式化 Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 Ctrl + Alt + J 弹出模板选择窗口，讲选定的代码加入动态模板中 Ctrl + Alt + H 调用层次 Ctrl + Alt + B 在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 Ctrl + Alt + V 快速引进变量 Ctrl + Alt + Y 同步、刷新 Ctrl + Alt + S 打开 IntelliJ IDEA 系统设置 Ctrl + Alt + F7 显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来 Ctrl + Alt + F11 切换全屏模式 Ctrl + Alt + Enter 光标所在行上空出一行，光标定位到新行 Ctrl + Alt + Home 弹出跟当前文件有关联的文件弹出层 Ctrl + Alt + Space 类名自动完成 Ctrl + Alt + 左方向键 退回到上一个操作的地方 （必备）**（注意与其他软件快捷键冲突）** Ctrl + Alt + 右方向键 前进到上一个操作的地方 （必备）**（注意与其他软件快捷键冲突）** Ctrl + Alt + 前方向键 在查找模式下，跳到上个查找的文件 Ctrl + Alt + 后方向键 在查找模式下，跳到下个查找的文件 Ctrl + Shift 快捷键 介绍 Ctrl + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 （必备） Ctrl + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 （必备） Ctrl + Shift + J 自动将下一行合并到当前行末尾 （必备） Ctrl + Shift + Z 取消撤销 （必备） Ctrl + Shift + W 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 （必备） Ctrl + Shift + N 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 （必备） Ctrl + Shift + U 对选中的代码进行大 / 小写轮流转换 （必备） Ctrl + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 Ctrl + Shift + C 复制当前文件磁盘路径到剪贴板 Ctrl + Shift + V 弹出缓存的最近拷贝的内容管理器弹出层 Ctrl + Shift + E 显示最近修改的文件列表的弹出层 Ctrl + Shift + H 显示方法层次结构 Ctrl + Shift + B 跳转到类型声明处 Ctrl + Shift + I 快速查看光标所在的方法 或 类的定义 Ctrl + Shift + A 查找动作 / 设置 Ctrl + Shift + / 代码块注释 （必备） Ctrl + Shift + [ 选中从光标所在位置到它的顶部中括号位置 Ctrl + Shift + ] 选中从光标所在位置到它的底部中括号位置 Ctrl + Shift + + 展开所有代码 Ctrl + Shift + - 折叠所有代码 Ctrl + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失 Ctrl + Shift + F8 在 Debug 模式下，指定断点进入条件 Ctrl + Shift + F9 编译选中的文件 / 包 / Module Ctrl + Shift + F12 编辑器最大化 Ctrl + Shift + Space 智能代码提示 Ctrl + Shift + Enter 自动结束代码，行末自动添加分号 （必备） Ctrl + Shift + Backspace 退回到上次修改的地方 Ctrl + Shift + 1,2,3…9 快速添加指定数值的书签 Ctrl + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句 Ctrl + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句 Ctrl + Shift + 左方向键 在光标焦点是在工具选项卡上，缩小选项卡区域 Ctrl + Shift + 右方向键 在光标焦点是在工具选项卡上，扩大选项卡区域 Ctrl + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 Ctrl + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 Alt + Shift 快捷键 介绍 Alt + Shift + N 选择 / 添加 task Alt + Shift + F 显示添加到收藏夹弹出层 Alt + Shift + C 查看最近操作项目的变化情况列表 Alt + Shift + F 添加到收藏夹 Alt + Shift + I 查看项目当前文件 Alt + Shift + F7 在 Debug 模式下，下一步，进入当前方法体内，如果方法体还有方法，则会进入该内嵌的方法中，依此循环进入 Alt + Shift + F9 弹出 Debug 的可选择菜单 Alt + Shift + F10 弹出 Run 的可选择菜单 Alt + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 Alt + Shift + 前方向键 移动光标所在行向上移动 Alt + Shift + 后方向键 移动光标所在行向下移动 Ctrl + Shift + Alt 快捷键 介绍 Ctrl + Shift + Alt + V 无格式黏贴 Ctrl + Shift + Alt + N 前往指定的变量 / 方法 Ctrl + Shift + Alt + S 打开当前项目设置 Ctrl + Shift + Alt + C 复制参考信息 其他 快捷键 介绍 F2 跳转到下一个高亮错误 或 警告位置 （必备） F3 在查找模式下，定位到下一个匹配处 F4 编辑源 F7 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 F8 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F9 在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上 F11 添加书签 F12 回到前一个工具窗口 Tab 缩进 ESC 从工具窗口进入代码文件窗口 连按两次Shift 弹出 Search Everywhere 弹出层","categories":[{"name":"IDEA","slug":"IDEA","permalink":"http://example.com/categories/IDEA/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"http://example.com/Tag/IDEA/"}]},{"title":"IDEA常用快捷键&操作","slug":"idea常用","date":"2021-02-24T16:26:06.368Z","updated":"2021-03-05T16:17:23.700Z","comments":true,"path":"2021/02/25/idea常用/","link":"","permalink":"http://example.com/2021/02/25/idea%E5%B8%B8%E7%94%A8/","excerpt":"","text":"&emsp;&emsp; ctrl+w：逐渐向外层选中 CTRL+shift+上下：当前行上下移 SHIFT+F10：运行main CTRL+F2：停止运行 shift+esc：关闭下方窗口 CTRL+shift+左右：跳转至上/下一个方法（上/下一个历史光标位置） CTRL+F12：弹出窗口形式查看当前类的所有方法 Alt+7：左边小窗口查看当前类所有方法 SHIFT + F2：定位到报错处（红线） CTRL + R：替换指定文本。 SHIFT + F6：批量修改变量、方法名。 CTRL + ALT + V：抽取变量（已改为ALT + X） CTRL + ALT + B/左键：方法具体实现 CTRL + ALT + M：将选中代码提取为方法 CTRL + ALT + P：抽取为方法参数，并修改方法被引用的地方 ALT + 1：打开Project 窗口。 CTRL + E：最近文件窗口。 CTRL + P：方法、构造器参数提示。 ALT + F7：查看指定方法/变量等被引用的次数和位置。 &emsp;&emsp; debug时，下方的Frames窗口对应虚拟机栈，其中每个项就是一个栈帧（对应一个方法），右边的Variables对应该栈帧的局部变量表。 多个线程下调试时，右键断电，选择Thread 此时在此时选择线程： debug过程可以修改变量的值：","categories":[{"name":"IDEA","slug":"IDEA","permalink":"http://example.com/categories/IDEA/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"http://example.com/Tag/IDEA/"}]},{"title":"IDEA的一些使用技巧","slug":"IDEA使用技巧","date":"2021-02-24T16:23:26.053Z","updated":"2021-02-24T16:27:24.326Z","comments":true,"path":"2021/02/25/IDEA使用技巧/","link":"","permalink":"http://example.com/2021/02/25/IDEA%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/","excerpt":"","text":"该笔记基于IDEA-2019版本 提高运行速度在idea安装目录的bin目录下的idea.exe.vmoptions文件，调整Xms跟Xmx两个参数的值可提高运行速度，但要注意电脑的运行内存是否足够。 恢复默认设置在用户目录中，有一个.IntelliJIdea2019.3目录，该目录下有个config跟一个system目录，前者存放关于IDEA一些设置相关的配置文件。可以通过将这两个目录删除来实现恢复默认设置（在重启idea时会自动创建这两个文件，但之前设置的快捷键、模板等将被重置）。 工具条【View】-》【Appearance】-》【选中Tool Bar】，打开工具条。 IDEA中的Project和Module参考链接： https://blog.csdn.net/qq_35246620/article/details/65448689 在 IntelliJ IDEA 中Project是最顶级的结构单元，然后就是Module，一个Project可以有多个Module。 一个Project是由一个或多个Module组成， 当为单Module项目的时候，这个单独的Module实际上就是一个Project； 当为多Module项目的时候，多个模块处于同一个Project之中，此时彼此之间具有互相依赖的关联关系。 此外， IntelliJ IDEA 的Project是一个不具备任何编码设置、构建等开发功能的概念，其主要作用就是起到一个项目定义、范围约束、规范类型的效果，这个目录在命名上应该有其代表性的意义。在缺省情况下，IntelliJ IDEA 是默认单Project单Module的，这时Project和Module合二为一。 要删除Module时，需要进入Project Structure，在左边选择Modules，右边视图中选中要删除的Module，点击上方的-（或右键delete）即可。此时在项目中移除了对应Module，但在磁盘中没有删除Module对应目录，需手动删除。 在一个Module中，可以通过在本Module的imi文件中配置引入其他Module的内容。可以使用Alt+Enter的提示功能自动配置。 一些设置鼠标悬停显示文档【Settings】-》【Editor】-》【General】-》【视图右边滑到最下面，勾上show quik documentation on mouse move】 下方的Tooltip delay设置延迟时间。 自动导包 显示方法间的分隔符 忽略大小写提示的差别如图取消勾选即可。 效果：输入S跟s的提示将变的一样。 多个文件的标签多行显示打开多个文件时，让多个文件的标签分成多行显示。如图，取消勾选。 设置代码编辑区各部分样式设置如单行注释、多行注释、方法等字体的样式。在框框内点击不同位置可自动跳转到对应的设置。 当导入同一个包的类超过多少时使用* 设置类的头部信息 设置编码（全局） 设置自动编译也可同时勾上框框第二项，启动多模块并行编译。但会占用更多内存。 多个代码文件垂直/水平显示右键标签页，如图： 效果： CTRL+/ 插入注释时带缩进设置Java文件： XML文件同理： 参考：https://blog.csdn.net/VariatioZbw/article/details/105626147 为main方法传递参数 参考：https://blog.csdn.net/u013713294/article/details/53020293 有时需要使用main方法的args参数，而为args参数赋值一般在命令行中，如下： 12javac Test.java //编译java Test param1 param2 param3 ... //运行Test类，param是传递给main方法的参数 在idea中可以设置参数，在main方法运行时把这些参数传递给它，步骤如下： 或 点击OK，运行main方法时即会传入设置的参数。 快捷键 查看/修改快捷键： 快捷键大全： 以下大部分来自：https://blog.csdn.net/qq_38963960/article/details/89552704 Ctrl 快捷键 介绍 Ctrl + F 在当前文件进行文本查找 （必备） Ctrl + R 在当前文件进行文本替换 （必备） Ctrl + Z 撤销 （必备） Ctrl + Y 删除光标所在行 或 删除选中的行 （必备） Ctrl + X 剪切光标所在行 或 剪切选择内容 Ctrl + C 复制光标所在行 或 复制选择内容 Ctrl + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 （必备） Ctrl + W 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 （必备） Ctrl + E 显示最近打开的文件记录列表 Ctrl + N 根据输入的 类名 查找类文件 Ctrl + G 在当前文件跳转到指定行处 Ctrl + J 插入自定义动态代码模板 Ctrl + P 方法参数提示显示 Ctrl + Q 光标所在的变量 / 类名 / 方法名等上面（也可以在提示补充的时候按），显示文档内容 Ctrl + U 前往当前光标所在的方法的父类的方法 / 接口定义 Ctrl + B 进入光标所在的方法/变量的接口或是定义出，等效于 Ctrl + 左键单击 Ctrl + K 版本控制提交项目，需要此项目有加入到版本控制才可用 Ctrl + T 版本控制更新项目，需要此项目有加入到版本控制才可用 Ctrl + H 显示当前类的层次结构 Ctrl + O 选择可重写的方法 Ctrl + I 选择可继承的方法 Ctrl + + 展开代码 Ctrl + - 折叠代码 Ctrl + / 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 （必备） Ctrl + [ 移动光标到当前所在代码的花括号开始位置 Ctrl + ] 移动光标到当前所在代码的花括号结束位置 Ctrl + F1 在光标所在的错误代码出显示错误信息 Ctrl + F3 调转到所选中的词的下一个引用位置 Ctrl + F4 关闭当前编辑文件 Ctrl + F8 在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点 Ctrl + F9 执行 Make Project 操作 Ctrl + F11 选中文件 / 文件夹，使用助记符设定 / 取消书签 Ctrl + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选 Ctrl + Tab 编辑窗口切换，如果在切换的过程又加按上delete，则是关闭对应选中的窗口 Ctrl + Enter 智能分隔行 Ctrl + End 跳到文件尾 Ctrl + Home 跳到文件头 Ctrl + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl + 逗号 （必备） Ctrl + Delete 删除光标后面的单词或是中文句 Ctrl + BackSpace 删除光标前面的单词或是中文句 Ctrl + 1,2,3…9 定位到对应数值的书签位置 Ctrl + 左键单击 在打开的文件标题上，弹出该文件路径 Ctrl + 光标定位 按 Ctrl 不要松开，会显示光标所在的类信息摘要 Ctrl + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 Ctrl + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 Ctrl + 前方向键 等效于鼠标滚轮向前效果 Ctrl + 后方向键 等效于鼠标滚轮向后效果 Alt 快捷键 介绍 Alt + ` 显示版本控制常用操作菜单弹出层 Alt + Q 弹出一个提示，显示当前类的声明 / 上下文信息 Alt + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 Alt + F2 对于前面页面，显示各类浏览器打开目标选择弹出层 Alt + F3 选中文本，逐个往下查找相同文本，并高亮显示 Alt + F7 查找光标所在的方法 / 变量 / 类被调用的地方 Alt + F8 在 Debug 的状态下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果 Alt + Home 定位 / 显示到当前文件的 Navigation Bar Alt + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同 （必备） Alt + Insert 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 Alt + 左方向键 按左方向切换当前已打开的文件视图 Alt + 右方向键 按右方向切换当前已打开的文件视图 Alt + 前方向键 当前光标跳转到当前文件的前一个方法名位置 Alt + 后方向键 当前光标跳转到当前文件的后一个方法名位置 Alt + 1,2,3…9 显示对应数值的选项卡，其中 1 是 Project 用得最多 Alt + 7 显示当前类的所有方法、成员变量等 Shift 快捷键 介绍 Shift + F1 如果有外部文档可以连接外部文档 Shift + F2 跳转到上一个高亮错误 或 警告位置 Shift + F3 在查找模式下，查找匹配上一个 Shift + F4 对当前打开的文件，使用新Windows窗口打开，旧窗口保留 Shift + F6 对文件 / 文件夹 重命名 Shift + F7 在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法 Shift + F8 在 Debug 模式下，跳出，表现出来的效果跟 F9 一样 Shift + F9 等效于点击工具栏的 Debug 按钮 Shift + F10 等效于点击工具栏的 Run 按钮 Shift + F11 弹出书签显示层 Shift + Tab 取消缩进 Shift + ESC 隐藏当前 或 最后一个激活的工具窗口 Shift + End 选中光标到当前行尾位置 Shift + Home 选中光标到当前行头位置 Shift + Enter 在当前行的下一行另起新行 Shift+Alt+Enter 在当前行的上一行另起新行 Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 Shift + 滚轮前后滚动 当前文件的横向滚动轴滚动 Ctrl + Alt 快捷键 介绍 Ctrl + Alt + L 格式化代码，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + O 优化导入的类，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + I 光标所在行 或 选中部分进行自动代码缩进，有点类似格式化 Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 Ctrl + Alt + J 弹出模板选择窗口，讲选定的代码加入动态模板中 Ctrl + Alt + H 调用层次 Ctrl + Alt + B 在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 Ctrl + Alt + V 快速引进变量 Ctrl + Alt + Y 同步、刷新 Ctrl + Alt + S 打开 IntelliJ IDEA 系统设置 Ctrl + Alt + F7 显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来 Ctrl + Alt + F11 切换全屏模式 Ctrl + Alt + Enter 光标所在行上空出一行，光标定位到新行 Ctrl + Alt + Home 弹出跟当前文件有关联的文件弹出层 Ctrl + Alt + Space 类名自动完成 Ctrl + Alt + 左方向键 退回到上一个操作的地方 （必备）**（注意与其他软件快捷键冲突）** Ctrl + Alt + 右方向键 前进到上一个操作的地方 （必备）**（注意与其他软件快捷键冲突）** Ctrl + Alt + 前方向键 在查找模式下，跳到上个查找的文件 Ctrl + Alt + 后方向键 在查找模式下，跳到下个查找的文件 Ctrl + Shift 快捷键 介绍 Ctrl + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 （必备） Ctrl + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 （必备） Ctrl + Shift + J 自动将下一行合并到当前行末尾 （必备） Ctrl + Shift + Z 取消撤销 （必备） Ctrl + Shift + W 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 （必备） Ctrl + Shift + N 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 （必备） Ctrl + Shift + U 对选中的代码进行大 / 小写轮流转换 （必备） Ctrl + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 Ctrl + Shift + C 复制当前文件磁盘路径到剪贴板 Ctrl + Shift + V 弹出缓存的最近拷贝的内容管理器弹出层 Ctrl + Shift + E 显示最近修改的文件列表的弹出层 Ctrl + Shift + H 显示方法层次结构 Ctrl + Shift + B 跳转到类型声明处 Ctrl + Shift + I 快速查看光标所在的方法 或 类的定义 Ctrl + Shift + A 查找动作 / 设置 Ctrl + Shift + / 代码块注释 （必备） Ctrl + Shift + [ 选中从光标所在位置到它的顶部中括号位置 Ctrl + Shift + ] 选中从光标所在位置到它的底部中括号位置 Ctrl + Shift + + 展开所有代码 Ctrl + Shift + - 折叠所有代码 Ctrl + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失 Ctrl + Shift + F8 在 Debug 模式下，指定断点进入条件 Ctrl + Shift + F9 编译选中的文件 / 包 / Module Ctrl + Shift + F12 编辑器最大化 Ctrl + Shift + Space 智能代码提示 Ctrl + Shift + Enter 自动结束代码，行末自动添加分号 （必备） Ctrl + Shift + Backspace 退回到上次修改的地方 Ctrl + Shift + 1,2,3…9 快速添加指定数值的书签 Ctrl + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句 Ctrl + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句 Ctrl + Shift + 左方向键 在光标焦点是在工具选项卡上，缩小选项卡区域 Ctrl + Shift + 右方向键 在光标焦点是在工具选项卡上，扩大选项卡区域 Ctrl + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 Ctrl + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 Alt + Shift 快捷键 介绍 Alt + Shift + N 选择 / 添加 task Alt + Shift + F 显示添加到收藏夹弹出层 Alt + Shift + C 查看最近操作项目的变化情况列表 Alt + Shift + F 添加到收藏夹 Alt + Shift + I 查看项目当前文件 Alt + Shift + F7 在 Debug 模式下，下一步，进入当前方法体内，如果方法体还有方法，则会进入该内嵌的方法中，依此循环进入 Alt + Shift + F9 弹出 Debug 的可选择菜单 Alt + Shift + F10 弹出 Run 的可选择菜单 Alt + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 Alt + Shift + 前方向键 移动光标所在行向上移动 Alt + Shift + 后方向键 移动光标所在行向下移动 Ctrl + Shift + Alt 快捷键 介绍 Ctrl + Shift + Alt + V 无格式黏贴 Ctrl + Shift + Alt + N 前往指定的变量 / 方法 Ctrl + Shift + Alt + S 打开当前项目设置 Ctrl + Shift + Alt + C 复制参考信息 其他 快捷键 介绍 F2 跳转到下一个高亮错误 或 警告位置 （必备） F3 在查找模式下，定位到下一个匹配处 F4 编辑源 F7 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 F8 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F9 在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上 F11 添加书签 F12 回到前一个工具窗口 Tab 缩进 ESC 从工具窗口进入代码文件窗口 连按两次Shift 弹出 Search Everywhere 弹出层 模板查看/设置模板： Live Templates中可以查看、编辑、添加以及删除模板： Postfix Completion中只能查看、禁用。下图的Before框表示模板的预定义形式，After表示输出效果。比如下图的例子，输入foo.forr，摁下enter。将输出after框的模板。 自定义模板 如上图操作，输入模板组名，确定。选中创建的模板组，点击+，点击Live Template在组中添加新模板。 设置新模板： 1处填写模板缩写 2处填写模板的描述 3处定义模板内容。例子中模板的意义：输入test按下enter出现模板后，光标会跳至$var1$位置，输入完成后按enter，光标跳至$var2$处。 下一步，点击define，选择java： 点击OK即可。 idea自带模板 Before After 备注 psvm public static void main(String[] args) &#123;&#125; sout System.out.println(); soutm System.out.println(&quot;当前方法的全限定名&quot;); soutp System.out.println(&quot;c = &quot; + c); 以valueName=value的形式输出 soutv 与上同 输出某一变量 variable.sout System.out.println(variable); fori （递增） for (int i = 0; i &lt; ; i++) &#123;&#125; 输入完成后光标跳至第一个i后可改变变量名；按enter光标跳至&lt;后再按enter跳至&#123;&#125;中 arrs/List/Set.fori for (int i = 0; i &lt; xxx.size(); i++) &#123;&#125; 可对数组、集合使用。 forr（递减） 与上同理 arrs/List/Set.forr iter for (T t : arrs) &#123;&#125; 对某一数组使用forEach循环 arrs.iter 同上 对指定数组使用forEach循环 itar for (int i = 0; i &lt; arr.length; i++) &#123;int i1 =arr[i];&#125; 对代码中上一个数组使用普通for循环 ifn if (xxx == null) &#123;&#125; value.null if (value == null) &#123;&#125; inn （if not null） if (st != null) &#123;&#125; value.nn if (value == null) &#123;&#125; prsf private static final psfi public static final int psfs public static final String psf public static final 快捷创建Mybatis主配置文件 填写Name以及文件类型（Extension），并在方框内写入初始代码： Apply，即完成模板设置。 右键New创建文件时，即可看到创建的模板： 版本控制（git）克隆GitHub的项目到idea中1.先在idea中配置好git安装目录： 2.添加GitHub账户 3.从GitHub上clone仓库： 或者： 4.填写仓库信息 5.是否为clone的仓库创建新项目，选择yes： 后面是创建项目的一些选项，此处省略。 完成。 6.clone后，在idea中左侧的项目框右键： 即可看到git的各种操作。 没有add的文件在idea中会显示为红色。 将本地项目Share到GitHub这种方式将会在GitHub创建一个仓库，并将项目push到该仓库。 步骤： 后续步骤简单，省略。 Idea自带的文件修改历史功能右键一个文件-》【Local History】=》【show History】，即可看到文件的修改历史。 本地历史的相关信息保存在C:\\User\\.IntelliJIdea2019.3\\system\\LocalHistory下。 调试基本操作调试的界面和各种按钮，鼠标悬停在按钮上可查看快捷键信息： 各种操作的含义： 为断点添加条件即在该断点停止的条件是满足设置的条件。 例子： 创建一个for循环，并在输出语句添加断点： 右键断点，在condition中设置条件： 启动Debug，停止时i的值是60： 调试过程中查看变量的值基本数据类型的值可直接在界面上查看，如上述例子。对于引用类型变量，若要查看具体的属性信息，可将鼠标悬停在变量上，点击+即可查看。 创建Javadoc文档步骤： PS：命令行参数中，指定的字符集要和项目的字符集一致。 清除缓存和索引IDEA首次加载项目时会创建索引。 IntelliJ IDEA的缓存和索引主要是用来加快文件查询， 从而加快各种查找、代码提示等操作的速度。但是， IntelliJ IDEA的索引和缓存并不是一直会良好地支持IntelliJ IDEA的，某些特殊条件下， IntelliJ IDEA的缓存和索引文件也是会损坏的， 比如：断电、蓝屏引起的强制关机， 当你重新打开IntelliJ IDEA， 很可能Intell IDEA会报各种莫名其妙错误。这种情况可以清理下缓存和索引。如下： 【File】-》【Invalidate cache/Restart】，选择invalidate and restart。 或者将C:\\User\\.IntelliJIdea2019.3\\system文件删除（需要idea先关闭），并再次启动idea，等待其重新创建索引即可。 Maven下载maven导入jar包的源码和依赖点击右侧边栏的maven，如图： 选择Download Sources下载源码的jar包；选择Download Documentation下载说明文档（javadoc文件）；或者两者都下载。 打开maven的仓库目录，按下图找到对应目录： 如该图中到仓库下的com\\google\\protobuf\\protobuf-java\\3.11.4目录下，可看见下载的javadoc和sources的jar包。 maven项目构建可执行jar包（包含导入的依赖） 参考：https://www.cnblogs.com/dzblog/p/6913809.html pom.xml文件中配置插件： 12345678910111213141516171819202122232425262728&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- 此处指定main方法入口的class --&gt; &lt;mainClass&gt;包含main方法的入口类全限定名&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;assembly&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 执行package命令： 在target目录下即可看见项目的包含依赖的可执行jar包。 不包含依赖、包含部分依赖的打包方式见参考链接。 其他","categories":[{"name":"IDEA","slug":"IDEA","permalink":"http://example.com/categories/IDEA/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"http://example.com/Tag/IDEA/"}]},{"title":"JVM垃圾回收","slug":"Java/JVM/垃圾回收","date":"2021-02-18T05:20:53.928Z","updated":"2021-03-20T12:51:21.272Z","comments":true,"path":"2021/02/18/Java/JVM/垃圾回收/","link":"","permalink":"http://example.com/2021/02/18/Java/JVM/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/","excerpt":"","text":"概述当需要排查各种内存溢出问题、当垃圾收集成为系统达到更高并发的瓶颈时，我们就需要对这些“自动化”的技术实施必要的监控和调节。 对于程序计数器、虚拟机栈、本地方法栈，这几个区域的内存分配和回收都具有确定性，它们随着线程结束或方法结束时回收内存。而堆和方法区则有很大的不确定性：只有到运行期才能知道程序要创建哪些对象，创建多少对象，它们的内存分配和回收是动态的。 &emsp;&emsp; Java 的自动内存管理主要是针对对象内存的回收和对象内存的分配。同时，Java 自动内存管理最核心的功能是 堆 内存中对象的分配与回收。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代：再细致一点有：Eden 空间、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 堆空间的基本结构（图片来自javaGuide）： &emsp;&emsp; 判断对象已死垃圾收集器对堆回收之前需要判断哪些对象存活，哪些死亡（即不能再被任何途径使用的对象）。有引用计数算法和可达性分析算法两种判断方式。 &emsp;&emsp; 引用计数算法给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 循环依赖示例：除了对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。 代码示例： 123456789101112public class ReferenceCountingGc &#123; Object instance = null; public static void main(String[] args) &#123; ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; &#125;&#125; &emsp;&emsp; 可达性分析算法这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。 可作为 GC Roots 的对象包括下面几种: 虚拟机栈(栈帧中的本地变量表)中引用的对象 本地方法栈(Native 方法)中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 Java虚拟机内部引用，如基本类型对应的Class对象，系统类加载器、常驻异常对象等。 被同步锁（synchronized关键字）持有的对象。 &emsp;&emsp; 引用类型无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。 JDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用。 JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱）。 强引用我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。在任何情况下，只要这个强引用存在，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 &emsp;&emsp; 软引用软引用用来描述一些还有用，但非必须的对象。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。后续可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。 &emsp;&emsp; 弱引用如果一个对象只具有弱引用，那就类似于可有可无的生活用品。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期，它只能生存到下一次垃圾收集发生。 在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。 &emsp;&emsp; 虚引用“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要用来跟踪对象被垃圾回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 &emsp;&emsp; 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 &emsp;&emsp; “非死不可”？即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程：可达性分析法中不可达的对象被第一次标记，随后进行一次筛选，筛选的条件是此对象是否有必要执行 finalize 方法。当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。 被判定为需要执行的对象将会被放在一个队列中，并由一个低优先级线程去执行它们的finalize()方法，除非这个对象在finalize()方法中与引用链上的任何一个对象建立关联，否则就会被真的回收。 这种“自救”不推荐被使用。 &emsp;&emsp; 回收方法区方法区也是垃圾回收的对象区域，这里的垃圾收集主要包含两部分内容：废弃的常量和不再使用的类型。方法区的垃圾收集通常“性价比”比较低。 回收废弃常量运行时常量池主要回收的是废弃的常量。判断一个常量是否废弃： 假如在字符串常量池中存在字符串 “abc”，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 “abc” 就是废弃常量，如果这时发生内存回收的话而且有必要的话，”abc” 就会被系统清理出常量池了。 &emsp;&emsp; 关于常量池，方法区，元空间： JDK1.7 之前运行时常量池逻辑包含字符串常量池存放在方法区， 此时 HotSpot 虚拟机对方法区的实现为永久代 JDK1.7 字符串常量池 被从方法区拿到了堆中， 这里没有提到运行时常量池，也就是说字符串常量池被单独拿到堆，运行时常量池剩下的东西还在方法区， 也就是 HotSpot 中的永久代 。 JDK1.8 HotSpot 移除了永久代用元空间(Metaspace)取而代之， 这时候字符串常量池还在堆， 运行时常量池还在方法区， 只不过方法区的实现从永久代变成了元空间(Metaspace)。 &emsp;&emsp; 回收类判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。 类需要同时满足下面 3 个条件才能算是 “无用的类” ： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。 在大量使用反射、动态代理、CGLib等字节码框架， 动态生成JSP以及OSGi这类频繁自定义类加载器的场景中， 通常都需要Java虚拟机具备类型卸载的能力， 以保证不会对方法区造成过大的内存压力。 &emsp;&emsp; 垃圾收集算法分代收集理论分代收集理论的3个经验法则： 弱分代假说：绝大多数对象都是朝生夕灭的。 强分代假说：熬过越多次垃圾收集过程的对象就越难以消亡。 跨代引用假说：跨代引用相对于同代引用来说占极少数。 假如要进行一次只局限于新生代区域内的收集(Minor GC) ， 但新生代中的对象是完全有可能被老年代所引用的， 为了找出该区域中的存活对象， 不得不在固定的GC Roots之外，再额外遍历整个老年代中所有对象来确保可达性分析结果的正确性，反过来也是一样。但无疑会为内存回收带来很大的性能负担。为了解决这个问题，于是添加了第3个经验法则。 &emsp;&emsp; 分代收集理论放到具体的JVM中，设计者一般至少把Java堆划分为新生代和老年代。在Java堆划分出不同的区域之后，垃圾收集器才可以每次只回收其中某一个或者某些部分的区域——因而有了“Minor GC”、“Major GC”、“Full GC”这样的回收类型的划分；也才能够针对不同的区域安排与里面存储对象存亡特征相匹配的垃圾收集算法。 &emsp;&emsp; 标记-清除算法该算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。（或者反过来标记不需要回收的对象） 它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题： 效率问题。如果堆中很多对象需要回收，这时必须进行大量清除和标记的动作。 内存碎片问题（标记清除后会产生大量不连续的碎片） &emsp;&emsp; 复制算法为了解决效率问题，“复制”收集算法出现了。它将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 这样实现简单，运行高效，缺陷也明显，可用内存缩小了一半，且当对象存活率较高时，该算法效率较低。 &emsp;&emsp; 针对内存浪费太多的改进（Appel式回收）：把新生代分为一块较大的Eden空间和两块较小的Survivor空间， 每次分配内存只使用Eden和其中一块Survivor。发生垃圾收集时， 将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间上， 然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8：1， 只有10%的新生代是会被“浪费”的。 但也没有办法保证每次回收都只有不多于10%的对象存活， 因此Appel式回收还有一个充当罕见情况的“逃生门”的安全设计， 当Survivor空间不足以容纳一次MinorGC之后存活的对象时，就需要依赖其他内存区域（实际上大多就是老年代）进行分配担保(Handle Promotion) &emsp;&emsp; 标记-整理算法复制算法不适合老年代，因为老年代的回收率低，需要复制的对象太多。标记-整理算法是针对老年代的，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 图示（来自JavaGuide）： &emsp;&emsp; 标记-清除、标记-整理的本质区别在于是不是移动式的回收算法。是否移动对象都存在弊端： 如果移动存活对象，尤其是在老年代这种每次回收都有大量对象存活区域，移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作，而且这种对象移动操作必须全程暂停用户应用程序才能进行（“Stop The World”）。 但如果完全不考虑移动和整理存活对象，弥散于堆中的存活对象导致的空间碎片化问题就只能依赖更为复杂的内存分配策略来解决。 移动则内存回收时会更复杂，不移动则内存分配时会更复杂。从垃圾收集的停顿时间来看，不移动对象停顿时间会更短，甚至可以不需要停顿，但是从总的来说，移动对象会更划算。 &emsp;&emsp; 分代收集算法当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将 java 堆分为新生代和老年代，这样就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。 延伸面试问题： HotSpot 为什么要分为新生代和老年代？根据上面的对分代收集算法的介绍回答。 &emsp;&emsp; 垃圾收集器Serial 收集器Serial（串行）收集器是最基本、历史最悠久的垃圾收集器。这个收集器是一个单线程收集器。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，而且它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ “Stop The World” ），直到它收集结束。 新生代采用复制算法，老年代采用标记-整理算法。如图（来自《深入理解JVM》 Serial不是已无用的”鸡肋“，它是HotSpot运行在客户端模式下的默认新生代收集器。它简单而高效（与其他收集器的单线程相比）。Serial 收集器没有线程交互的额外开销，可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择。 &emsp;&emsp; ParNew 收集器ParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。 新生代采用复制算法，老年代采用标记-整理算法。（图片来自JavaGuide) 它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器配合工作。 在谈论垃圾收集器的上下文语境中，并行和并发概念可理解为： 并行（Parallel） ：指多条垃圾收集线程并行工作，通常默认此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。 &emsp;&emsp; Parallel Scavenge收集器Parallel Scavenge 收集器也是使用复制算法的新生代多线程收集器，看上去几乎和 ParNew 一样。 其不同点在于：CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间，而Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。停顿时间短，可以让用户有更好的体验；高吞吐量则可以充分利用处理器资源，适合在后台运算而不需要过多交互的任务。 所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解，手工优化存在困难的时候，使用 Parallel Scavenge 收集器配合自适应调节策略，把内存管理优化交给虚拟机去完成也是一个不错的选择。 自适应调节策略也是Parallel Scavenge收集器区别于ParNew收集器的一个重要特性。 &emsp;&emsp; JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old，如果指定了-XX:+UseParallelGC 参数，则默认指定了 -XX:+UseParallelOldGC，可以使用-XX:-UseParallelOldGC 来禁用该功能。 &emsp;&emsp; 新生代采用复制算法，老年代采用标记-整理算法。（图片来自JavaGuide） &emsp;&emsp; Serial Old 收集器Serial收集器的老年代版本，使用标记-整理算法，它同样是一个单线程收集器。该收集器主要也是供客户端模式下的HotSpot使用。如果在服务端模式下，主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。 &emsp;&emsp; Parallel Old 收集器Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器组合使用。 &emsp;&emsp; CMS 收集器CMS（Concurrent Mark Sweep，并发标记清除）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。CMS收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。（并发收集、低停顿） CMS 收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤： 初始标记（STW）： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ； 并发标记： GC 和用户线程一起并发运行，从GC Roots的直接关联对象开始遍历整个对象图。但在这个阶段结束，并不能保证扫描完当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。 重新标记（STW）： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。 并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。 （图片来自JavaGuide） &emsp;&emsp; 由于在整个过程中耗时最长的并发标记和并发清除阶段中，垃圾收集器线程都可以与用户线程一起工作， 所以从总体上来说， CMS收集器的内存回收过程是与用户线程一起并发执行的。 &emsp;&emsp; CMS收集器有下面三个明显的缺点： 对 CPU 资源敏感； 无法处理浮动垃圾； 且在垃圾收集阶段还需要预留足够内存空间提供给用户线程使用， 在JDK 5的默认设置下， CMS收集的阈值是68%。JDK 6时，阈值默认提升至92%。但如果预留的内存无法满足程序分配新对象的需要， 就会出现一次“并发失败”(Concurrent Mode Failure) ， 这时虚拟机将启动后备预案：冻结用户线程的执行， 临时启用Serial Old收集器来重新进行老年代的垃圾收集，但这样停顿时间就很长了。 在CMS的并发标记和并发清理阶段， 用户线程是还在继续运行的， 还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CMS无法在当次收集中处理掉它们， 只好留待下一次垃圾收集时再清理掉。这一部分垃圾就称为“浮动垃圾”。 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 &emsp;&emsp; G1收集器G1 (Garbage-First) 是一款面向服务器的垃圾收集器，主要针对配备多颗处理器及大容量内存的机器。 以极高概率满足 GC 停顿时间要求的同时，还具备高吞吐量性能特征。它开创了收集器面向局部收集的设计思路和基于Region的内存布局形式。 JDK9发布时，G1取代Parallel Scavenge+Parallel Old组合，是服务端模式下的默认收集器，而CMS被声明为不被推荐。 &emsp;&emsp; 基于Region的内存布局： 在G1收集器出现之前的所有其他收集器， 包括CMS在内， 垃圾收集的目标范围要么是整个新生代(MinorGC) 、整个老年代(Major GC) 、或整个Java堆(Full GC) 。而G1可以面向堆内存任何部分来组成回收集(Collection Set， 一般简称CSet) 进行回收，衡量标准不再是它属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大， 这就是G1收集器的Mixed GC模式。 G1仍是遵循分代收集理论，但其堆内存的布局与其他收集器有非常明显的差异：G1不再坚持固定大小以及固定数量的分代区域划分， 而是把连续的Java堆划分为多个大小相等的独立区域(Region) ， 每一个Region都可以根据需要， 扮演新生代的Eden空间、Survivor空间，或者老年代空间。 Region中还有一类特殊的Humongous区域，专门用来存储大对象。G1认为只要大小超过了一个Region容量一半的对象即可判定为大对象。每个Region的大小可以通过参数-XX:G1HeapRegionSize设定，取值范围为1MB~32MB，且应为2的N次幂。而对于那些超过了整个Region容量的超级大对象， 将会被存放在N个连续的Humongous Region之中， &emsp;&emsp; 总结G1的一些特点： 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。 空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，停顿时间模型即支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标。 &emsp;&emsp; G1 收集器的运作大致分为以下几个步骤（具体P101）： 初始标记 （短暂STW） 并发标记 最终标记 （短暂STW） 筛选回收 （STW） G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region（这也就是它的名字 Garbage-First 的由来） 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。 &emsp;&emsp; Shenandoah收集器(to be…)&emsp;&emsp; ZGC收集器(to be…)《新一代垃圾回收器 ZGC 的探索与实践》 &emsp;&emsp; 参考 JavaGuide-Note 《深入理解JVM》第3版","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"http://example.com/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/Tag/JVM/"}]},{"title":"类加载过程","slug":"Java/JVM/类加载过程","date":"2021-02-17T09:57:24.583Z","updated":"2021-03-20T12:51:57.168Z","comments":true,"path":"2021/02/17/Java/JVM/类加载过程/","link":"","permalink":"http://example.com/2021/02/17/Java/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B/","excerpt":"","text":"类的生命周期类的生命周期： 类的加载、连接和初始化都是在程序运行期间完成的。这为Java程序提供更大的灵活性。 &emsp;&emsp; 以下几种情况，生命周期将结束： 执行了System.exit()或Runtime.getRuntime().exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 JVM进程被终止。 &emsp;&emsp; 类加载过程Class文件需要加载到虚拟机中之后才能运行和使用，当程序主动使用某个类时，若该类未被加载到内存中（即首次主动使用），则系统通过加载、连接、初始化3个步骤来对该类进行初始化。连接过程又可分为三步:验证-&gt;准备-&gt;解析。 类加载过程图示： 加载加载指将类的class文件读入内存，将其放在运行时数据区的方法区内，并为之创建一个java.lang.Class对象，用来封装类在方法区内的数据结构，并提供了方法区内的数据结构的接口。（JVM规范并未说明Cass对象位于哪里， HotSpot虚拟机将其放在了方法区中） 加载阶段主要完成下面3件事情： 通过全类名获取定义此类的二进制字节流 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个代表该类的 Class 对象，作为方法区这些数据的访问入口 加载class文件的方式： 从本地系统中直接加载 通过网络下载cass文件 从zjp，jar等归档文件中加载class文件 将Java源文件动态编译为class文件（如动态代理） &emsp;&emsp; 连接连接阶段负责把类的二进制数据合并到JRE中。 验证：检验被加载的类是否有正确的内部结构并和其他类协调一致。 Class文件不一定由Java文件编译而来，需要对其进行验证，防止加载错误或恶意的字节码流。 类的验证的部分内容：类文件的结构检查；语义检查；字节码验证；二进制兼容性的验证等。 图片来自JavaGuide： 准备：为类的类变量分配内存，并设置默认初始值。通常情况下，不管有无为静态变量指定初始值，在准备阶段都会先将其初始化为零值。而若是类字段的字段属性表中存在ConstantValue属性，则会初始化为该属性指定的初始值，如使用了final static的情况。 解析：将类的二进制数据中的符号引用替换为直接引用。 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。 符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。在程序实际运行时，只有符号引用是不够的，举个例子：在程序执行方法时，系统需要明确知道这个方法所在的位置。Java 虚拟机为每个类都准备了一张方法表来存放类中所有的方法。当需要调用一个类的方法的时候，只要知道这个方法在方发表中的偏移量就可以直接调用该方法了。通过解析操作符号引用就可以直接转变为目标方法在类中方法表的位置，从而使得方法可以被调用。 综上，解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。(JavaGuide-类的加载过程 ) 加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，它们必须按顺序的开始（注意开始的意思是，这些阶段通常都是互相交叉的混合进行，会在一个阶段执行的过程中调用、激活另一个阶段），而解析阶段不一定，它可以在初始化阶段之后再开始。 &emsp;&emsp; 初始化初始化阶段，虚拟机对类进行初始化，主要是对类变量进行初始化（赋指定的值）。JVM会按顺序执行类文件中的初始化语句（static）。 初始化一个类包含以下步骤： 若该类还没被加载和连接，则对该类进行加载和连接。 若该类的直接父类没有被初始化，对该父类执行初始化。 若类中有初始化语句，则依次执行这些语句。 执行第2个步骤时，对父类的初始化步骤同样遵循这3个步骤。若父类有直接父类，则进行同样操作，以此类推。所以JVM最先初始化的总是java.lang.Object类。 只有主动使用类时才会对类执行初始化操作。 &emsp;&emsp; 类的卸载当 Mysample类被加载、连接和初始化后，它的生命周期就开始了。当代表MySample类的Class对象不再被引用，即不可触及时该Class对象就会被JVM垃圾回收机制回收，结束生命周期， Mysample类在方法区内的数据也会被卸载，从而结束 Mysample类的生命周期。 类何时结束生命周期，取决于代表它的Class对象何时结束生命周期。 每一个类加载器包含被它所加载的Class对象的引用。 程序中的每一个对象包含一个其所属类对应的Class对象的引用。（obj.class） 这两种引用不存在时类才会被卸载。即不存在指向相关类加载器的引用，和不存在Class对应的对象的情况。 &emsp;&emsp; 由Java虚拟机自带的类加载器所加载的类，在虚拟机的生命周期中，始终不会被卸载。Java虚拟机本身会始终引用这些类加载器，而这些类加载器则会始终引用它们所加载的类的Class对象，因此这些Class对象始终是可触及的。而由用户自定义的类加载器所加载的类是存在被卸载的可能的。 &emsp;&emsp; 验证示例： 使用类加载器中的MyClassLoader，编写测试代码，运行时添加JVM参数-XX:+TraceClassUnloading（跟踪卸载）： 1234567891011121314public static void test2() throws Exception&#123; String path = &quot;E:\\\\AAAFrequently-used\\\\temp\\\\&quot;; MyClassLoader loader = new MyClassLoader(&quot;loader1&quot;); loader.setPath(path); Class&lt;?&gt; clazz = loader.loadClass(&quot;classloader.MyTest1&quot;); Object obj = clazz.newInstance(); loader = null; clazz =null; obj = null; //没有任何引用指向MyTest1的Class对象，执行垃圾回收，MyTest1的Class对象将被卸载 System.gc();&#125; 把loader、clazz、obj都置为null，调用System.gc()执行垃圾回收， 会导致MyTest1的Class对象被卸载，输出： 1[Unloading class classloader.MyTest1 0x0000000100061028] &emsp;&emsp; 主动使用和被动使用主动使用《JVM规范》严格规定有且只有以下6种情况需要立即对类进行初始化： 当遇到 new 、 getstatic、putstatic或invokestatic 这4条直接码指令时，对应以下情况： 创建类的示例。（JVM执行new指令）。 访问某个类的静态变量（JVM执行getstatic指令），或为其静态变量赋值（jvm执行putstatic指令）（静态常量除外）。 调用类的静态方法（jvm执行invokestatic指令）。 注意：访问静态内部类的static遍历，创建静态内部类的实例不会造成外部类的初始化。这些情况下的new、getstatic等针对的是这个静态内部类，只会触发静态内部类的初始化。 使用 java.lang.reflect 包的方法对类进行反射调用时。如Class.forname(&quot;...&quot;)，newInstance()等等。 初始化一个子类时，若父类未初始化，先触发该父类的初始化。 当虚拟机启动时，用户需要定义一个要执行的主类 (包含 main 方法的类)，虚拟机会先初始化这个类。 当使用JDK 7新加人的动态语言支持时， 如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_get Static、REF_putStatic、REF_invokeStatic、REF_newInvokeSpecial四种类型的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发其初始化。 当一个接口中定义了JDK8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。 &emsp;&emsp; 这六种场景的行为称为对一个类型进行主动引用，其他情况的引用都称为被动引用，不会引起初始化。 被动使用除了以上情况，其他情况视为对类的被动使用，不会触发对类的初始化。一些被动使用的情况： 通过子类访问父类的静态变量，不会导致子类的初始化。访问静态变量，只有定义了该变量的类才会被初始化。 示例： 1234567891011121314151617181920212223242526class Parent1&#123; public static String str = &quot;hello，world&quot;; static &#123; System.out.println(&quot;Parent1&#x27;s static block&quot;); &#125;&#125;class Child extends Parent1&#123; public static String str1 = &quot;shit&quot;; static &#123; System.out.println(&quot;Child&#x27;s static block&quot;); &#125;&#125;public class MyTest1 &#123; public static void main(String[] args) &#123; //Child的static块没有执行 //访问静态字段，只有定义了该字段的类才会吧被初始化 // System.out.println(Child.str); //Parent1和Child1的static都执行了 //访问一个类的静态变量属于主动使用该类，所以初始化了Child //初始化一个类的子类时相当于主动访问了其所有父类，所以Parent1被初始化（一个类初始化时，要求其所有父类都要初始化完成） System.out.println(Child.str1); &#125;&#125; 但此时Child可能会被加载。在运行程序时添加jvm参数-XX:+TraceClassLoading可查看类加载信息。其中可看到 1[Loaded classloader.Child from file:/E:.....] 创建数组实例时不会造成数组元素类型的初始化，如下： 12345678910111213141516171819package classloader;public class MyTest3 &#123; public static void main(String[] args) &#123; Parent3[] parent3s = new Parent3[3]; System.out.println(parent3s.getClass()); Parent3[][] parent3s1 = new Parent3[2][2]; System.out.println(parent3s1.getClass()); System.out.println(parent3s.getClass().getSuperclass()); System.out.println(parent3s1.getClass().getSuperclass()); &#125;&#125;class Parent3&#123; static &#123; System.out.println(&quot;Parent3.static initializer&quot;); &#125;&#125; 输出： 1234class [Lclassloader.Parent3;class [[Lclassloader.Parent3;class java.lang.Objectclass java.lang.Object 可以看到，数组的类型并不是Parent3。 对于数组实例来说，其类型是由JVM在运行期动态生成的，表示为[L + 数组元素全限定名 + ;，二维数组则是[[...，且其父类就是java.lang.Object类。即并没有访问数组元素对应的类，因此不会造成其初始化。 调用ClassLoader的loadClass()方法。 还有一种final static的情况，如下。 关于final static对于一个final修饰的静态变量，若该变量的值在编译时就可以确定，那么该变量相当于“宏变量”。Java编译器会在编译时直接把这个类变量出现的地方替换为它的值。该常量在编译阶段会存入到调用这个常量的方法所在的类的常量池中，本质上，调用类并没有直接引用到定义常量的类，而是在调用常量池中的常量，因此并不会触发定义常量的类的初始化，且在把常量放入常量池之后，访问常量的类与定义该常量的类已经没有关系，此时将常量所在类的class文件删除仍然能运行。 &emsp;&emsp; 示例：（MyTest2） 1234567891011121314151617181920public class FinalStaticTest &#123; public static void main(String[] args) &#123; System.out.println(FinalStatic.a);//不会导致类的初始化，static块不执行 System.out.println(FinalStatic.b); &#125;&#125;//。。。。。。//输出：//ojbk//FinalStatic&#x27;s static block//obbkclass FinalStatic&#123; public static final String a = &quot;ojbk&quot;; public static String b = &quot;obbk&quot;; static &#123; System.out.println(&quot;FinalStatic&#x27;s static block&quot;); &#125;&#125; 从字节码方面看： 访问非final的静态变量或变量的值编译时不能确定的final static变量，jvm执行的是getstatic指令（在字节码文件中使用getstatic助记符），而对于宏变量则不是。 使用javap命令反编译FinalStaticTest：javap -c FinalStaticTest.class ，在输出的字节码中可看到 System.out.println(FinalStatic.b);对应的是 111: getstatic #6 // Field classloader/FinalStatic.b:Ljava/lang/String; 而System.out.println(FinalStatic.a);对应的是 3: ldc #4 // String ojbk 即String类型的宏变量对应助记符ldc。即并没用调用getstatic指令，因此不会触发类的初始化。 &emsp;&emsp; 而若是final static变量的值在编译时不能确定，访问该值依旧会使用getstatic指令，所以会造成类的初始化。 示例： 123456789101112class FinalStatic2&#123; public static final String str = UUID.randomUUID().toString(); static &#123; System.out.println(&quot;FinalStatic2&#x27;s static block&quot;); &#125;&#125;public class FinalStaticTest &#123; public static void main(String[] args) &#123; System.out.println(FinalStatic2.str); &#125;&#125; 使用javap命令可看到： 13: getstatic #3 // Field classloader/FinalStatic2.str:Ljava/lang/String; &emsp;&emsp; 关于准备、初始化阶段的示例定义类： 1234567891011121314151617class Singleton&#123; public static int count1 = 1; private static Singleton singleton = new Singleton(); private Singleton()&#123; count1++; count2++; System.out.println(count1); System.out.println(count2); &#125; public static int count2 = 0; public static Singleton getInstance()&#123; return singleton; &#125;&#125; 测试代码： 123456789101112public class MyTest5 &#123; public static void main(String[] args) &#123; Singleton singleton = Singleton.getInstance(); System.out.println(&quot;count1 = &quot; + singleton.count1); System.out.println(&quot;count2 = &quot; + singleton.count2); &#125;&#125;//output21count1 = 2count2 = 0 解析：在使用了Singleton的静态方法getInstance()时，引起了对Singleton的初始化，而初始化之前需要进行加载和连接，其中，在连接阶段的准备阶段，为count1和count2分配了内存，并赋默认值（0），在随后的初始化阶段，按顺序执行初始化语句，count被赋值为1，随后执行new Singleton()，将count1、2++，此时的值为2、1，最后执行count2 = 0，所以最后两个变量的值是2，0。 &emsp;&emsp; 关于接口的初始化类的初始化规则不全部适用于接口，对于接口： 当一个接口在初始化时，不会触发其父接口的初始化，只有在真正使用到父接口的时候（如引用接口中所定义的常量时），才会执行父接口的初始化。即使调用实现类的实现方法也不会触发接口的初始化。 若是一个接口包含default方法，则当其实现类被初始化时，会先初始化接口。（若还没初始化） 在初始化一个类时并不会初始化该类的实现接口（除非该接口包含default方法）。 接口中的成员变量默认被public static final修饰，所以对于接口变量同样适用上述宏变量的情况。 &emsp;&emsp; 示例：（若是接口被初始化，则接口中的new Thread()会执行，输出语句） 12345678910111213141516171819202122232425262728293031323334353637383940414243interface IParent&#123; String a = UUID.randomUUID().toString(); Thread thread = new Thread()&#123; &#123; System.out.println(&quot;IParent.instance initializer&quot;); &#125; &#125;;&#125;interface IChild extends IParent&#123; int b = 6; String str = UUID.randomUUID().toString(); Thread thread = new Thread()&#123; &#123; System.out.println(&quot;IChild.instance initializer&quot;); &#125; &#125;;&#125;class Imp implements IParent&#123; public static int c = 6; static &#123; System.out.println(&quot;Imp.static initializer&quot;); &#125;&#125;public class MyTest4 &#123; public static void main(String[] args) &#123; //1.访问宏变量，没有引起两个接口的初始化，output： //6 // System.out.println(IChild.b); //2.IChild被初始化，但其父接口并没有被初始化，output： //IChild.instance initializer //caac858a-e095-4152-abf4-b75f41a24873 // System.out.println(IChild.str); //3.类的初始化并不会触发其实现接口的初始化，output： //Imp.static initializer //6 System.out.println(Imp.c); &#125;&#125; &emsp;&emsp; 参考 深入理解JVM虚拟机视频 Guide-类的加载过程 jvm-类加载过程 《疯狂Java讲义》 《深入理解JVM》","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"http://example.com/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/Tag/JVM/"}]},{"title":"Java内存区域","slug":"Java/JVM/JVM内存区域","date":"2021-02-17T09:57:24.582Z","updated":"2021-03-20T12:53:19.047Z","comments":true,"path":"2021/02/17/Java/JVM/JVM内存区域/","link":"","permalink":"http://example.com/2021/02/17/Java/JVM/JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F/","excerpt":"","text":"Java内存区域概述相比于C/C++，Java虚拟机拥有自动内存管理机制，不需要为每一个new操作配对对应的delete/free代码，不容易出现内存泄漏和内存溢出问题。而正是因为 Java 程序员把内存控制权利交给 Java 虚拟机，一旦出现内存泄漏和溢出方面的问题，如果不了解虚拟机是怎样使用内存的，那么排查错误将会是一个非常艰巨的任务。 &emsp;&emsp; 运行时数据区域划分Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域。对于jdk1.8和之前的版本，内存的划分有一些不同，如下（图片来自JavaGuide）： jdk1.8之前： jdk1.8： &emsp;&emsp; 程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。其作用是： 字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令。分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了（上下文切换）。 程序计数器是一块“线程私有”的内存区域： 为什么程序计数器是线程私有： 由于Java虚拟机的多线程是通过线程轮流切换、分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储。 &emsp;&emsp; 若线程正在执行一个Java方法，则计数器记录的是正在执行的方法对应字节码指令的地址。而若是在执行native方法，则计数器为空（Undefined）。**程序计数器不会抛出OutOfMemoryError错误**（《JVM规范》没有规定这种情况） &emsp;&emsp; Java虚拟机栈与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型：每个Java方法被执行的时候， Java虚拟机都会同步创建一个栈帧（Stack Frame） 用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 递归调用时，每一次递归都在栈顶创建一个栈帧。 Java 方法有两种返回方式： return 语句。 抛出异常。 不管哪种返回方式都会导致栈帧被弹出。 &emsp;&emsp; Java内存可以粗糙的区分为堆内存（Heap）和栈内存 (Stack)，其中栈通常指这里的虚拟机栈，或者更多情况下只是指虚拟机栈中局部变量表部分。 局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference 类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。 &emsp;&emsp; Java 虚拟机栈会出现两种错误：StackOverFlowError 和 OutOfMemoryError。 StackOverFlowError： 若 Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 StackOverFlowError 错误。 OutOfMemoryError： 若 Java 虚拟机堆中没有空闲内存，并且垃圾回收器也无法提供更多内存的话。就会抛出 OutOfMemoryError 错误。 &emsp;&emsp; 本地方法栈和虚拟机栈所发挥的作用相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中本地方法栈和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种错误。 &emsp;&emsp; Java堆Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java世界中“几乎”所有的对象都在堆中分配，但是，随着JIT编译期的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。从jdk 1.7开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。 &emsp;&emsp; Java 堆是垃圾收集器管理的主要区域，因此也被称作GC 堆（Garbage Collected Heap） 在垃圾回收机制中，有时会对堆进行划分，如“新生代”，“老年代”等，但这些区域划分仅仅是一部分垃圾收集器的共同特性或者说设计风格而已， 而非某个Java虚拟机具体实现的固有内存布局， 更不是《Java虚拟机规范》里对Java堆的进一步细致划分。 根据JVM规范，Java堆可以处于物理上不连续的内存空间中，但在逻辑上应该被视为连续的。Java堆可以被实现为固定大小，也可实现为可扩展，当前主流JVM都是可扩展的（参数-Xmx、-Xms），若堆内存中没有空间可分配且不可扩展，则抛出OOM异常。 （来自JavaGuide） 在 JDK 7 版本及JDK 7 版本之前，堆内存被通常被分为下面三部分： 新生代内存(Young Generation) 老生代(Old Generation) 永生代(Permanent Generation) JDK 8 版本之后方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是直接内存。 上图所示的 Eden 区、两个 Survivor 区都属于新生代（为了区分，这两个 Survivor 区域按照顺序被命名为 from 和 to），中间一层属于老年代。 &emsp;&emsp; to be continue…. https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/Java%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F?id=_24-%e5%a0%86 &emsp;&emsp; 方法区方法区与 Java 堆一样，是各个线程共享的内存区域、可以不连续的内存和大小可扩展，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 &emsp;&emsp; 方法区与永久代的关系JDK1.8以前，方法区经常被称为永久代，JVM规范只是定义了方法区这个概念和它的作用，并没有定义永久代，永久代是Hotsp对方法区的一个具体实现，但这种实现方式Java应用更容易遇到内存溢出问题。从JDK1.6开始HotSpot逐渐放弃永久代，到JDK1.8已完全放弃永久代的概念，改用在本地内存中实现元空间（Meta-space）（元空间也是方法区的一种实现）。 永久代有一个 JVM 本身设置固定大小上限，无法进行调整，而元空间使用的是直接内存，默认情况下其上限是系统的物理内存大小（unlimited），内存溢出几率很小。可以通过MaxMetaspaceSize参数指定元空间大小。 元空间溢出时会得到如下错误： java.lang.OutOfMemoryError: MetaSpace &emsp;&emsp; 常用参数JDK1.8之前通常通过下面这些参数来调节方法区大小 12-XX:PermSize=N //方法区 (永久代) 初始大小-XX:MaxPermSize=N //方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen JDK 1.8 之后 下面是一些常用参数： 12-XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小）-XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小 -XX：MetaspaceSize 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。 &emsp;&emsp; 运行时常量池运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池表，用于存放编译期生成的各种字面量和符号引用。运行时常量池是方法区的一部分，受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 错误。 运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性， Java语言并不要求常量一定只有编译期才能产生，也就是说，并非预置人Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放人池中。 &emsp;&emsp; 直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 错误出现。 JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。 本机直接内存的分配不会受到 Java 堆的限制，但是会受到本机总内存大小以及处理器寻址空间的限制。 &emsp;&emsp; HotSpot虚拟机中的对象对象创建过程创建对象在Java代码中通常只是一个new关键字，而在虚拟机中的过程如下： 类加载检查虚拟机遇到一条 new 指令时，首先检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 &emsp;&emsp; 分配内存在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。 划分堆内存的两种方式： 指针碰撞（Bump The Pointer）。假设Java堆中内存是绝对规整的，所有被使用过的内存都被放在一边，空闲的内存被放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的距离， 这种分配方式即为“指针碰撞”。（GC收集器：Serial、ParNew） 空闲列表（Free List）。如果Java堆中的内存并不是规整的，已被使用的内存和空闲的内存相互交错在一起，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表” 。（GC收集器：CMS） 选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定（或者说，Java 堆是否规整取决于 GC 收集器的算法是”标记-清除”，还是”标记-整理”（也称作”标记-压缩”））。 &emsp;&emsp; 线程安全问题： 分配内存的操作在并发环境下并不是线程安全的，在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的。通常虚拟机采用两种方式来保证线程安全： CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。 TLAB： 为每一个线程预先在Java堆中分配一小块内存，称为本地线程分配缓存（Thread Local Allocation Buffer，TLAB）。哪个线程要分配内存，就在其对应TLAB中分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配。 虚拟机是否采用TLAB，可通过参数-XX:+/-UseTLAB设定。 &emsp;&emsp; 初始化零值内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 若使用了TLAB，则可以提前至TLAB分配时顺便进行。 &emsp;&emsp; 设置对象头初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码（实际上哈希码会延迟到调用Object.hashCode()方法时才调用）、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 &emsp;&emsp; 执行init方法（构造函数）在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 是否接着执行init方法，由字节码流中new指令后面是否跟随invokespecial指令所决定， Java编译器会在遇到new关键字的地方同时生成这两条字节码指令， 但如果直接通过其他方式产生的则不一定如此。 &emsp;&emsp; 对象在堆中的内存布局在 HotSpot 虚拟机中，对象在内存中的布局可以分为 3 块区域：对象头、实例数据和对齐填充。 HotSpot 虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是那个类的实例。 实例数据部分是对象真正存储的有效信息，也是在程序中所定义的各种类型的字段内容。无论是从父类继承的还是在子类中定义的字段都必须记录在这部分。 对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位符作用。 HotSpot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是对象的大小必须是 8 字节的整数倍。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 &emsp;&emsp; 对象的访问定位建立对象就是为了使用对象，Java程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有①使用句柄和②直接指针两种： 句柄： 如果使用句柄的话， Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。如图：（图片来自JavaGuide） 直接指针（HotSpot主要使用这种方式，也有例外情况）： 如果使用直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址。即reference直接指向堆中对象所在内存。如图： &emsp;&emsp; 这两种方式的优势： 使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时（如垃圾收集时对象经常移动）只会改变句柄中的实例数据指针，而 reference 本身不需要修改。 使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销。 &emsp;&emsp; String相关补充内容","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"http://example.com/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/Tag/JVM/"}]},{"title":"类加载器","slug":"Java/JVM/类加载器","date":"2021-02-17T09:57:24.580Z","updated":"2021-03-20T12:52:30.977Z","comments":true,"path":"2021/02/17/Java/JVM/类加载器/","link":"","permalink":"http://example.com/2021/02/17/Java/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/","excerpt":"","text":"类加载器分类类的 加载阶段 由类加载器完成。Java支持以下4种类型的类加载器： 前3种是Java虚拟机内置的类加载器，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader： 启动（根）类加载器（BootstrapClassLoader）：最顶层的加载类，没有继承java.ang.ClassLoader类。由C++实现，主要负责加载Java核心类库，加载%JAVA_HOME%/lib目录下的**rt.jar**、resources.jar、charsets.jar和class等（是按文件名识别的）。或者或被 -Xbootclasspath参数指定的路径中的所有类（系统属性sun.boot.class.path）。 扩展类加载器（ExtensionClassLoader）：它的父加载器为根类加载器。它从java.ext.dirs系统属性所指定的目录中加载类库，或者从JDK的安装目录的 jre\\lib\\ext子目录下加载jar和class文件。这个文件夹可以用于放置具有通用性的类库，以扩展JavaE功能。 应用（系统）类加载器（System/AppClassLoader）：它的父加载器为扩展类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中加载类（jdk默认的java.class.path是.，即当前目录，在idea中运行时会为该属性添加其他路径）。AppClassLoader是用户自定义的类加载器的默认父加载器。 用户自定义类加载器。通过创建java.lang.ClassLoader的子类实现，用户可定制类的加载方式。 4种类加载器的层次关系： &emsp;&emsp; 一般认为上一层加载器是下一层加载器的父加载器，除了BootstrapClassLoader之外，所有的加载器都是有父加载器的。 双亲委派模型中，类加载器之间的父子关系一般不会以继承（Inheritance）的关系来实现，而是都使用组合（Composition）关系来复用父加载器的代码的。源码体现：在ClassLoader中关于父加载器的定义：private final ClassLoader parent; &emsp;&emsp; Ext loader、App loader以及java.lang.ClassLoader是由启动类加载器加载的。 类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了. class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（Linkage Error错误）如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 &emsp;&emsp; 查看3个JVM类加载器中3个属性包含的路径：执行，可以看到java.class.path的输出中包含当前项目的classes路径 123456789101112131415161718public static void main(String[] args) &#123; // System.out.println(System.getProperty(&quot;sun.boot.class.path&quot;)); String property = System.getProperty(&quot;sun.boot.class.path&quot;); String property1 = System.getProperty(&quot;java.ext.dirs&quot;); String property2 = System.getProperty(&quot;java.class.path&quot;); print(property); print(property1); print(property2);&#125;public static void print(String property)&#123; String[] properties = property.split(&quot;;&quot;); for (String s : properties) &#123; System.out.println(s); &#125; System.out.println();&#125; 可通过修改系统属性java.system.class.loader来将自定义类加载器作为app loader。 相关demo：（JVMDemo/classloader/MyTest16 JVMDemo\\classloader\\MyTest13） &emsp;&emsp; ClassLoader除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自java.lang.ClassLoader。当一个类不能通过JVM内置3个类加载器加载时，比如需要通过网络加载，则需要继承ClassLoader创建子类，自定义类加载器。 获取ClassLoader的几种方式： 获得当前类的Clas Loader：clazz.getClassloader 获得当前线程上下文ClassLoader：Thread. currentThread().getContextClassLoader() 获得系统ClassLoader：Classloader.getSystemClassLoader()（获取AppClassLoader） 获得调用者的ClassLoader：DriverManager.getCallerClassLoader() 调用ClassLoader的loadClass()方法时，只会对类进行加载和连接，不会执行初始化操作。 &emsp;&emsp; ClassLoader的部分javadoc及其翻译★：一些点 数组的Class对象不是由类加载器创建，而是在JVM运行时自动创建的。 调用数组的Class对象的getClassLoader()方法返回的类加载器，与其数组元素返回的一样。而如果其数组元素是原生类型，则该数组没有类加载器。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667A class loader is an object that is responsible for loading classes. The class ClassLoader is an abstract class. Given the binary name of a class， a class loader should attempt to locate or generate data that constitutes a definition for the class. A typical strategy is to transform the name into a file name and then read a &quot;class file&quot; of that name from a file system.一种典型的策略是，将给定的name转换为文件名，并从文件系统中读取对应的class文件。Every Class object contains a reference to the ClassLoader that defined it.每一个Class对象包含一个定义了该Class对象的ClassLoader的引用Class objects for array classes are not created by class loaders， but are created automatically as required by the Java runtime. 数组的Class对象不是由类加载器创建，而是在JVM运行时自动创建的。The class loader for an array class， as returned by Class.getClassLoader() is the same as the class loader for its element type; if the element type is a primitive type， then the array class has no class loader.调用数组的Class对象的getClassLoader()方法返回的类加载器，与其数组元素返回的一样。而如果其数组元素是原生类型，则该数组没有类加载器。Applications implement subclasses of ClassLoader in order to extend the manner in which the Java virtual machine dynamically loads classes.应用程序实现类加载器的子类，来扩展JVM动态加载类的方式。Class loaders may typically be used by security managers to indicate security domains.The ClassLoader class uses a delegation model to search for classes and resources. ClassLoader类使用委托机制来寻找类和资源Each instance of ClassLoader has an associated parent class loader. When requested to find a class or resource， a ClassLoader instance will delegate the search for the class or resource to its parent class loader before attempting to find the class or resource itself. 每一个ClassLoader的实例都有一个与之关联的父ClassLoader。当被要求寻找一个类或资源时，ClassLoader实例在尝试自己寻找之前，会先委托给父ClassLoader去执行。The virtual machine&#x27;s built-in class loader， called the &quot;bootstrap class loader&quot;， does not itself have a parent but may serve as the parent of a ClassLoader instance.JVM有一个内建ClassLoader叫做bootstrap class loader，它本身没有父类，但可以作为类加载器实例的父类Class loaders that support concurrent loading of classes are known as parallel capable class loaders and are required to register themselves at their class initialization time by invoking the ClassLoader.registerAsParallelCapable method. Note that the ClassLoader class is registered as parallel capable by default.However， its subclasses still need to register themselves if they are parallel capable. 支持并发加载的ClassLoader被称为可并行的类加载器，且它们被要求在初始化时通过调用ClassLoader.registerAsParallelCapable方法进行注册。注意ClassLoader类默认会被注册。然而它的子类依然需要自行进行注册（如果需要并行能力）In environments in which the delegation model is not strictly hierarchical， class loaders need to be parallel capable， otherwise class loading can lead to deadlocks because the loader lock is held for the duration of the class loading process (see loadClass methods).Normally， the Java virtual machine loads classes from the local file system in a platform-dependent manner. For example， on UNIX systems， the virtual machine loads classes from the directory defined by the CLASSPATH environment variable.However， some classes may not originate from a file; they may originate from other sources， such as the network， or they could be constructed by an application.然而，某些class文件不是来源于文件，可能是来自其他来源，如网络、或者被程序创建。The method defineClass converts an array of bytes into an instance of class Class. Instances of this newly defined class can be created using Class.newInstance.defineClass方法可以将一个字节数组转换为一个Class对象，且可以通过Class.newInstance()方法来创建这个Class对应的类实例。The methods and constructors of objects created by a class loader may reference other classes. To determine the class(es) referred to， the Java virtual machine invokes the loadClass method of the class loader that originally created the class.类加载器创建的对象的方法和构造函数可以引用其他类。要确定引用的类，Java虚拟机调用最初创建类的类装入器的loadClass方法For example， an application could create a network class loader to download class files from a server. Sample code might look like: ClassLoader loader = new NetworkClassLoader(host， port); Object main = loader.loadClass(&quot;Main&quot;， true).newInstance(); . . . The network class loader subclass must define the methods findClass and loadClassData to load a class from the network. Once it has downloaded the bytes that make up the class， it should use the method defineClass to create a class instance. 网络类加载器的子类必须定义findClass()和loadClassData()方法（也可其他命名）用于加载来源于网络的类，用于从网络中加载类。一旦它下载了组成类的字节，它就应该使用defineClass方法来创建对应的Class对象。A sample implementation is:（示例） class NetworkClassLoader extends ClassLoader &#123; String host; int port; public Class findClass(String name) &#123; byte[] b = loadClassData(name); return defineClass(name， b， 0， b.length); &#125; private byte[] loadClassData(String name) &#123; // load the class data from the connection . . . &#125; &#125; &emsp;&emsp; 双亲委托机制概述每一个类都有一个对应它的类加载器。系统中的ClassLoder在工作时默认使用 双亲委派机制 ： 当一个类加载器收到加载类的请求时，它不会直接去加载指定的类，而是首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。 加载时，类加载器首先会把该请求委派给父类加载器的 loadClass() 处理（若检查到父类加载器为null，则使用启动类加载器 BootstrapClassLoader 作为父类加载器，并让其尝试加载指定类）。所有的请求最终都传送到顶层的启动类加载器 BootstrapClassLoader 中。 如果父类加载器无法处理，才由自己调用findClass()方法尝试加载类。 &emsp;&emsp; 即自底向上检查是否被加载过，再自顶向下尝试加载。 （当ClassLoder的parent为null时，表示其parent为BootstrapClassLoader） 图片来自Guide哥文档（链接）： 加载类的类加载器称为定义类加载器，返回已经被加载的类的类加载器称为初始化类加载器。 &emsp;&emsp; 双亲委派机制在ClassLoader的loadClass()方法中体现：（来自Guide哥文档链接） 123456789101112131415161718192021222324252627282930313233343536private final ClassLoader parent; protected Class&lt;?&gt; loadClass(String name， boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 首先，检查请求的类是否已经被加载过 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123;//父加载器不为空，调用父加载器loadClass()方法处理 c = parent.loadClass(name， false); &#125; else &#123;//父加载器为空，使用启动类加载器 BootstrapClassLoader 加载 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; //抛出异常说明父类加载器无法完成加载请求 &#125; if (c == null) &#123; long t1 = System.nanoTime(); //自己尝试加载 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; &emsp;&emsp; 每个Class对象都对应一个加载它的类加载器，每个类加载器都有一个父类加载器（若为null表示父类加载器为BootstrapClassLoader）。示例： 1234567891011121314public class MyTest &#123; public static void main(String[] args) &#123; ClassLoader classLoader = MyTest.class.getClassLoader(); System.out.println(classLoader); while (classLoader != null) &#123; classLoader = classLoader.getParent(); System.out.println(classLoader); &#125; &#125;&#125;output:sun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@1b6d3586null 可以看到，自定义的类由AppClassLoader加载，AppClassLoader的父类加载器是ExtClassLoader，ExtClassLoader的父类加载器是BootstrapClassLoader（表示为null）。 &emsp;&emsp; 双亲委托机制的优点 双亲委派机制保证了Java程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式是根据类的全限定名（binary name）和用于加载该类的定义类加载器）。当父加载器已经加载过某一个类时，子加载器就不会再重新加载这个类。 保证了安全性，使 Java 的核心 API 不被篡改。因为在该机制下，用户自定义类加载器不能加载应由根类加载器加载的核心类库，防止不可靠或恶意代码代替Java核心类库。 &emsp;&emsp; 打破双亲委托机制自定义加载器需要继承 ClassLoader 。如果不想打破双亲委派机制，重写 ClassLoader 类中的 findClass() 方法即可，因为默认的loadClass()实现会调用该方法（当父加载器无法加载指定类时）。无法被父类加载器加载的类最终会通过这个方法被加载。 如果想打破双亲委派机制则需要重写 loadClass() 方法。 &emsp;&emsp; loadClass()、findClass()、definclass()区别 loadClass() 就是主要进行类加载的方法，默认的双亲委派机制就实现在这个方法中。 findClass() 根据名称或位置加载.class字节码文件 definclass() 把字节码转化为Class对象 &emsp;&emsp; 类加载器命名空间 每个类加载器都有自己的命名空间，命名空间由该加载器及所有父加载器所加载的类组成。 一个类在JVM中的唯一性由这个类本身和它的类加载器决定。 在同一个命名空间中，不会出现类的全限定名相同的两个类。 在不同的命名空间中，有可能会出现全限定名相同的两个类。 子加载器所加载的类能够访问父加载器所加载的类。 父加载器所加载的类无法访问到子加载器所加载的类。 如果两个类加载器之间没有间接或直接的父子关系，则被这两个类加载器所加载的类互不可见。 &emsp;&emsp; 若是自定义了多个类加载器，则可能会出现同一个类加载多次的情况，JVM 是根据类的全限定名（binary name）和用于加载该类的定义类加载器区分不同类的，如果相同全限定名的类是由两个不同的加载器所加载，那么这些类就是不同的，即使class文件的字节码完全一样，并且从相同的位置加载。（验证示例见JVMDemo/test14） &emsp;&emsp; 默认情况下，如果一个类由A类加载器加载，则该类的依赖类也由A加载（若被依赖类未被加载）。这时可能会出现以下异常情况：（见JVMDemo\\classloader\\test12） 内外两个类位于不同命名空间的情况，即被不同的类加载器加载。 被包含类不能被加载成功的情况。 &emsp;&emsp; 自定义类加载器示例示例（使用双亲委派机制）： 自定义类加载器： 重写ClassLoader的findClass(String name)方法，在使用该类加载器加载类时，该方法会被loadClass()方法调用。 当父类加载器无法加载指定类时，会由该类加载器进行加载，此时loadClass()方法会调用findClass(String name)方法，在该方法中又调用loadClassData()方法来从指定路径读取 .class文件，返回对应的字节数组。 再通过defineClass()（继承自ClassLoader的方法，底层由C++实现）方法加载类，返回对应的Class对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class MyClassLoader extends ClassLoader &#123; private String classLoaderName; private final String fileExtension = &quot;.class&quot;; private String path; public MyClassLoader(String classLoaderName)&#123; super();//默认使用系统类加载器作为双亲委托 this.classLoaderName = classLoaderName; &#125; public MyClassLoader(ClassLoader parent， String classLoaderName)&#123; super(parent);//自行指定双亲委托 this.classLoaderName = classLoaderName; &#125; @Override public String toString() &#123; return &quot;[&quot; + this.classLoaderName + &quot;]&quot;; &#125; //★★ @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] data = loadClassData(name); System.out.println(&quot;MyClassLoader.findClass&quot;); return this.defineClass(name， data， 0， data.length); &#125; //★★ public byte[] loadClassData(String name)&#123; System.out.println(&quot;self define loadCLassData&quot;); InputStream is = null; byte[] data = null; ByteArrayOutputStream baos = null; name = name.replace(&quot;.&quot;， &quot;\\\\&quot;); try&#123; is = new FileInputStream(new File(this.path + name + this.fileExtension)); baos = new ByteArrayOutputStream(); int ch = 0; while(-1 != (ch=is.read()))&#123; baos.write(ch); &#125; data = baos.toByteArray(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; try &#123; is.close(); baos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return data; &#125; public void setPath(String path)&#123; this.path = path; &#125;&#125; &emsp;&emsp; 测试：（若父类加载器无法加载MyTest1类，则在E:\\AAAFrequently-used\\temp\\路径下读取MyTest1类的 .class 文件并创建Class对象） 12345678910111213141516171819202122public static void test1() throws Exception&#123; String path = &quot;E:\\\\AAAFrequently-used\\\\temp\\\\&quot;; MyClassLoader loader = new MyClassLoader(&quot;loader1&quot;); loader.setPath(path); Class&lt;?&gt; clazz = loader.loadClass(&quot;classloader.MyTest1&quot;); Object obj = clazz.newInstance(); System.out.println(&quot;class: &quot; + clazz.hashCode()); System.out.println(&quot;class loader: &quot; + obj.getClass().getClassLoader()); System.out.println(&quot;class&#x27; instance: &quot; + obj); System.out.println(&quot;\\n&quot;); MyClassLoader loader2 = new MyClassLoader(&quot;loader2&quot;);//---1---- loader2.setPath(path); Class&lt;?&gt; clazz2 = loader2.loadClass(&quot;classloader.MyTest1&quot;); Object obj2 = clazz2.newInstance(); System.out.println(&quot;class: &quot; + clazz2.hashCode()); System.out.println(&quot;class loader: &quot; + obj2.getClass().getClassLoader()); System.out.println(&quot;class&#x27; instance: &quot; + obj2);&#125; 此时loader1、loader2的父类加载器都是系统类加载器，运行结果： 若是当前项目的classpath路径下有MyTest1的 .class 文件时，根据双亲委派机制，MyTest1将由系统类加载器进行加载，因此创建的两个Class实例相同： 12345678class: 460141958class loader: sun.misc.Launcher$AppClassLoader@18b4aac2class&#x27; instance: classloader.MyTest1@4554617cclass: 460141958class loader: sun.misc.Launcher$AppClassLoader@18b4aac2class&#x27; instance: classloader.MyTest1@74a14482 把classpath下的MyTest1.class移除，放到E:\\AAAFrequently-used\\temp\\classloader路径下，重新运行程序。因为loader1、loader2的父类加载器都无法加载MyTest1，所以最后会由它们进行加载，此时会加载出两个MyTest1的Class对象： 这两个Class位于不同的命名空间。 输出： 123456789101112self define loadCLassDataMyClassLoader.findClassclass: 1956725890class loader: [loader1]class&#x27; instance: classloader.MyTest1@1540e19dself define loadCLassDataMyClassLoader.findClassclass: 2133927002class loader: [loader2]class&#x27; instance: classloader.MyTest1@6d6f6e28 把–1–处代码改为MyClassLoader loader2 = new MyClassLoader(loader， &quot;loader2&quot;);，即loader2的父类加载器是loader1。重新运行程序。根据双亲委派机制，因为其父类加载器loader1已完成MyTest1的加载，所以loader2不会重新加载类，返回loader1创建的Class对象： 12345678910self define loadCLassDataMyClassLoader.findClassclass: 1956725890class loader: [loader1]class&#x27; instance: classloader.MyTest1@1540e19dclass: 1956725890class loader: [loader1]class&#x27; instance: classloader.MyTest1@677327b6 &emsp;&emsp; 线程上下文类加载器线程上下文类加载器（Thread Context ClassLoader，since jdk1.2）可用于解决某些双亲委托机制无法适应的情况，主要为了解决SPI（Service Provider Interface，服务提供接口）的问题。 SPI即一组接口或抽象类，没有具体实现。jdk中的一些SPI的具体实现由Java核心类库提供，这些SPI和具体实现都可以被启动类加载器所加载。而对于某些SPI，如jdbc的SPI，其具体实现由第三方提供，若是遵循双亲委托机制，则它们无法通过启动类加载器来加载，这时可以就可以使用线程上下文类加载器来加载这些具体实现。Context ClassLoade破坏了双亲委托机制。 即当高层提供了统一的接口让低层实现，同时又需要在高层加载这些具体实现，则需要使用Context ClassLoader来寻找并加载这些类。 Context ClassLoader通过Thread.currentThread().getContextClassLoader()获取，若无显式指定，则默认为系统类加载器。 Context ClassLoade的一般使用模式是：获取-》使用-》还原： 12345678ClassLoader loader = Thread.currentThread().getContextClassLoader();try&#123; Thread.currentThread().setContextClassLoader(targetTccl); myMethod();&#125;finally&#123; //还原 Thread.currentThread().setContextClassLoader(loader);&#125; 其中，在myMethod();中通过Thread.currentThread().getContextClassLoader();获取线程上下文类加载器来加载某些类（服务提供者）。 ServiceLoader类是jdk提供的一个用于加载服务具体实现的类，具体见源码分析笔记。 &emsp;&emsp; 参考 深入理解JVM虚拟机视频 Guide-类的加载过程 jvm-类加载过程 《疯狂Java讲义》 《深入理解JVM》 十个双亲委派问题","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"http://example.com/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://example.com/Tag/JVM/"}]},{"title":"深拷贝、浅拷贝","slug":"Java/基础/深拷贝、浅拷贝","date":"2020-12-02T14:25:18.129Z","updated":"2021-03-20T12:46:06.358Z","comments":true,"path":"2020/12/02/Java/基础/深拷贝、浅拷贝/","link":"","permalink":"http://example.com/2020/12/02/Java/%E5%9F%BA%E7%A1%80/%E6%B7%B1%E6%8B%B7%E8%B4%9D%E3%80%81%E6%B5%85%E6%8B%B7%E8%B4%9D/","excerpt":"","text":"&emsp; 概述定义两个类： 1234567891011public class Major &#123; private String majorName; private int id; //...&#125;public class Student &#123; private String name; private Major major; //...&#125; &emsp; 浅拷贝即在拷贝对象时，对于对象中的引用类型成员变量，只复制该成员变量的对象引用，而该引用地址指向的实际对象空间其实只有一份。如图（图片来自参考链接）： 深拷贝即对于引用类型字段所指向的对象，也会在内存中也创建一个副本。如图（图片来自参考链接）： &emsp; 代码实现浅拷贝要拷贝的类实现Cloneable接口，重写Object的clone()方法，并使用其默认实现来实现浅拷贝（Object类的clone()方法的默认实现就是浅拷贝，且该方法是一个native方法）。 Cloneable接口是一个空接口，与Serializable接口类似，只是一个标记。通过实现该接口，使实现类支持使用Object类的clone()方法，否则会抛出CloneNotSupportedException异常。 &emsp; 示例： 1234567891011public class Student implements Cloneable&#123; private String name; private Major major; @Override public Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; //...&#125; 测试： 12345678910111213141516public static void main(String[] args) throws CloneNotSupportedException &#123; Major major = new Major(&quot;软件工程&quot;, 1); Student student1 = new Student(&quot;小明&quot;, major); Student student2 = (Student) student1.clone(); System.out.println(student1); System.out.println(student2); System.out.println(&quot;student1==student2 &quot; + (student1==student2)); System.out.println(&quot;两个student的major是否相同：&quot; + (student1.getMajor()==student2.getMajor())); major.setId(666); major.setMajorName(&quot;信息安全&quot;); System.out.println(student1); System.out.println(student2);&#125; 输出： 123456Student&#123;name=&#x27;小明&#x27;, major=Major&#123;majorName=&#x27;软件工程&#x27;, id=1&#125;&#125;Student&#123;name=&#x27;小明&#x27;, major=Major&#123;majorName=&#x27;软件工程&#x27;, id=1&#125;&#125;student1==student2 false两个student的major是否相同：trueStudent&#123;name=&#x27;小明&#x27;, major=Major&#123;majorName=&#x27;信息安全&#x27;, id=666&#125;&#125;Student&#123;name=&#x27;小明&#x27;, major=Major&#123;majorName=&#x27;信息安全&#x27;, id=666&#125;&#125; 两个student不相同，说明拷贝了一个新的对象。 修改major对象后，两个student中的major都改变，说明两个major指向同一对象。 &emsp; 深拷贝深拷贝可以有两种实现方式： 同样使用Cloneable接口，但与浅拷贝不同，需要对引用对象实现进行深度遍历式拷贝。 使用反序列化实现。 &emsp; 使用Cloneable接口Major类也需要实现Cloneable接口。Major中的成员变量都是值类型，所以使用clone()方法默认实现即可。 12345678public class Major implements Cloneable&#123; //... @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; //...&#125; &emsp; 在顶层的调用类中（Student）重写clone方法，来调用引用类型字段的clone()方法实现深度拷贝： 先通过浅拷贝拷贝出一个student。 再创建一个major的副本。 123456789101112public class Student &#123; //... @Override protected Object clone() throws CloneNotSupportedException &#123; Student cloneStu = (Student) super.clone(); if(major!=null) &#123; cloneStu.major = (Major) major.clone();//!!! &#125; return cloneStu; &#125; //...&#125; 使用相同的测试代码，输出： 123456Student&#123;name=&#x27;小明&#x27;, major=Major&#123;majorName=&#x27;软件工程&#x27;, id=1&#125;&#125;Student&#123;name=&#x27;小明&#x27;, major=Major&#123;majorName=&#x27;软件工程&#x27;, id=1&#125;&#125;student1==student2 false两个student的major是否相同：falseStudent&#123;name=&#x27;小明&#x27;, major=Major&#123;majorName=&#x27;信息安全&#x27;, id=666&#125;&#125;Student&#123;name=&#x27;小明&#x27;, major=Major&#123;majorName=&#x27;软件工程&#x27;, id=1&#125;&#125; &emsp; 使用反序列化Major、Student都实现Serializable接口，在Student中编写clone()方法： 1234567891011121314151617181920public class Student implements Serializable &#123; //... public Student clone()&#123; try &#123; ByteArrayOutputStream byteOut = new ByteArrayOutputStream(); ObjectOutputStream objectOutputStream = new ObjectOutputStream(byteOut); objectOutputStream.writeObject(this); ObjectInputStream objectInputStream = new ObjectInputStream(new ByteArrayInputStream(byteOut.toByteArray())); return (Student2) objectInputStream.readObject(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; return null; &#125; //...&#125; 同样使用相同的测试代码，输出： 123456Student2&#123;name=&#x27;小明&#x27;, major=Major2&#123;majorName=&#x27;软件工程&#x27;, id=1&#125;&#125;Student2&#123;name=&#x27;小明&#x27;, major=Major2&#123;majorName=&#x27;软件工程&#x27;, id=1&#125;&#125;student1==student2 false两个student的major是否相同：falseStudent2&#123;name=&#x27;小明&#x27;, major=Major2&#123;majorName=&#x27;信息安全&#x27;, id=666&#125;&#125;Student2&#123;name=&#x27;小明&#x27;, major=Major2&#123;majorName=&#x27;软件工程&#x27;, id=1&#125;&#125; &emsp; 深拷贝List集合 来自参考链接 12345678910public static &lt;T&gt; List&lt;T&gt; deepCopy(List&lt;T&gt; src)throws Exception&#123; ByteArrayOutputStream byteOut = new ByteArrayOutputStream(); ObjectOutputStream out = new ObjectOutputStream(byteOut); out.writeObject(src); ByteArrayInputStream byteIn = new ByteArrayInputStream(byteOut.toByteArray()); ObjectInputStream in = new ObjectInputStream(byteIn); List&lt;T&gt; dest = (List&lt;T&gt;) in.readObject(); return dest;&#125; &emsp; 参考 程序羊-深拷贝、浅拷贝 java List复制：浅拷贝与深拷贝","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"http://example.com/categories/Java/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"Spring中处理json数据的总结","slug":"框架/Spring中处理json数据","date":"2020-11-12T16:45:26.199Z","updated":"2020-12-03T15:46:33.592Z","comments":true,"path":"2020/11/13/框架/Spring中处理json数据/","link":"","permalink":"http://example.com/2020/11/13/%E6%A1%86%E6%9E%B6/Spring%E4%B8%AD%E5%A4%84%E7%90%86json%E6%95%B0%E6%8D%AE/","excerpt":"","text":"总结一下Spring中一些解析json数据的技巧。 @RequestBody注解@RequestBody注解常用来处理content-type不是默认的application/x-www-form-urlcoded编码的内容，比如application/json或者是application/xml等。一般情况下来说常用其来处理application/json类型。 @RequestBody的修饰对象的控制器方法形参，一般用于修饰JavaBean形参，其可以将请求体中的JSON字符串绑定到修饰的bean上。也可以修饰字符串，会将请求体的参数以key1=value1&amp;key2=value2&amp;...的格式复制给String控制器参数。 &emsp; 修饰JavaBean时，json字符串要与JavaBean的属性对应，且可以修饰List集合类型的形参，这时前端要以json数组的形式发送数据，且要指定content-type为application/json类型。 接收json对象字符串示例JavaBean： 123456789101112public class Role &#123; private int id; private String roleName; //getter、setter、toString&#125;public class Person &#123; private String name; private Integer age; private List&lt;Role&gt; roles; //getter、setter、toString&#125; &emsp; Controller： 123456789@RestControllerpublic class DataResolveController &#123; @PostMapping(&quot;/doJsonObject&quot;) public String resolveJsonObject(@RequestBody Person person)&#123; System.out.println(person); return &quot;ok&quot;; &#125;&#125; &emsp; 在前端发送Ajax： **注意发送ajax请求时，contentType要指定为application/json**。 person对象的属性与Person类一一对应，其中roles的属性值是一个json对象数组。 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Index&lt;/title&gt; &lt;script src=&quot;https://cdn.staticfile.org/jquery/2.1.1/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Test @RequestBody&lt;/h1&gt; &lt;button id=&quot;send&quot;&gt;send ajax&lt;/button&gt; &lt;script&gt; $(&quot;#send&quot;).click(function () &#123; var person = &#123; &quot;name&quot;:&quot;白小纯&quot;, &quot;age&quot;:&quot;20&quot;, &quot;roles&quot;:[ &#123;&quot;id&quot;:&quot;1&quot;,&quot;roleName&quot;:&quot;医生&quot;&#125;, &#123;&quot;id&quot;:&quot;2&quot;,&quot;roleName&quot;:&quot;老师&quot;&#125; ]&#125;; $.ajax(&#123; type: &quot;POST&quot;, url: &quot;doJsonObject&quot;, contentType: &quot;application/json; charset=utf-8&quot;, data: JSON.stringify(person), dataType: &quot;json&quot;, &#125;); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; &emsp; 点击按钮，后台输出： 1Person&#123;name=&#x27;白小纯&#x27;, age=20, roles=[Role&#123;id=1, roleName=&#x27;医生&#x27;&#125;, Role&#123;id=2, roleName=&#x27;老师&#x27;&#125;]&#125; 接收json数组示例控制器： 123456@RequestMapping(&quot;/sendarray&quot;)@ResponseBodypublic String testReceiveArray(@RequestBody List&lt;Integer&gt; array)&#123; System.out.println(array); return &quot;success&quot;;&#125; &emsp; Ajax代码（jQuery）： 这里发送json数组可以直接使用字符串形式，如下。也可以先创建一个变量var array = [1,2,3,5]，再通过JSON.stringify(array)转换为json数据。 12345678910111213141516$(function () &#123; $(&quot;#btn1&quot;).click(function () &#123; //var array = [1,2,3,5]; //JSON.stringify(array) $.ajax(&#123; url: &quot;sendarray&quot;, type: &quot;post&quot;, data: &quot;[1,2,3]&quot;, dataType: &quot;text&quot;, contentType: &quot;application/json;charset=UTF-8&quot;, success: function (result) &#123; alert(result); &#125; &#125;) &#125;)&#125;); 服务端输出：[1, 2, 3]。 List的元素也可以是其他的JavaBean。 &emsp; 使用Jackson处理jsonJackson简介 来自参考连接 Jackson 是当前用的比较广泛的，用来序列化和反序列化 json 的 Java 的开源框架。Jackson 社区相对比较活跃，更新速度也比较快， 从 Github 中的统计来看，Jackson 是最流行的 json 解析器之一 。 Spring MVC 的默认 json 解析器便是 Jackson。 Jackson 优点很多。 Jackson 所依赖的 jar 包较少 ，简单易用。与其他 Java 的 json 的框架 Gson 等相比， Jackson 解析大的 json 文件速度比较快；Jackson 运行时占用内存比较低，性能比较好；Jackson 有灵活的 API，可以很容易进行扩展和定制。 Jackson 的 1.x 版本的包名是 org.codehaus.jackson ，当升级到 2.x 版本时，包名变为 com.fasterxml.jackson。 Jackson 的核心模块由三部分组成。 jackson-core，核心包，提供基于”流模式”解析的相关 API，它包括 JsonPaser 和 JsonGenerator。 Jackson 内部实现正是通过高性能的流模式 API 的 JsonGenerator 和 JsonParser 来生成和解析 json。 jackson-annotations，注解包，提供标准注解功能； jackson-databind ，数据绑定包， 提供基于”对象绑定” 解析的相关 API （ ObjectMapper ） 和”树模型” 解析的相关 API （JsonNode）；基于”对象绑定” 解析的 API 和”树模型”解析的 API 依赖基于”流模式”解析的 API。 依赖对于SpringMVC项目，需要导入依赖（maven）： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.9.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.6&lt;/version&gt;&lt;/dependency&gt; 对于SpringBoot项目，依赖spring-boot-starter-web中就包括了Jackson的依赖。所以无需导入。 &emsp; JSON字符串-》对象Jackson的一个主要类就是ObjectMapper，通过该类的readValue()方法可以将json字符串解析为指定对象。 &emsp; 示例： JavaBean使用上述的Person和Role。 12345678@Testvoid testJackson() throws JsonProcessingException &#123; ObjectMapper mapper = new ObjectMapper(); String personJson = &quot;&#123;\\&quot;name\\&quot;:\\&quot;白小纯\\&quot;, \\&quot;age\\&quot;:\\&quot;20\\&quot;, \\&quot;roles\\&quot;:[&#123;\\&quot;id\\&quot;:\\&quot;1\\&quot;,\\&quot;roleName\\&quot;:\\&quot;医生\\&quot;&#125;, &quot; + &quot;&#123;\\&quot;id\\&quot;:\\&quot;2\\&quot;,\\&quot;roleName\\&quot;:\\&quot;老师\\&quot;&#125;]&#125;&quot;; Person person = mapper.readValue(personJson, Person.class); System.out.println(person);&#125; 输出： 1Person&#123;name=&#x27;白小纯&#x27;, age=20, roles=[Role&#123;id=1, roleName=&#x27;医生&#x27;&#125;, Role&#123;id=2, roleName=&#x27;老师&#x27;&#125;]&#125; &emsp; 对象-》json字符串通过ObjectMapper对象的writeValueAsString()方法实现。 示例： 12345678910111213141516171819202122public void testObjectToJson() throws JsonProcessingException &#123; ObjectMapper mapper = new ObjectMapper(); Person person = new Person(); List&lt;Role&gt; roles = new ArrayList&lt;&gt;(); Role role1 = new Role(); Role role2 = new Role(); role1.setId(1); role1.setRoleName(&quot;学生&quot;); role2.setId(2); role2.setRoleName(&quot;班长&quot;); roles.add(role1); roles.add(role2); person.setAge(20); person.setName(&quot;王大锤&quot;); person.setRoles(roles); String personStr = mapper.writeValueAsString(person); System.out.println(personStr);&#125; 输出： 1&#123;&quot;name&quot;:&quot;王大锤&quot;,&quot;age&quot;:20,&quot;roles&quot;:[&#123;&quot;id&quot;:1,&quot;roleName&quot;:&quot;学生&quot;&#125;,&#123;&quot;id&quot;:2,&quot;roleName&quot;:&quot;班长&quot;&#125;]&#125; &emsp; JSON数组《-》LsitreadValue()方法可以解析JSON对象数组字符串为List集合，同样的，writeValueAsString()方法可以将List集合中的多个对象解析为Json对象数组字符串。 示例： 注意readValue()方法的第二个参数 123456789public void testJsonTOList() throws JsonProcessingException &#123; String rolesStr = &quot;[&#123;\\&quot;id\\&quot;:1,\\&quot;roleName\\&quot;:\\&quot;快递员\\&quot;&#125;,&#123;\\&quot;id\\&quot;:2,\\&quot;roleName\\&quot;:\\&quot;程序员\\&quot;&#125;]&quot;; ObjectMapper mapper = new ObjectMapper(); List&lt;Role&gt; roles = mapper.readValue(rolesStr, new TypeReference&lt;List&lt;Role&gt;&gt;() &#123;&#125;); System.out.println(roles); String jsonArray = mapper.writeValueAsString(roles); System.out.println(jsonArray);&#125; 输出： 12[Role&#123;id=1, roleName=&#x27;快递员&#x27;&#125;, Role&#123;id=2, roleName=&#x27;程序员&#x27;&#125;][&#123;&quot;id&quot;:1,&quot;roleName&quot;:&quot;快递员&quot;&#125;,&#123;&quot;id&quot;:2,&quot;roleName&quot;:&quot;程序员&quot;&#125;] &emsp; References Jackson使用详解–掘金 三分恶（想要深入了解Jackson可以看这篇博客，巨详细）","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Jackson","slug":"Jackson","permalink":"http://example.com/Tag/Jackson/"}]},{"title":"","slug":"框架/SSM整合Demo","date":"2020-11-04T11:15:09.875Z","updated":"2021-03-15T09:35:14.704Z","comments":true,"path":"2020/11/04/框架/SSM整合Demo/","link":"","permalink":"http://example.com/2020/11/04/%E6%A1%86%E6%9E%B6/SSM%E6%95%B4%E5%90%88Demo/","excerpt":"","text":"概述本文只介绍项目中的配置文件，完整项目：github。 项目中使用了两张表（员工表、部门表，一个员工对应一个部门）： 123456789101112131415161718create table dept( dept_id int auto_increment primary key, dept_name varchar(255) null);create table employees( emp_id int auto_increment primary key, emp_name varchar(30) null, gender char null, email varchar(255) null, d_id int null, constraint emp_fk_dept foreign key (d_id) references dept (dept_id)); &emsp; 该项目是idea的maven项目，总的目录结构： &emsp; 导入依赖pom.xml文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.example&lt;/groupId&gt; &lt;artifactId&gt;SSMIntegration&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;SSMIntegration Maven Webapp&lt;/name&gt; &lt;url&gt;http://www.example.com&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring单元测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.2.8.RELEASE&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- spring以及springMVC相关依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.2.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.2.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 事务相关配置所需依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;5.2.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis整合spring的jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 数据库连接池以及数据库驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.22&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.7.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.22&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis逆向工程依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt; &lt;version&gt;1.3.7&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis分页插件 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 处理json数据的jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.11.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- JSR303校验所需依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;6.1.5.Final&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; &lt;version&gt;2.11.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-web&lt;/artifactId&gt; &lt;version&gt;2.11.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-jcl&lt;/artifactId&gt; &lt;version&gt;2.11.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- servlet-api --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;SSMIntegration&lt;/finalName&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- mybatis逆向工程所需插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; 若在关闭tomcat服务器时会报错，见： https://www.cnblogs.com/bxiaoo/p/13828772.html &emsp; SpringMVC配置文件spring-mvc.xml（位于resources/ssm下）： 123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc https://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt; &lt;!-- 在该配置文件中只配置web组件相关的bean --&gt; &lt;!-- 扫描controller --&gt; &lt;context:component-scan base-package=&quot;com.ssm.controller&quot; /&gt; &lt;!-- 配置视图解析器 --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/views/&quot; /&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt; &lt;/bean&gt; &lt;!-- 两个常用配置 --&gt; &lt;!-- 让springmvc处理不了的请求交给tomcat，如静态资源等 --&gt; &lt;mvc:default-servlet-handler /&gt; &lt;!-- 支持一些springmvc高级功能，如jsr303校验、快捷的Ajax、映射动态请求等 --&gt; &lt;mvc:annotation-driven /&gt;&lt;/beans&gt; &emsp; Spring配置文件spring配置文件中配置了service、dao等bean，也包括跟mybatis的整合配置。 整合MybatisSpring整合Mybatis通过类SqlSessionFactoryBean，在该bean中可以进行与Mybatis主配置文件一样的配置，即可以省略Mybatis主配置文件。也可以通过configLocation属性来指定主配置文件的路径。 spring-mybatis.xml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 加载配置文件 --&gt; &lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot; /&gt; &lt;!-- 配置数据库连接池，这里使用德鲁伊 --&gt; &lt;bean class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; id=&quot;dataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;driver&#125;&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;user&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot; /&gt; &lt;!-- 最大连接池数量 --&gt; &lt;property name=&quot;maxActive&quot; value=&quot;30&quot; /&gt; &lt;!-- 最小连接池 --&gt; &lt;property name=&quot;minIdle&quot; value=&quot;10&quot; /&gt; &lt;!-- 连接超时时间 --&gt; &lt;property name=&quot;validationQueryTimeout&quot; value=&quot;3&quot; /&gt; &lt;/bean&gt; &lt;!-- ==========================spring和MyBatis完美整合=========================== --&gt; &lt;!-- mybatis的主配置文件中的所有配置，都可以在SqlSessionFactoryBean中进行配置 --&gt; &lt;bean class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot; id=&quot;sqlSessionFactory&quot;&gt; &lt;!-- 指定数据源 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!-- 指定映射文件 --&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/*.xml&quot; /&gt; &lt;!-- 指定别名 --&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.ssm.bean&quot; /&gt; &lt;!-- 配置分页插件 --&gt; &lt;property name=&quot;plugins&quot;&gt; &lt;set&gt; &lt;bean class=&quot;com.github.pagehelper.PageInterceptor&quot; /&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- SqlSessionTemplate是线程安全的 --&gt; &lt;bean class=&quot;org.mybatis.spring.SqlSessionTemplate&quot; id=&quot;sessionTemplate&quot;&gt; &lt;constructor-arg name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactory&quot; /&gt; &lt;constructor-arg name=&quot;executorType&quot; value=&quot;BATCH&quot; /&gt; &lt;/bean&gt; &lt;!-- 扫描dao接口，将dao接口的实现类添加到ioc容器（Root WebApplicationContext）中 --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.ssm.dao&quot; /&gt; &lt;/bean&gt; &lt;!-- ========================================================================== --&gt;&lt;/beans&gt; jdbc.properties： 1234driver=com.mysql.cj.jdbc.Driverurl=jdbc:mysql://locaohost:3306/ssm?serverTimezone=UTCuser=rootpassword=admin 关于SqlSessionTemplate：对于SqlSessionTemplate的理解 整合spring事务管理关于spring中基于xml的声明式事务要注意的一个点： 在基于XML的声明式事务中，事务属性的tx: method是必须配置的，如果某个方法没有对应的tx: method配置，那么事务对这个方法就不生效，即不会使用默认值 。 spring-service.xml： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop https://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 配置service层：扫描 service 包；配置事务管理 --&gt; &lt;!-- 扫描service --&gt; &lt;context:component-scan base-package=&quot;com.ssm.service&quot; /&gt; &lt;!-- =========配置事务管理========= --&gt; &lt;bean class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot; id=&quot;transactionManager&quot;&gt; &lt;!-- 指定控制的数据源 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;/bean&gt; &lt;!-- 也可以配置基于注解的声明式事务 --&gt; &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; /&gt; &lt;!-- 使用 xml 配置事务管理 --&gt; &lt;!-- 配置事务属性，即配置事务的传播行为，隔离级别等 --&gt; &lt;!-- advice默认指定id为transactionManager的事务管理器，所以若是配置的事务管理器id不是该值，则需显示指定 事务管理器 --&gt; &lt;tx:advice id=&quot;txAdvice&quot;&gt; &lt;tx:attributes&gt; &lt;!-- name属性指定当前method标签配置的事务属性要应用到哪些方法 如第二个method标签指定对所有get开头的方法应用只读属性（只能查询）--&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;tx:method name=&quot;get*&quot; read-only=&quot;true&quot;/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 配置事务的切入点 --&gt; &lt;aop:config&gt; &lt;aop:pointcut id=&quot;txPoint&quot; expression=&quot;execution(* com.ssm.service..*(..))&quot;/&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;txPoint&quot; /&gt; &lt;/aop:config&gt; &lt;!-- ===================================================== --&gt;&lt;/beans&gt; &emsp; spring配置文件将 mybatis、service 整合进 spring Root ApplicationContext。 rootApplicationContext.xml： 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 导入整合mybatis的相关配置 --&gt; &lt;import resource=&quot;classpath:ssm/spring-mybatis.xml&quot; /&gt; &lt;!-- 导入 service 相关配置 --&gt; &lt;import resource=&quot;classpath:ssm/spring-service.xml&quot; /&gt;&lt;/beans&gt; &emsp; 日志配置文件log4j2的配置文件（log4j2.xml），该配置主要打印sql语句执行日志： 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot; monitorInterval=&quot;30&quot;&gt; &lt;Properties&gt; &lt;property name=&quot;PATTERN&quot;&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%t-%L] %-5level %logger&#123;36&#125; - %msg%n&lt;/property&gt; &lt;/Properties&gt; &lt;Appenders&gt; &lt;Console name=&quot;consolePrint&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;%d&#123;HH:mm:ss&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n&quot; /&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;!--然后定义logger，只有定义了logger并引入的appender，appender才会生效 --&gt; &lt;Loggers&gt; &lt;logger name=&quot;com.ssm.dao&quot; level=&quot;DEBUG&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;consolePrint&quot;/&gt; &lt;/logger&gt; &lt;!-- 配置日志的根节点 --&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;consolePrint&quot; /&gt; &lt;/root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; &emsp; web.xml配置文件web.xml： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384&lt;!DOCTYPE web-app PUBLIC &quot;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN&quot; &quot;http://java.sun.com/dtd/web-app_2_3.dtd&quot; &gt;&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;!-- spring配置文件的位置 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:ssm/rootApplicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- log4j配置文件的位置--&gt; &lt;context-param&gt; &lt;param-name&gt;log4jConfiguration&lt;/param-name&gt; &lt;param-value&gt;classpath:log4j2.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 防止Spring内存溢出监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.util.IntrospectorCleanupListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 通过配置ContextLoaderListener，让其创建Spring的应用上下文（Root ApplicationContext）--&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 服务器关闭时关闭驱动的监听器 --&gt; &lt;listener&gt; &lt;listener-class&gt;com.ssm.listener.DriverMangerListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置DispatcherServlet --&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:ssm/spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 过滤器配置 --&gt; &lt;!-- 字符编码过滤器，该过滤器一般位于所有过滤器之前 --&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- HiddenHttpMethodFilter用于将post请求转换为指定请求 --&gt; &lt;filter&gt; &lt;filter-name&gt;hiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;hiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 当客户端发送PUT、DELETE、PATCH请求时，该过滤器会将其中的参数信息进行处理，以 便可以通过HttpRequest对象的getParameter方法获取到参数数据 --&gt; &lt;filter&gt; &lt;filter-name&gt;FormContentFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.FormContentFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;FormContentFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; &emsp; web.xml中的FormContentFilter： 在前端，可以通过Ajax直接发送DELETE、PUT等post、get之外的请求，但tomcat对于post之外的请求，并不会将其中的参数数据封装进request对象，从而不能通过request的getParameter方法可以获取到这些参数。而springMVC是使用getParameter方法来获取数据封装进控制器方法的JavaBean形参，所以导致了封装不了JavaBean的信息。 FormContentFilter可以对DELETE、PUT请求中的参数数据进行处理，让springMVC可以正常封装JavaBean形参。 关于IntrospectorCleanupListener：IntrospectorCleanupListener作用 &emsp; Mybatis-Generator使用mybatis逆向工程身材mapper及其配置文件。 配置文件（generator/generatorConfig.xml）： 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;generatorConfiguration&gt; &lt;classPathEntry location=&quot;mysql驱动包绝对路径&quot;/&gt; &lt;context id=&quot;simple&quot; targetRuntime=&quot;MyBatis3Simple&quot;&gt; &lt;!-- 配置生成的类不带注释 --&gt; &lt;commentGenerator&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot; /&gt; &lt;/commentGenerator&gt; &lt;!-- 配置数据库连接信息 --&gt; &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql://127.0.0.1:3306/ssm?serverTimezone=UTC&quot; userId=&quot;root&quot; password=&quot;admin&quot;/&gt; &lt;!--指定生成的JavaBean的位置 --&gt; &lt;javaModelGenerator targetPackage=&quot;com.ssm.bean&quot; targetProject=&quot;src/main/java&quot;/&gt; &lt;!-- 指定映射文件的生成位置 --&gt; &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/resources&quot;/&gt; &lt;!-- 指定dao接口生成的位置 --&gt; &lt;javaClientGenerator targetPackage=&quot;com.ssm.dao&quot; targetProject=&quot;src/main/java&quot; type=&quot;XMLMAPPER&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定每个表的生成策略 --&gt; &lt;table tableName=&quot;employees&quot; domainObjectName=&quot;Employee&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;true&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;true&quot; selectByExampleQueryId=&quot;false&quot;/&gt; &lt;table tableName=&quot;dept&quot; domainObjectName=&quot;Department&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;true&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;true&quot; selectByExampleQueryId=&quot;false&quot;/&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; &emsp; 参考 【SSM】Eclipse使用Maven创建Web项目+整合SSM框架 SSM框架——详细整合教程（Spring+SpringMVC+MyBatis） 使用Log4j2打印Mybatis SQL语句以及结果集 手把手教你整合最优雅SSM框架","categories":[],"tags":[]},{"title":"Mybatis逆向工程","slug":"框架/Mybatis逆向工程","date":"2020-11-04T10:33:15.236Z","updated":"2020-11-07T10:04:44.888Z","comments":true,"path":"2020/11/04/框架/Mybatis逆向工程/","link":"","permalink":"http://example.com/2020/11/04/%E6%A1%86%E6%9E%B6/Mybatis%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B/","excerpt":"","text":"概述Mybatis逆向工程（Mybatis Generator）用于根据配置文件自动生成数据表对应的JavaBean，以及dao接口和映射文件。 该示例以Maven的插件形式运行Mybatis逆向工程。（Maven项目） pom.xml中添加插件12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;configuration&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; &emsp; 数据表示例以dept表（部门）和employees表（员工）为例。员工的d_id指向dept的主键。 dept： employees： &emsp; 创建配置文件创建连接数据库相关信息的jdbc.properties文件以及逆向工程的配置文件generatorConfig.xml。放在resource目录下。并将MySQL jdbc驱动包放在resource下（这里使用的是mysql-connector-java-5.1.47.jar）。 PS：mybatis-generator插件默认在resource目录下查找generatorConfig.xml配置文件，所以这里的generatorConfig.xml配置文件要注意位置与命名。 jdbc.properties： 1234driver=com.mysql.jdbc.Driverurl=jdbc:mysql://127.0.0.1:3306/ssm?serverTimezone=UTCuser=rootpassword=admin &emsp; generatorConfig.xml： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071&lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;generatorConfiguration&gt; &lt;!--导入properties配置文件--&gt; &lt;properties resource=&quot;jdbc.properties&quot;&gt;&lt;/properties&gt; &lt;!--指定特定数据库的jdbc驱动jar包的位置--&gt; &lt;classPathEntry location=&quot;驱动包的绝对路径&quot;/&gt; &lt;context id=&quot;default&quot; targetRuntime=&quot;MyBatis3&quot;&gt; &lt;!-- 配置生成的类不带注释（建议，因为生成的注释没啥用） --&gt; &lt;commentGenerator&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot;/&gt; &lt;/commentGenerator&gt; &lt;!--jdbc的数据库连接 --&gt; &lt;jdbcConnection driverClass=&quot;$&#123;driver&#125;&quot; connectionURL=&quot;$&#123;url&#125;&quot; userId=&quot;$&#123;user&#125;&quot; password=&quot;$&#123;password&#125;&quot; /&gt; &lt;!-- 指定生成的JavaBean的包位置, 用来生成含有主键key的类，记录类 以及查询Example类 不用事先创建好包结构，mybatis-generator会根据配置自动创建，sqlMapGenerator同 targetPackage 指定生成的JavaBean生成所在的包名 targetProject 指定在该项目下所在的路径 --&gt; &lt;javaModelGenerator targetPackage=&quot;com.generator.bean&quot; targetProject=&quot;src/main/java&quot;&gt; &lt;!-- 是否允许子包，即targetPackage.schemaName.tableName --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot;/&gt; &lt;!-- 是否对model添加 构造函数 --&gt; &lt;property name=&quot;constructorBased&quot; value=&quot;true&quot;/&gt; &lt;!-- 建立的Model对象是否 不可改变 即生成的Model对象不会有 setter方法，只有构造方法 --&gt; &lt;property name=&quot;immutable&quot; value=&quot;false&quot;/&gt; &lt;/javaModelGenerator&gt; &lt;!--Mapper映射文件生成所在的目录 为每一个数据库的表生成对应的SqlMap文件 --&gt; &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/resources&quot; /&gt; &lt;!-- 指定dao接口（mapper）的位置 type=&quot;ANNOTATEDMAPPER&quot;,生成Java Model 和基于注解的Mapper对象 type=&quot;MIXEDMAPPER&quot;,生成基于注解的Java Model 和相应的Mapper对象 type=&quot;XMLMAPPER&quot;,生成SQLMap XML文件和独立的Mapper接口 --&gt; &lt;javaClientGenerator targetPackage=&quot;com.generator.dao&quot; targetProject=&quot;src/main/java&quot; type=&quot;XMLMAPPER&quot;&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定每个表的生成策略 配置数据表与JavaBean的名称映射，以及是否创建根据条件查询的sql语句等 --&gt; &lt;!-- tableName指定表名，domainObjectName指定表对应的JavaBean名 --&gt; &lt;table tableName=&quot;dept&quot; domainObjectName=&quot;Department&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;true&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;true&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;/table&gt; &lt;table tableName=&quot;employees&quot; domainObjectName=&quot;Employee&quot; enableCountByExample=&quot;false&quot; enableUpdateByExample=&quot;true&quot; enableDeleteByExample=&quot;false&quot; enableSelectByExample=&quot;true&quot; selectByExampleQueryId=&quot;false&quot;&gt; &lt;/table&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; &emsp; 插件相关配置在maven窗口配置一个插件运行。 分别填入项目的目录以及命令mybatis-generator:generate -e： OK。 &emsp; 运行Generator打开maven窗口可看到： &emsp; 双击即可运行generator。 运行后的项目目录，可看到创建了JavaBean、dao以及映射文件： &emsp; XxxExample的使用通过逆向工程生成的JavaBean中可以看到有XxxExample的类，这些类的作用是用于设置查询条件。 简单的示例： 123456789101112131415@Testpublic void testEmployeeExample() throws IOException &#123; SqlSession session = getSqlSession();//获取SqlSession（方法具体实现省略） //创建一个example类 EmployeeExample example = new EmployeeExample(); //查询employees表中did为1的记录 example.or().andDIdEqualTo(1); EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); List&lt;Employee&gt; employees = mapper.selectByExample(example); for(Employee e : employees)&#123; System.out.println(e); &#125;&#125; &emsp; 又如：通过模糊查询，查询EmpName包含“三”的记录。 12EmployeeExample example = new EmployeeExample();example.or().andEmpNameLike(&quot;%三%&quot;); &emsp; 其他的添加查询条件的方法：（来自https://blog.csdn.net/biandous/article/details/65630783） 方法 说明 example.setOrderByClause(“字段名 ASC”); 添加升序排列条件，DESC为降序 example.setDistinct(false) 去除重复，boolean型，true为选择不重复的记录。 criteria.andXxxIsNull 添加字段xxx为null的条件 criteria.andXxxIsNotNull 添加字段xxx不为null的条件 criteria.andXxxEqualTo(value) 添加xxx字段等于value条件 criteria.andXxxNotEqualTo(value) 添加xxx字段不等于value条件 criteria.andXxxGreaterThan(value) 添加xxx字段大于value条件 criteria.andXxxGreaterThanOrEqualTo(value) 添加xxx字段大于等于value条件 criteria.andXxxLessThan(value) 添加xxx字段小于value条件 criteria.andXxxLessThanOrEqualTo(value) 添加xxx字段小于等于value条件 criteria.andXxxIn(List&lt;？&gt;) 添加xxx字段值在List&lt;？&gt;条件 criteria.andXxxNotIn(List&lt;？&gt;) 添加xxx字段值不在List&lt;？&gt;条件 criteria.andXxxLike(“%”+value+”%”) 添加xxx字段值为value的模糊查询条件 criteria.andXxxNotLike(“%”+value+”%”) 添加xxx字段值不为value的模糊查询条件 criteria.andXxxBetween(value1,value2) 添加xxx字段值在value1和value2之间条件 criteria.andXxxNotBetween(value1,value2) 添加xxx字段值不在value1和value2之间条件 &emsp; 以上方法都可以通过example类的or()方法调用（如示例），推荐使用这种方式。 使用or()方法添加多个条件时要注意： 若是要添加多个AND条件，应是这种方式： **example.or().andXxx1(xx).andXxx2(xx).addXxx3(xx);**。 若是使用以下方式，添加的多个条件将是OR条件： 123example.or().andXxx1(xx);example.or().andXxx2(xx);example.or().andXxx3(xx); &emsp; 参考 https://blog.csdn.net/for_my_life/article/details/51228098 https://blog.csdn.net/biandous/article/details/65630783 &emsp;","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://example.com/Tag/Mybatis/"}]},{"title":"Mybatis的使用","slug":"框架/Mybatis的基本使用","date":"2020-11-04T09:45:23.039Z","updated":"2020-11-15T06:31:27.912Z","comments":true,"path":"2020/11/04/框架/Mybatis的基本使用/","link":"","permalink":"http://example.com/2020/11/04/%E6%A1%86%E6%9E%B6/Mybatis%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","excerpt":"","text":"概述中文文档： https://mybatis.org/mybatis-3/zh/index.html MyBatis 是支持定制化 SQL，存储过程和高级映射的优秀持久层框架。MyBatis 消除了几乎所有的JDBC代码和参数的手工设置以及结果集的检索。MyBatis 使用简单的 XML或注解用于配置和原始映射，将接口和 Java 的POJO映射成数据库中的记录。它内部封装了 jdbc，使开发者能更专注于 SQL 代码， 而不需要花费精力去处理加载驱动、创建连接、创建 statement 等繁杂的过程。 QuickStart该示例基于IDEA的Maven项目。 导入依赖主要是导入mybatis和mysql jdbc驱动包依赖。 123456789101112131415161718192021222324&lt;!-- 两个必须导入的依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 使用lombok可以通过使用@Data注解修饰entity类，从而使Lombok为该类自动生成getter、setter、constructor以及toString。 使用前需在idea中安装Lombok插件：【Settings】-》【Plugins】，搜索Lombok，安装即可。 若不使用Lombok则后述的User类注意添加getter、setter等。 创建实体类、数据表以及dao接口（Mapper）包结构： user表： User 123456@Datapublic class User &#123; private Integer id; private String username; private String password;&#125; UserMapper 123public interface UserMapper &#123; User selectById(Integer id);&#125; Mybatis中，把dao接口称为Mapper（映射器）。 创建映射文件在resource目录下创建Mapper对应的xml配置文件，Mapper对应的xml文件在resource中的目录结构要与Mapper的包结构保持一致，如图： PS：IDEA的Maven项目中，在resource目录下不能创建package，只能创建redirect，且创建目录时，需一层一层创建，这样在磁盘中才会有对应的目录结构，若在创建时使用 com.entity的命名方式，则在磁盘中只会创建一个名为com.entity的目录 UserMapper.xml： 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.dao.UserMapper&quot;&gt; &lt;!-- #&#123;id&#125;将会接收UserMapper.selectById方法中的id参数 --&gt; &lt;select id=&quot;selectById&quot; resultType=&quot;com.entity.User&quot; &gt; select * from user where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 创建主配置文件主配置文件用于用于配置数据源，事务管理器，映射文件位置等其他全局设置。一般命名为SqlMapConfig.xml，放在resource目录下。 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;!-- default属性指定配置的environment中某一个的id --&gt; &lt;environments default=&quot;development&quot;&gt; &lt;!-- 配置连接数据库的相关信息 --&gt; &lt;environment id=&quot;development&quot;&gt; &lt;!-- 事务管理器 --&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test?serverTimezone=UTC&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;admin&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 指定映射配置文件的路径，注意分隔符是 / 而不是 . --&gt; &lt;mappers&gt; &lt;mapper resource=&quot;com/mapper/UserMapper.xml&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 获取SqlSession，进行数据库操作测试方法： 1234567891011121314151617181920212223242526@Testpublic void test() throws IOException &#123; //获取主配置文件的输入流 InputStream in = Resources.getResourceAsStream(&quot;sqlMapConfig.xml&quot;); //创建SqlSessionFactoryBuilder SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); //通过SqlSessionFactoryBuilder加载输入流，创建工厂 SqlSessionFactory factory = builder.build(in); //通过工厂创建SqlSession对象 SqlSession sqlSession = factory.openSession(); //通过SqlSession对象获取Dao的代理对象 UserDao userDao = sqlSession.getMapper(UserDao.class); //执行数据库操作 User user = userDao.selectById(1); System.out.println(&quot;user = &quot; + user); //关闭sqlSession sqlSession.close();&#125; 执行test方法，输出：user = User(id=1, username=张三, password= 123456) over. 获取SqlSession步骤步骤如下： 读取配置文件。通过org.apache.ibatis.io.Resources类的getResourceAsStream()静态方法获取主配置文件的输入流： InputStream in = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;); 创建SqlSessionFactory工厂。SqlSessionFactory不能直接通过构造器创建，需先创建一个SqlSessionFactoryBuilder，再通过builder加载上述创建的输入流，创建工厂对象： 12SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder();SqlSessionFactory factory = builder.builde(in);//传入主配置文件的输入流 通过工厂创建SqlSession对象。 SqlSession session = factory.openSession(); 通过session获取dao接口的代理对象（也可以不使用代理对象，直接使用session对象的方法实现数据库操作，如selectAll()等） XxxDao dao = session.getMapper(XxxDao.class); 使用该dao代理对象执行方法，进行数据库操作。 SqlSession简介SqlSession对象是Mybatis中的一个主要接口，可以通过这个接口来执行命令，获取映射器示例和管理事务。 SqlSession提供了之间操作数据库的方法，如：session.selectOne(&quot;org.mybatis.example.BlogMapper.selectBlog&quot;, 101)。但一般不使用这些方法，而是通过配置Mapper（即dao接口）的映射文件，再通过SqlSession获取Mapper的代理对象。 SqlSession由SqlSessionFactory创建，SqlSessionFactory的openSession方法有一个重载形式：openSession(boolean autoCommit)，autoCommit指定是否自动提交（即是否开启事务），默认是false，即开启事务。所以默认情况下执行update、delte和insert语句时需要提交事务，即执行SqlSession的commit()方法，否则将造成事务回滚。也可以通过openSession(true)来获取关闭事务的SqlSession。 另外，SqlSession 对象不是线程安全的，所以每个线程都应该有它自己的 SqlSession 对象，且每次执行完数据库操作后，应关闭SqlSession：session.close()。 最佳作用域 SqlSessionFactoryBuilder 创建了SqlSessionFactory后，就不再需要SqlSessionFactoryBuilder，所以其最佳作用域是方法作用域，即声明为局部变量。 SqlSessionFactory SqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在。因为SqlSession需要每次使用完都执行关闭操作，因此每一次进行数据库操作需通过SqlSessionFactory 获取SqlSession。 因此 SqlSessionFactory 的最佳作用域是应用作用域。 最简单的就是使用单例模式或者静态单例模式。 SqlSession SqlSession 对象不是线程安全的，每个线程都应该有它自己的 SqlSession 对象。所以SqlSession的最佳作用域是请求或方法作用域。 不能将 SqlSession 实例的引用放在一个类的静态域，甚至一个类的实例变量。 也绝不能将 SqlSession 实例的引用放在任何类型的托管作用域中，比如 Servlet 框架中的 HttpSession。如果使用一种 Web 框架，可以将 SqlSession 放在一个和 HTTP 请求相似的作用域中。 且每次使用完SqlSession，都应该执行关闭操作。 主配置文件文件结构主配置文件结构：（详细说明见官方文档：https://mybatis.org/mybatis-3/zh/configuration.html） configuration（配置） properties（属性) settings（设置） typeAliases（类型别名） typeHandlers（类型处理器) objectFactory（对象工厂） plugins（插件） environments（环境配置） environment（环境变量） transactionManager（事务管理器） dataSource（数据源） databaseIdProvider（数据库厂商标识） mappers（映射器） 以下介绍几个常用标签。其他标签的具体使用见官方文档。 &lt;properties&gt;该标签的作用是配置连接数据库的相关参数信息。可以通过&lt;property&gt;子标签配置，也可以使用resource属性引用外部配置文件，两种方式可以混合使用。在配置&lt;dataSource&gt;时，通过$&#123;paramName&#125;的方式获取到配置的值。 如快速入门中主配置文件可改为： 12345678910111213141516//...省略&lt;properties resource=&quot;jdbc.properties&quot; /&gt;&lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;$&#123;driver&#125;&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt;//...省略 jdbc.properties：（该文件放在resource目录下） 1234driver=com.mysql.jdbc.Driverurl=jdbc:mysql://127.0.0.1:3306/test?serverTimezone=UTCusername=rootpassword=admin 一般把属性信息都配置在properties文件中，不使用property标签配置。 &lt;settings&gt;&lt;settings&gt; 用来配置mybatis的一些全局变量，以开启延迟加载为例： 123&lt;settings&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt;&lt;/settings&gt; mybatis有很多全局变量，其他变量的详细介绍见：https://mybatis.org/mybatis-3/zh/configuration.html#settings &lt;typeAliases&gt;该标签的作用是为Java类指定一个缩写别名，就不用每次指定类时都使用其全限定名。 如： type属性指定类的全限定名；alias属性指定别名。 123&lt;typeAliases&gt; &lt;typeAlias alias=&quot;author&quot; type=&quot;domain.blog.Author&quot;/&gt;&lt;/typeAliases&gt; 通过该配置，在任何使用 domain.blog.Autho 的地方，都可以用author代替，且不区分大小写。 也可以在&lt;typeAliases&gt; 标签中使用&lt;package&gt;标签指定一个包名，对该包下的所有类会使用 Bean 的首字母小写的非限定类名来作为它的别名。如domain.blog.Blog的别名为blog。这种方法更被推荐使用。 例子： 123&lt;typeAliases&gt; &lt;package name=&quot;domain.blog&quot;/&gt;&lt;/typeAliases&gt; &lt;environments&gt;&lt;environments&gt;用于配置环境。可以配置多个数据库环境，但只能选择一种环境，通过default指定要使用的&lt;environment&gt; 的id。每个 SqlSessionFactory 实例只能对应一种环境，如想要连接两个数据库，则需要两个SqlSessionFactory 。 在&lt;environments&gt;通过&lt;transactionManager&gt; 来配置事务管理器。 以下来自官网： 在 MyBatis 中有两种类型的事务管理器（也就是 type=”[JDBC|MANAGED]”）： JDBC – 这个配置直接使用了 JDBC 的提交和回滚设施，它依赖从数据源获得的连接来管理事务作用域。 MANAGED – 这个配置几乎没做什么。它从不提交或回滚一个连接，而是让容器来管理事务的整个生命周期（比如 JEE 应用服务器的上下文）。 默认情况下它会关闭连接。然而一些容器并不希望连接被关闭，因此需要将 closeConnection 属性设置为 false 来阻止默认的关闭行为 如果使用的是Spring + MyBatis，则没有必要配置事务管理器，因为 Spring 模块会使用自带的管理器来覆盖前面的配置。 &lt;dataSource&gt; 元素使用标准的 JDBC 数据源接口来配置 JDBC 连接对象的资源。在&lt;dataSource&gt;通过type属性指定数据源类型，Mybatis提供了3种数据源类型： UNPOOLED：每次请求数据库连接时打开一个连接，使用完时关闭连接。没有使用连接池的概念。适用那些对数据库连接可用性要求不高的简单应用程序。 POOLED：使用了连接池，避免了创建新的连接实例时所必需的初始化和认证时间。 JNDI：放置一个 JNDI 上下文的数据源引用。 示例： 1234567891011&lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;$&#123;driver&#125;&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;url&#125;&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;password&#125;&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt;&lt;/environments&gt; &lt;mappers&gt;该标签用于指定映射文件的位置，即告诉Mybatis要到哪里去找Mapper对应的映射文件。 有多种配置方式： 使用第一种方式时，是在resource目录下（类路径下）寻找映射文件。映射文件的目录结构要与其对应的Mapper的包结构一致，如org/mybatis/builder/UserMapper.xml对应org.mybatis.builder.UserMapper。**且要注意分隔符是 / 而不是 . ** 12345678910111213141516&lt;!-- 使用相对于类路径的资源引用 --&gt;&lt;mappers&gt; &lt;mapper resource=&quot;org/mybatis/builder/UserMapper.xml&quot;/&gt;&lt;/mappers&gt;&lt;!-- 使用映射器接口实现类的完全限定类名 --&gt;&lt;mappers&gt; &lt;mapper class=&quot;org.mybatis.builder.AuthorMapper&quot;/&gt;&lt;/mappers&gt;&lt;!-- 将包内的映射器接口实现全部注册为映射器 --&gt;&lt;mappers&gt; &lt;package name=&quot;org.mybatis.builder&quot;/&gt;&lt;/mappers&gt; 基本CRUD以及参数映射#{}和${}默认情况下，使用 #&#123;&#125; 时，MyBatis 会创建 PreparedStatement 参数占位符，并通过占位符安全地设置参数（就像使用 ? 一样）。 但PreparedStatement 的占位符不能用于一些元数据字段，如表名、列名。这时可以使用$&#123;&#125;，mybatis会直接插入一个不转义的字符串。 如要查询某个字段名为指定值的记录，不用在mapper中定义多个查询方法，如：findById()、findByUsername()。可以直接用一个方法：其中columnName指字段名，value指字段值 1User selectByColumn(@Param(&quot;columnName&quot;) String columnName, @Param(&quot;value&quot;) String value); 映射文件中的sql语句： 123&lt;select id=&quot;selectByColumn&quot; resultType=&quot;user&quot;&gt; select * from user where $&#123;columnName&#125;=#&#123;value&#125;&lt;/select&gt; 其中columnName将直接替换$&#123;columnName&#125;。 一般优先使用#&#123;&#125;，其使用的是PreparedStatement会更加安全。而$&#123;&#125;可能会引起SQL注入。 参数映射 对于方法形参到sql语句的参数映射： 当Mapper方法只有一个参数时，#&#123;&#125;内的值无需与方法形参名对应，可以任意指定。若是有多个形参： 以param加上形参在参数列表中的位置来命名（从1开始），比如：#&#123;param1&#125;、#&#123;param2&#125;。 使用@Param注解修饰形参，通过其value属性自定义命名，并在#&#123;&#125;内使用对应命名。 当传入的参数的一个JavaBean，要获取其属性，通过#&#123;属性名&#125;即可。（若是bean中含bean，则使用#&#123;innerBean.paramName&#125;的形式） parameterType属性可以指定传入的参数类型。该属性是可选的，一般情况下mybatis都可以推断出具体传入语句的参数类型。 对于sql语句到返回值的参数映射： 通过resultType属性可以指定返回值类型。且当返回值是集合时，返回类型不是设置为集合，而是应指定其集合元素的类型。resultType适用于表的字段名与JavaBean的成员变量名一一对应的情况，MyBatis 会获取结果中返回的列名并在 Java 类中查找相同名字的属性（忽略大小写）。若是不对应将会抛出异常。这种情况可以使用&lt;resultMap&gt;标签。 PS：当使用#&#123;&#125;从传入的对象中获取其属性值时是区分大小写的，如User对象有一个userName属性，若使用#&#123;username&#125;，Mybatis将会找不到userName属性，抛出异常。 &lt;resultMap&gt;标签可以对表字段与JavaBean属性不对应的情况进行手动映射。且手动映射与自动映射会相互配合。即在&lt;resultMapL&gt;中可以只手动映射不对应的字段，那些对应的字段可以省略，Mybatis会进行自动映射处理。&lt;resultMap&gt;配置完毕后，在&lt;select&gt; 等标签中通过resultMap属性引用。 返回类型的配置不能省略。 &lt;resultMap&gt;示例： Book类： 1234567public class Book &#123; private Integer id; private String bookName; private String bookAuthor; private Integer price; //getter、setter、toString&#125; book表： 可看到Book类的bookName、bookAuthor属性与book表的book_name，author不对应。 映射文件的配置： &lt;resultMap&gt;的id属性唯一标识该映射。 type属性指定要映射的JavaBean类；id标签用于映射主键，result标签用于映射普通字段。property属性指定JavaBean的属性名，column属性指定表的字段名。 在select标签中使用resultMap=&quot;bookMap&quot;引用配置的映射。 12345678&lt;resultMap id=&quot;bookMap&quot; type=&quot;book&quot;&gt; &lt;id property=&quot;bookName&quot; column=&quot;book_name&quot; /&gt; &lt;result property=&quot;bookAuthor&quot; column=&quot;author&quot; /&gt;&lt;/resultMap&gt;&lt;select id=&quot;selectById&quot; resultMap=&quot;bookMap&quot;&gt; select * from book where id=#&#123;id&#125;&lt;/select&gt; 测试方法： 123456789101112@Testpublic void test() throws IOException &#123; SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); InputStream stream = Resources.getResourceAsStream(&quot;sqlMapConfig.xml&quot;); SqlSessionFactory factory = builder.build(stream); SqlSession session = factory.openSession(); BookMapper mapper = session.getMapper(BookMapper.class); Book book = mapper.selectById(1); System.out.println(book);&#125;//输出：Book(id=1, bookName=Java疯狂讲义, bookAuthor=李刚, price=100) &lt;select&gt; ★下文例子中的user表：其中，id是自增主键 User类： 123456public class User &#123; private Integer id; private String username; private String password; //...set、getter,toString&#125; ---------------- 直接上例子： UserMapper中查询相关方法定义： 1234567891011//根据id查询User selectById(Integer id);//查询全部，返回类型是集合List&lt;User&gt; selectAll();//模糊查询。查询username中带有keyword的用户List&lt;User&gt; selectByFuzzy(String keyword);//根据指定字段和其字段值查询User selectByColumn(String columnName, String value); 对应的映射文件： 123456789101112131415&lt;select id=&quot;selectById&quot; resultType=&quot;user&quot; &gt; select * from user where username = #&#123;id&#125;&lt;/select&gt;&lt;select id=&quot;selectAll&quot; resultType=&quot;user&quot;&gt; select * from user&lt;/select&gt;&lt;select id=&quot;selectByFuzzy&quot; resultType=&quot;user&quot;&gt; select * from user where username like #&#123;keyword&#125;&lt;/select&gt;&lt;select id=&quot;selectByColumn&quot; resultType=&quot;user&quot;&gt; select * from user where $&#123;param1&#125;=#&#123;param2&#125;&lt;/select&gt; 要注意的点： select标签中的id属性指定的是Mapper中的方法名。（对后文的&lt;insert&gt;等标签一样） resultType属性指定返回值类型。例子中的user指User类，已使用别名。 注意selectAll方法的返回值的List集合，而对应select标签的resultType属性是List的元素User。 selectByColumn是根据字段名跟字段值进行查询。与上文例子相同。该mapper方法有两个参数，在sql语句中使用param+形参位置的形式映射参数。 在测试方法中，调用mapper的selectByFuzzy方法时，传入的参数是%小%。即进行模糊查询时，要注意传参时先拼接好通配符。 测试方法： 测试类中使用了Junit的@Before初始化了SqlSessionFactory，并作为测试类的成员变量： 12345678private SqlSessionFactory factory;@Beforepublic void initFactory() throws IOException &#123; SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); InputStream in = Resources.getResourceAsStream(&quot;sqlMapConfig.xml&quot;); factory = builder.build(in);&#125; 1234567891011121314151617181920212223242526272829303132333435363738@Testpublic void testSelect()&#123; try(SqlSession session = factory.openSession();)&#123; UserMapper mapper = session.getMapper(UserMapper.class); User user = mapper.selectById(2); System.out.println(&quot;id为2的User: &quot; + user); List&lt;User&gt; users = mapper.selectAll(); System.out.println(&quot;所有User: &quot;); for (User u : users)&#123; System.out.println(u); &#125; //查询用户名中带有‘小’的用户 List&lt;User&gt; users2 = mapper.selectByFuzzy(&quot;%小%&quot;); System.out.println(&quot;用户名中带有 小 的用户：&quot;); for(User u : users2)&#123; System.out.println(u); &#125; User user1 = mapper.selectByColumn(&quot;username&quot;, &quot;张三&quot;); System.out.println(&quot;查询username字段为张三的记录：&quot; + user1); &#125;&#125;/**输出：id为2的User: User(id=2, username=李四, password=5896596)所有User: User(id=1, username=张三, password=123456)User(id=2, username=李四, password=5896596)User(id=3, username=王小强, password=666666)User(id=4, username=许小红, password=777777)用户名中带有 小 的用户：User(id=3, username=王小强, password=666666)User(id=4, username=许小红, password=777777)查询username字段为张三的记录：User(id=1, username=张三, password=123456)*/ &lt;insert&gt; ★同上，直接看例子。 Mapper方法定义： 1void insert(User user); 对应的映射文件配置： 123&lt;insert id=&quot;insert&quot; parameterType=&quot;user&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt; insert into user values(null, #&#123;username&#125;, #&#123;password&#125;)&lt;/insert&gt; 测试方法： 123456789101112131415@Testpublic void testInsert()&#123; try(SqlSession sqlSession=factory.openSession())&#123; UserMapper mapper = sqlSession.getMapper(UserMapper.class); User user = new User(); user.setUsername(&quot;蜘蛛侠&quot;); user.setPassword(&quot;555969&quot;); mapper.insert(user); System.out.println(&quot;执行插入后，获取user的id值：&quot; + user.getId()); //提交事务 sqlSession.commit(); &#125;&#125;//输出：执行插入后，获取user的id值：11 要注意的点： 注意到sql语句并没有插入id值（id是自增主键），可以通过useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;的配置，获取执行插入操作后新记录的主键值，获取的主键值会返回给传入的JavaBean；keyProperty指定的是表的字段名，，如例子中执行插入操作后，把插入记录的id值赋值给user对象。 也可以通过&lt;selectKey&gt;标签实现：（order属性值表示插入后或插入前获取主键） 123456&lt;insert id=&quot;insert&quot; parameterType=&quot;user&quot;&gt; &lt;selectKey keyProperty=&quot;id&quot; order=&quot;AFTER&quot; resultType=&quot;int&quot;&gt; select LAST_INSERT_ID(); &lt;/selectKey&gt; insert into user values(null, #&#123;username&#125;, #&#123;password&#125;)&lt;/insert&gt; 在测试方法的最后，有一句sqlSession.commit();，mybatis默认开启事务，即autoCommit属性为false，所以执行插入操作后需要提交事务。也可以在获取sqlSession时指定autoCommit属性为true，如下： **SqlSession sqlSession=factory.openSession(true)**（更新、删除操作也一样） 否则操作将会回滚。 &lt;delete&gt; &amp; &lt;update&gt;这两个元素与insert大同小异。看个简单示例即可。 Mapper方法： 123void update(User user);void deleteById(Integer id); 映射文件： 1234567&lt;update id=&quot;update&quot;&gt; update user set username=#&#123;username&#125;, password=#&#123;password&#125; where id = #&#123;id&#125;&lt;/update&gt;&lt;delete id=&quot;deleteById&quot;&gt; delete from user where id=#&#123;id&#125;&lt;/delete&gt; 测试方法： 12345678910111213141516171819202122@Testpublic void testUpdate()&#123; try(SqlSession session = factory.openSession(true))&#123; UserMapper mapper = session.getMapper(UserMapper.class); User user = new User(); user.setId(3); user.setUsername(&quot;王宝强&quot;); user.setPassword(&quot;666888&quot;); mapper.update(user); System.out.println(&quot;修改了id为3的user&quot;); &#125;&#125;@Testpublic void testDelete()&#123; try(SqlSession session = factory.openSession(true))&#123; UserMapper mapper = session.getMapper(UserMapper.class); mapper.deleteById(14); System.out.println(&quot;删除了id为14的user&quot;); &#125;&#125; 抽取可复用sql语句通过&lt;sql&gt;标签定义可重用的sql语句片段，通过&lt;include&gt;标签引用。 官方文档的示例： 123456789&lt;sql id=&quot;userColumns&quot;&gt; $&#123;alias&#125;.id,$&#123;alias&#125;.username,$&#123;alias&#125;.password &lt;/sql&gt;&lt;select id=&quot;selectUsers&quot; resultType=&quot;map&quot;&gt; select &lt;include refid=&quot;userColumns&quot;&gt;&lt;property name=&quot;alias&quot; value=&quot;t1&quot;/&gt;&lt;/include&gt;, &lt;include refid=&quot;userColumns&quot;&gt;&lt;property name=&quot;alias&quot; value=&quot;t2&quot;/&gt;&lt;/include&gt; from some_table t1 cross join some_table t2&lt;/select&gt; 动态SQLMybatis的动态sql可以使用简单的配置来实现根据条件拼接sql语句。让开发者可以不用过多关注于语法方面的问题。 下文例子中的数据表（employee）： 对应的JavaBean： 12345678public class Employee &#123; private Integer id; private String name; private String gender; private String department; private Integer salary; //...set getter toString&#125; &lt;if&gt;EmployeeMapper中的方法： 1List&lt;Employee&gt; selectByConditionIf(Employee employee); 对应的映射文件： 12345&lt;select id=&quot;selectByConditionIf&quot; resultType=&quot;employee&quot;&gt; select * from employee where gender=#&#123;gender&#125; &lt;if test=&quot;name != null&quot;&gt;and name like #&#123;name&#125;&lt;/if&gt; &lt;if test=&quot;salary != null&quot;&gt;and salary&gt;#&#123;salary&#125;&lt;/if&gt;&lt;/select&gt; test属性设置了条件。当employee的相关属性不为空时，将会在where中添加对应条件。test属性中要使用传入参数的属性时，直接使用属性名即可。 where关键字后必须带有一个条件，否则当所有if条件不满足时，sql语句将会出现语法错误：select * from employee where。 若是test中的条件要用到与或非，不能使用&amp;&amp; ||等符号，应使用and not or。如author != null and author.name != null。 当所有条件都不满足，就只有gender=#&#123;gender&#125;一个条件。 测试方法： 1234567891011121314151617181920@Testpublic void testIf()&#123; try(SqlSession session = factory.openSession())&#123; EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); Employee employee = new Employee(); employee.setGender(&quot;男&quot;); employee.setName(&quot;%小%&quot;); employee.setSalary(1000); List&lt;Employee&gt; employees = mapper.selectByConditionIf(employee); for(Employee e : employees)&#123; System.out.println(e); &#125; &#125;&#125;//输出：//Employee(id=1, name=小明, gender=男, department=保安部, salary=5000)//Employee(id=3, name=小强, gender=男, department=保安部, salary=5000) &lt;choose&gt;&lt;choose&gt; 类似于Java的switch，即按顺序判断条件，若满足则拼接对应的语句，之后的条件不再判断。所有条件都不满时，则拼接&lt;otherwise&gt;中的语句。 示例： EmployeeMapper中的方法： 1List&lt;Employee&gt; selectByConditionChoose(Employee employee); 对应的映射文件： 12345678910&lt;select id=&quot;selectByConditionChoose&quot; resultType=&quot;employee&quot;&gt; select * from employee where 1=1 &lt;choose&gt; &lt;when test=&quot;name != null&quot;&gt;and name like #&#123;name&#125;&lt;/when&gt; &lt;when test=&quot;salary != null&quot;&gt;and salary&gt;#&#123;salary&#125;&lt;/when&gt; &lt;otherwise&gt; and gender=#&#123;gender&#125; &lt;/otherwise&gt; &lt;/choose&gt;&lt;/select&gt; &lt;where&gt;相比于使用if，使用&lt;where&gt;标签在sql语句中不用出现where关键字。where元素只会在子元素返回任何内容的情况下才插入 “WHERE” 子句。若子句的开头为 “AND” 或 “OR”，where元素也会将它们去除。 示例： Mapper方法： 1List&lt;Employee&gt; selectByConditionWhere(Employee employee); 映射文件： 12345678&lt;select id=&quot;selectByConditionWhere&quot; resultType=&quot;employee&quot;&gt; select * from employee &lt;where&gt; &lt;if test=&quot;gender != null&quot;&gt;and gender=#&#123;gender&#125;&lt;/if&gt; &lt;if test=&quot;name != null&quot;&gt;and name like #&#123;name&#125;&lt;/if&gt; &lt;if test=&quot;salary != null&quot;&gt;and salary&gt;#&#123;salary&#125;&lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 当有条件满足时，mybatis会插入对应where子句。若没有条件满足，则会查询所有记录。 &lt;set&gt;与&lt;where&gt;类似，可通过&lt;set&gt; 实现动态更新语句。 示例： Mapper方法： 1void updateByCondition(Employee employee); 映射文件： 12345678910&lt;update id=&quot;updateByCondition&quot;&gt; update employee &lt;set&gt; &lt;if test=&quot;name != null&quot;&gt;name = #&#123;name&#125;,&lt;/if&gt; &lt;if test=&quot;gender != null&quot;&gt;gender = #&#123;gender&#125;,&lt;/if&gt; &lt;if test=&quot;department != null&quot;&gt;department = #&#123;department&#125;,&lt;/if&gt; &lt;if test=&quot;salary != null&quot;&gt;salary = #&#123;salary&#125;&lt;/if&gt; &lt;/set&gt; where id = #&#123;id&#125;&lt;/update&gt; 测试方法： 1234567891011121314@Testpublic void testUpdateByCondition()&#123; //注意以开启事务的方式获取SqlSession try(SqlSession session = factory.openSession(true))&#123; EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); Employee employee = new Employee(); employee.setId(1); employee.setDepartment(&quot;程序员&quot;); employee.setSalary(15000); mapper.updateByCondition(employee); &#125;&#125; 执行测试方法，id为1的记录的department字段和salary字段被更新。 注意if元素里的sql语句尾部的逗号不可少（最后一个if可省略逗号），否则会发送语法错误。 当所有的if都不满足条件会发生语法错误。 &lt;foreach&gt;&lt;foreach&gt; 可以通过循环的方式获取集合中的值。尤其适合IN语句。 根据id集合查询的示例： Mapper方法： 1List&lt;Employee&gt; selectByIdsWithForeach(List&lt;Integer&gt; ids); 映射文件： 12345678&lt;select id=&quot;selectByIdsWithForeach&quot; resultType=&quot;employee&quot;&gt; select * from employee where id in &lt;foreach collection=&quot;collection&quot; index=&quot;index&quot; item=&quot;id&quot; open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt; #&#123;id&#125; &lt;/foreach&gt;&lt;/select&gt; 测试方法： 1234567891011121314151617@Testpublic void testSelectByIdsWithForeach()&#123; try(SqlSession session = factory.openSession())&#123; EmployeeMapper mapper = session.getMapper(EmployeeMapper.class); ArrayList&lt;Integer&gt; ids = new ArrayList&lt;&gt;(); //获取id为1、2、3的记录 ids.add(1); ids.add(2); ids.add(3); List&lt;Employee&gt; employees = mapper.selectByIdsWithForeach(ids); for(Employee e : employees)&#123; System.out.println(e); &#125; &#125;&#125; **&lt;foreach&gt; 的collection属性的属性值只能为list和collection**，使用别的命名比如ids会抛出以下异常： Cause: org.apache.ibatis.binding.BindingException: Parameter ‘ids’ not found. Available parameters are [collection, list] 从异常来看应该是只能使用这两种命名…. 且Mapper方法的集合形参的参数名不用跟collection属性值相对应。 Mybatis多表查询一对一(&lt;association&gt;)以学生（Student）和身份证（Card）为例，即一个学生对应一个身份证。 数据表如下：（表中的字段除了3个id字段，其他都是varchar类型，card_id是指向card的id字段的外键） card： student： （省略了setter等） Card类： 1234public class Card &#123; private Integer id; private String idNumber;&#125; Student类： 12345public class Student &#123; private Integer id; private String studentName; private Card card;&#125; 编写StudentMapper方法： 1List&lt;Student&gt; selectAll(); 映射文件（查询全部，并Student对应的Card封装进Student）： sql语句使用的是等值连接查询。 cardMap和studentMap的id标签中的column属性值，分别是cid和sid，对应查询语句结果集的字段名，这里为s.id和c.id设置了别名。 此处column属性值不能使用s.id和c.id，mybatis将无法解析。所以可通过为字段指定别名，将column值指定为对应别名。 studentMap中使用了&lt;association&gt;标签来封装Student中的Card对象。 1234567891011121314151617&lt;resultMap id=&quot;cardMap&quot; type=&quot;card&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;cid&quot; /&gt; &lt;result property=&quot;idNumber&quot; column=&quot;id_number&quot; /&gt;&lt;/resultMap&gt;&lt;resultMap id=&quot;studentMap&quot; type=&quot;student&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;sid&quot; /&gt; &lt;result property=&quot;studentName&quot; column=&quot;student_name&quot; /&gt; &lt;association property=&quot;card&quot; resultMap=&quot;cardMap&quot; /&gt;&lt;/resultMap&gt;&lt;select id=&quot;selectAll&quot; resultMap=&quot;studentMap&quot;&gt; select s.id sid,student_name,c.id cid,id_number from student s inner join card c on s.card_id=c.id;&lt;/select&gt; 测试方法： 12345678910@Testpublic void testSelectALl()&#123; try(SqlSession session = factory.openSession())&#123; StudentMapper mapper = session.getMapper(StudentMapper.class); List&lt;Student&gt; students = mapper.selectAll(); for(Student student : students)&#123; System.out.println(student); &#125; &#125;&#125; 输出： 123Student(id=2, studentName=小明, card=Card(id=1, idNumber=111111))Student(id=1, studentName=张三, card=Card(id=2, idNumber=222222))Student(id=3, studentName=王大锤, card=Card(id=3, idNumber=333333)) &emsp; &emsp; 一对多(&lt;collection&gt;)以班级（grade）和老师（Teacher）为例，一个班级对应多个老师 grade表： teacher表：（grade_id为指向grade的外键） 对应的JavaBean： 123456789101112public class Grade &#123; private Integer id; private String gradeName; private List&lt;Teacher&gt; teachers;&#125;public class Teacher &#123; private Integer id; private String teacherName;&#125;//省略了setter、getter、toString 定义Mapper方法： 1List&lt;Grade&gt; selectAll(); 映射文件： 先使用&lt;resultMap&gt;分别对两个表跟JavaBean进行映射。 gradeMap中使用了&lt;collection&gt;封装Grade中的Teacher，通过resultMap属性指定集合类型。property属性指定集合对应的JavaBean属性。 与一对一中一样，注意别名问题。 1234567891011121314151617&lt;resultMap id=&quot;teacherMap&quot; type=&quot;teacher&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;tid&quot; /&gt; &lt;result property=&quot;teacherName&quot; column=&quot;teacher_name&quot; /&gt;&lt;/resultMap&gt;&lt;resultMap id=&quot;gradeMap&quot; type=&quot;grade&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;gid&quot; /&gt; &lt;result property=&quot;gradeName&quot; column=&quot;grade_name&quot; /&gt; &lt;collection property=&quot;teachers&quot; resultMap=&quot;teacherMap&quot; /&gt;&lt;/resultMap&gt;&lt;select id=&quot;selectAll&quot; resultMap=&quot;gradeMap&quot;&gt; select g.id gid, g.grade_name, t.id tid,t.teacher_name from grade g inner join teacher t on t.grade_id=g.id;&lt;/select&gt; 测试方法: 12345678910@Testpublic void testSelectAll()&#123; try(SqlSession session = factory.openSession())&#123; GradeMapper mapper = session.getMapper(GradeMapper.class); List&lt;Grade&gt; grades = mapper.selectAll(); for(Grade grade : grades)&#123; System.out.println(grade); &#125; &#125;&#125; 输出：可看到与实际表数据对应。 123Grade(id=2, gradeName=软件工程, teachers=[Teacher(id=1, teacherName=黄老师), Teacher(id=2, teacherName=徐老师), Teacher(id=3, teacherName=张老师)])Grade(id=1, gradeName=计算机科学与技术, teachers=[Teacher(id=4, teacherName=李老师)])Grade(id=3, gradeName=信息安全, teachers=[Teacher(id=5, teacherName=王老师), Teacher(id=6, teacherName=马老师)]) &emsp; &emsp; 多对多多对多其实本质就是一对多，相关的配置与一对多一样。 &emsp; &emsp; 小结在上述示例的映射文件中，都是先使用&lt;/resultMap&gt;封装好表与JavaBean之间的映射，再在&lt;association&gt;和&lt;collection&gt;中使用resultMap属性指定即可。这样配置代码更加整洁。 也可以在&lt;association&gt;和&lt;collection&gt;中配置映射关系，如一对一中的studentMap可改为： 123456789&lt;resultMap id=&quot;studentMap&quot; type=&quot;student&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;sid&quot; /&gt; &lt;result property=&quot;studentName&quot; column=&quot;student_name&quot; /&gt; &lt;!--&lt;association property=&quot;card&quot; resultMap=&quot;cardMap&quot; /&gt;--&gt; &lt;association property=&quot;card&quot; javaType=&quot;card&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;cid&quot; /&gt; &lt;result property=&quot;idNumber&quot; column=&quot;id_number&quot; /&gt; &lt;/association&gt;&lt;/resultMap&gt; 其中，替代resultMap属性，通过javaType指定封装的类型，对于&lt;collection&gt;，则是使用ofType属性。 Mybatis延迟加载概述在多表查询的一对多中，在查询“一”时，有时并不需要将“多”也全部查询出来，什么时候需要用到，什么时候再查询才更符合实际要求，不用造成不必要的系统开销。 在四种表关系中：一对多、多对多，通常情况下都是采用延迟加载；而一对一（跟多对一），通常情况下“一”都不可省略，所以一般都是采用立即加载（也有使用延迟加载的情况）。 Mybatis中可通过修改配置信息实现延迟加载。 &emsp; &emsp; 实现延迟加载实现延迟加载需要先设置mybatis的全局变量lazyLoadingEnabled为true（该值默认为false） ，表示开启延迟加载。 若是3.4.1 及之前的版本，还需设置aggressiveLazyLoading 变量为false，其默认值是true。 该变量的官方解释： 开启时，任一方法的调用都会加载该对象的所有延迟加载属性。 否则，每个延迟加载属性会按需加载 以上配置在主配置文件的settings标签中进行： 1234&lt;settings&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;!--&lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt;--&gt;&lt;/settings&gt; 通过示例验证： 以学生（Student）和身份证（Card）为例，即一个学生对应一个身份证。 数据表如下： card： student： Card类： 123456789public class Card &#123; private Integer id; private String idNumber; public Card() &#123; //被创建时输出内容。用于验证延迟加载 System.out.println(&quot;创建了一个Card对象...&quot;); &#125;&#125; Student类： 12345public class Student &#123; private Integer id; private String studentName; private Card card;&#125; 两个JavaBean对应的Mapper： 123public interface CardMapper &#123; Card selectById(Integer id); &#125;public interface StudentMapper &#123; List&lt;Student&gt; selectAll(); &#125; 映射文件： CardMapper.xml 12345678910&lt;mapper namespace=&quot;com.mapper.CardMapper&quot;&gt; &lt;resultMap id=&quot;cardMap&quot; type=&quot;card&quot;&gt; &lt;result property=&quot;idNumber&quot; column=&quot;id_number&quot; /&gt; &lt;/resultMap&gt; &lt;select id=&quot;selectById&quot; resultMap=&quot;cardMap&quot;&gt; select * from card where id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; StudentMapper.xml： selectAll中的sql语句不用使用连接查询语句。 在association标签中，select指定了查询Student中的Card时使用的查询方法，属性值是Mapper方法的全限定名。column属性指定了用于查询card所需的id，即select * from student的查询结果集中的card_id字段。 12345678910111213&lt;mapper namespace=&quot;com.mapper.StudentMapper&quot;&gt; &lt;resultMap id=&quot;studentMap&quot; type=&quot;student&quot;&gt; &lt;id property=&quot;id&quot; column=&quot;id&quot; /&gt; &lt;result property=&quot;studentName&quot; column=&quot;student_name&quot; /&gt; &lt;association property=&quot;card&quot; column=&quot;card_id&quot; select=&quot;com.mapper.CardMapper.selectById&quot; /&gt; &lt;/resultMap&gt; &lt;select id=&quot;selectAll&quot; resultMap=&quot;studentMap&quot;&gt; select * from student &lt;/select&gt;&lt;/mapper&gt; 测试方法： 123456789101112@Testpublic void testLazyLoad()&#123; try(SqlSession session = factory.openSession())&#123; StudentMapper mapper = session.getMapper(StudentMapper.class); List&lt;Student&gt; students = mapper.selectAll(); Student student = students.get(0); System.out.println(&quot;输出student的name：&quot; + student.getStudentName()); System.out.println(&quot;---------------------&quot;); System.out.println(&quot;输出student的card：&quot; + student.getCard()); &#125;&#125; 输出是： 1234输出student的name：张三---------------------创建了一个Card对象...输出student的card：Card(id=2, idNumber=222222) Card对象被创建时，会输出创建了一个Card对象...（见其类定义的构造器），通过输出可看出mapper.selectAll()执行时并没有创建Card对象。当调用了student的getCard()方法时才查询所需的Card对象。 通过idea的debug不能看出延迟加载的效果。debug过程中查看students变量可发现所有的card都被创建完成。。。 Mybatis 的缓存机制Mybatis 使用到了两种缓存：本地缓存（一级缓存）和二级缓存。 本地（一级）缓存每当一个新 session 被创建，MyBatis 就会创建一个与之相关联的本地缓存。任何在 session 执行过的查询结果都会被保存在本地缓存中，当再次执行参数相同的相同查询时，会返回缓存中的内容，而不用访问数据库。本地缓存将会在做出修改、事务提交或回滚，以及关闭 session 时清空，调用SqlSession的void clearCache()方法也可以情空缓存。 默认情况下，本地缓存数据的生命周期等同于整个 session 的周期。 简单示例： 12345678910@Testpublic void testCache()&#123; try(SqlSession session = factory.openSession())&#123; CardMapper mapper = session.getMapper(CardMapper.class); Card card1 = mapper.selectById(1); Card card2 = mapper.selectById(1); System.out.println(card1==card2); &#125;&#125; 输出true，第二次查询获取的是缓存在SqlSession中的card对象。 二级缓存 参考： https://blog.csdn.net/weixin_36380516/article/details/73194758 https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247483937&amp;idx=5&amp;sn=4a049d7461b67c4135183db09ec97bcb&amp;chksm=ebd74320dca0ca3691081597ac9db2447d51250d7aa819009231760977dd932b43a116fe44ba&amp;scene=21#wechat_redirect 二级缓存是mapper级别的缓存，二级缓存是跨SqlSession的，对于mapper级别的缓存不同的sqlsession是可以共享的。 每个Mapper有一个二级缓存区域（按namespace分），两个mapper的namespace如果相同，这两个mapper执行sql查询到数据将存在相同的二级缓存区域中。 如图：（图片来自第二个参考链接）","categories":[{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://example.com/Tag/Mybatis/"}]},{"title":"Java-序列化","slug":"Java/基础/序列化","date":"2020-11-04T09:43:46.050Z","updated":"2021-03-29T03:00:29.346Z","comments":true,"path":"2020/11/04/Java/基础/序列化/","link":"","permalink":"http://example.com/2020/11/04/Java/%E5%9F%BA%E7%A1%80/%E5%BA%8F%E5%88%97%E5%8C%96/","excerpt":"","text":"序列化的含义和意义序列化指将Java对象转换成字节序列， 这些字节序列可以保存在磁盘上， 或者进行网络传输。反序列化即指将序列化后的字节序列重新恢复成对象。序列化机制使得对象可以脱离程序的运行而独立存在。 一个Java对象要能序列化，必须实现一个特殊的java.io.Serializable接口，这个接口不包含任何方法或成员变量，只是一个标记。 &emsp; 序列化/反序列化序列化通过ObjectOutputStream来实现，它可以把一个Java对象写入字节流。 当序列化一个对象到文件时， 按照 Java 的标准约定是给文件一个 .ser 扩展名. 反序列化使用ObjectInputStream对象，它可以从字节流中读取一个Java对象。若反序列化时要使用readObject()读出多个对象，注意要与写入的顺序一致。 &emsp; 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041public class SerializableDemo &#123; public static void main(String[] args) throws Exception &#123; writeObj(); readObj(); &#125; private static void writeObj() throws Exception &#123; File file = new File(&quot;E:\\\\person.ser&quot;); FileOutputStream out = new FileOutputStream(file); ObjectOutputStream objectOutputStream = new ObjectOutputStream(out); Person person = new Person(&quot;王大锤&quot;, 25); objectOutputStream.writeObject(person); System.out.println(&quot;写入的对象：&quot; + person); objectOutputStream.close(); &#125; private static void readObj() throws Exception&#123; File file = new File(&quot;E:\\\\person.ser&quot;); FileInputStream in = new FileInputStream(file); ObjectInputStream objectInputStream = new ObjectInputStream(in); Person person = (Person)objectInputStream.readObject(); System.out.println(&quot;读取的对象：&quot; + person); objectInputStream.close(); &#125;&#125;class Person implements Serializable&#123; private String name; private int age; public Person(String name, int age) &#123; System.out.println(&quot;Person&#x27;s constructor&quot;); this.name = name; this.age = age; &#125; //...省略getter、setter、toString&#125; 程序输出： 123Person&#x27;s constructor写入的对象：Person&#123;name=&#x27;王大锤&#x27;, age=25&#125;读取的对象：Person&#123;name=&#x27;王大锤&#x27;, age=25&#125; 可以看到反序列化时，Person的构造器并没有执行。反序列化时，是由JVM直接构造出Java对象，不调用构造方法，构造方法内部的代码，在反序列化时将不被执行。 &emsp; 看另一个示例： 1234567891011121314public static void main(String[] args) throws Exception &#123; ByteArrayOutputStream byteOut = new ByteArrayOutputStream(); ObjectOutputStream objectOutputStream = new ObjectOutputStream(byteOut); Person person = new Person(&quot;张三&quot;, 20); objectOutputStream.writeObject(person); ObjectInputStream objectInputStream = new ObjectInputStream(new ByteArrayInputStream(byteOut.toByteArray())); Person readPerson = (Person)objectInputStream.readObject(); System.out.println(&quot;反序列化得到的Person对象：&quot; + readPerson); System.out.println(&quot;反序列化得到的对象与原对象是否是同一对象：&quot; + (person==readPerson));&#125; 输出： 12反序列化得到的Person对象：Person&#123;name=&#x27;张三&#x27;, age=20&#125;反序列化得到的对象与原对象是否是同一对象：false 可见反序列化得到的对象与原来的person不是同一个对象，即反序列化得到的是一个新的对象。 &emsp; serialVersionUID每一个可序列化类都会带有一个long类型的serialVersionUID静态常量值，如果没有人为显式定义过serialVersionUID，那编译器会根据类的各种信息为它自动声明一个。 serialVersionUID是序列化前后类的唯一标识符，在反序列化时，jvm会把字节流中的序列号id和被序列化类的序列号id进行比较，只有两个id相同才能成功反序列化，否则抛出InvalidClassException异常。 若是没有人为指定序列号id，则若是改变类时（如添加新的成员变量），默认的serialVersionUID值将会改变。 示例： 执行上述例子的writeObj()方法后，在Person类定义中添加一个birth成员变量：private Date birth; 再执行readObj()进行反序列化，此时抛出异常：即字节流中的serialVersionUID与Person类的不同。 1Exception in thread &quot;main&quot; java.io.InvalidClassException: io.stream.serializable.Person; local class incompatible: stream classdesc serialVersionUID = 5578959987866231607, local class serialVersionUID = -8466270221378179612 一般对于可序列化类，为了serialVersionUID的确定性，都要人为指定一个serialVersionUID值，可以使用idea的自动生成功能：IDEA自动生成serialVersionUID 。 &emsp; 反序列化时的异常在反序列化时readObject()可能抛出的异常有： ClassNotFoundException：没有找到对应的Class； InvalidClassException：Class不匹配。 抛出ClassNotFoundException的情况：一台电脑上的Java程序把一个Java对象序列化以后，通过网络传给另一台电脑上的另一个Java程序，但是这台电脑的Java程序并没有定义该类，所以无法反序列化，抛出该异常。 抛出InvalidClassException的情况：如serialVersionUID中的示例情况。 &emsp; 序列化的特殊情况 当要序列化的对象中包含其他引用类型变量的引用时，该变量对应的类也要实现Serializable接口。 对同一个对象多次序列化，只有第一次序列化时JVM才会将对象转换为字节序列，之后的序列化只是直接输出一个序列化编号。且反序列化时多次使用readObject()读出的是同一个对象。 &emsp; 示例： 示例中的Person类同上。新增了一个ID类： 1234567891011package stream.serializable;import java.io.Serializable;public class ID implements Serializable &#123; private static final long serialVersionUID = -5829455553074732547L; private int number; private Person person; //...省略getter、setter、toString&#125; &emsp; 创建一个Person对象person和一个ID对象id，id中的Person指向person。将person和id序列化。再反序列，可看到readId.getPerson()==readPerson返回true。 12345678910111213141516171819202122public static void main(String[] args) throws Exception &#123; File file = new File(&quot;E:\\\\id.ser&quot;); FileOutputStream out = new FileOutputStream(file); ObjectOutputStream objectOutputStream = new ObjectOutputStream(out); ID id = new ID(); Person person = new Person(&quot;王大锤&quot;, 30); id.setNumber(1); id.setPerson(person); objectOutputStream.writeObject(id); objectOutputStream.writeObject(person); FileInputStream in = new FileInputStream(file); ObjectInputStream objectInputStream = new ObjectInputStream(in); ID readId = (ID) objectInputStream.readObject(); Person readPerson = (Person) objectInputStream.readObject(); System.out.println(readId); System.out.println(readPerson); System.out.print(&quot;readId.getPerson()==readPerson:&quot;); System.out.print(readId.getPerson()==readPerson);&#125; 凡是被static修饰的字段是不会被序列化的。 因为序列化保存的是对象的状态而非类的状态，所以会忽略static静态域。 凡是被transient修饰符修饰的字段也是不会被序列化的。 transient修饰符的作用就是修饰不想被序列号的成员变量，一般是对于一些要保密的字段，如密码。对于被transient修饰的字段，在序列号时以null值填充（对于值类型，则使用0、false等默认值）。 &emsp; 还有一个点是序列化的受控和加强，具体见第3个参考链接中最后一个小节。 参考 廖雪峰Java教程-序列化 菜鸟教程 序列化/反序列化，我忍你很久了，淦！ （程序羊） 《疯狂Java讲义 第4版》 &emsp;","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"http://example.com/categories/Java/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"Java-关于byte类型","slug":"Java/基础/byte类型数据","date":"2020-11-04T09:38:36.487Z","updated":"2021-03-20T12:06:10.555Z","comments":true,"path":"2020/11/04/Java/基础/byte类型数据/","link":"","permalink":"http://example.com/2020/11/04/Java/%E5%9F%BA%E7%A1%80/byte%E7%B1%BB%E5%9E%8B%E6%95%B0%E6%8D%AE/","excerpt":"","text":"byte类型数据的范围Java中一个byte类型数据的大小是一个字节，即8位，其范围是-128（1000_0000) ~ 127（0111_1111），二进制的最高位是符号位。 &emsp; 使用二进制形式赋值报错问题为byte类型变量赋值只能是-128~127范围内的数。 可以使用二进制形式赋值，如：byte b = 0b10011; （b=19）。且使用二进制赋值时，系统是以补码形式解析赋值的二进制数（如对于0b10011是19；对于0b1111_1101则是-3）。 若想使用二进制形式赋值一个负数，如：byte b = 0b1001_0101;，编译器会报类型不兼容的错误（int不能赋值给byte）。需要添加类型强制转换：byte b = (byte) 0b1001_0101; 原因：（参考：关于JAVA中Byte数据类型二进制赋值运算报错问题） byte共有8个比特位，其中最高位是符号位，给它赋值0b1001_0101时，最高位的1系统无法判断是实际数值还是符号位数值。添加强制类型转换(byte)，则系统可以知道1是符号位，此时可以被赋值；如果没有加强制类型转换，则系统认为0b1001_0101是一个int类型数据。int类型值无法赋值给byte变量，所以会报错。 &emsp; 以二进制形式输出byte以二进制形式输出byte可以通过包装类Integer的静态方法toBinaryString(int i)。 示例： 123456789byte a = 2;byte b = 12;System.out.println(Integer.toBinaryString(a));System.out.println(Integer.toBinaryString(b));/**输出：101100*/ &emsp; 但若是通过该方法输出一个负数的byte变量，会看到结果是输出了一个32位的二进制数，如： 123456byte a = -2;System.out.println(Integer.toBinaryString(a));/**输出：11111111111111111111111111111110*/ 这是因为byte值被赋值给toBinaryString()方法时被转换为int类型，即变成32位。对于上个例子的正数也一样被转换为int，只不过因为是正数，所以高位的0可以被省略，因而看起来是正常显示；但对于负数，高位的1不可以省略，所以以32位形式显示。 &emsp; 针对负数的byte，可以截取结果的后8位，如下： 123456789101112public static void main(String[] args) throws IOException &#123; byte a = -2; String aBinary = Integer.toBinaryString(a); aBinary = aBinary.substring(aBinary.length()-8); System.out.println(&quot;原二进制数：&quot; + Integer.toBinaryString(a)); System.out.println(&quot;截取后的二进制数：&quot; + aBinary);&#125;/**输出：原二进制数：11111111111111111111111111111110截取后的二进制数：11111110*/ &emsp; 一个Integer.toBinaryString()处理byte值（对于正数，进行左补0；对于负数，截取后8位）的示例： 123456789101112131415161718192021222324252627282930313233public class Test &#123; public static void main(String[] args) throws IOException &#123; byte a = 2; byte b = -2; String aBinary = getBinaryByteStr(Integer.toBinaryString(a)); String bBinary = getBinaryByteStr(Integer.toBinaryString(b)); System.out.println(aBinary); System.out.println(bBinary); &#125; private static String getBinaryIntWithZero(String binary)&#123; int zeroCount = 8 - binary.length(); String zeros = &quot;&quot;; if(zeroCount &gt; 0)&#123; for (int i = 0; i &lt; zeroCount; i++) &#123; zeros += 0; &#125; &#125; return zeros + binary; &#125; /** * 获取8位二进制形式 */ public static String getBinaryByteStr(String b)&#123; if(b.length()&gt;8)&#123; return b.substring(b.length()-8); &#125; else &#123; return getBinaryIntWithZero(b); &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"http://example.com/categories/Java/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"Java IO总结","slug":"Java/基础/Java IO总结","date":"2020-11-01T12:05:41.630Z","updated":"2021-03-20T12:49:59.793Z","comments":true,"path":"2020/11/01/Java/基础/Java IO总结/","link":"","permalink":"http://example.com/2020/11/01/Java/%E5%9F%BA%E7%A1%80/Java%20IO%E6%80%BB%E7%BB%93/","excerpt":"","text":"File类概述使用Java io流经常会用到File类，这里先对File类做个总结。 File类是Java.io包下代表与平台无关的文件和目录。可通过File对象新建、重命名、文件和目录，但不能通过File类访问文件内容本身，此操作需通过Java输入/输出流。 File 类是对文件系统的映射，并不是硬盘上真实的文件， new File(“filePath”) 只是创建一个与硬盘中filePath指定的文件或目录（不管存不存在）对应的File对象，并不会在硬盘中创建文件，即一个File对象只是和硬盘里面的一个文件/目录相关联。如果所指向的文件不存在，调用exist()将返回false，可以通过createNewFile()方法在硬盘中创建对应文件或目录。 创建File对象创建File对象最常用的方法是使用构造器new File(String pathName)。pathName可以是绝对路径和相对路径。可以通过传入空字符串来创建一个当前路径对应的File对象：File file = new File(&quot;&quot;);，可以通过该方法来获取当前路径。 File类还包含其他构造器，具体查看官方文档或者File类源码。 常用API File类的一些静态变量： separator（String）：代表当前系统对应的文件路径分隔符 separatorChar（char）：与系统有关的默认名称分隔符，为了方便，它被表示为一个字符串。此字符串只包含一个字符 pathSeparatorChar（char）：与系统有关的路径分隔符，为了方便，它被表示为一个字符串 pathSeparator（String）：此字符用于分隔以路径列表形式给定的文件序列中的文件名。在UNIX 系统上此字段为:；在 Windows系统上，它为 ; 获取文件名 String getName()：返回文件名（最后一级子路径名） String getPath()：返回文件（若是目录则返回空字符串）对应的路径名 String getAbsolutePath()：返回绝对路径名 String getParent()：返回父目录名 boolean renameTo(File newName)：修改文件名，成功返回true，否则false（文件不存在时返回false） 检测文件 **boolean exist()**：是否存在 boolean canWrite()：是否可写 boolean canRead()：是否可读 **boolean isFile()**：是否是文件而不是目录 **boolean isDirectory()**：是否是目录而不是文件 获取文件信息 long lastModified()：返回最后修改的时间 long length()：返回文件长度 文件操作： boolean createNewFile()：若对应文件不存在，创建对应的新文件。创建成功返回true，否则false boolean delete()：删除对应文件 static File createTempFile(String prefix, String suffix)：静态方法。根据前缀，后缀以及系统生成的随机数在默认的临时文件目录中创建一个空文件。prefix至少3字节，suffix可为null static File createTempFile(String prefix, String suffix, File directory)：在指定目录创建对应文件 void deleteOnExit()：注册删除钩子。当虚拟机退出时，删除该文件 目录操作： boolean mkdir()：创建File对象对应的目录 String[] list()：返回File的所有子文件名和路径名的String数组 File[] listFiles()：返回File的所有子文件名和路径名的File数组 static File[] listRoots()：返回系统所有的根路径的File数组 文件过滤器在使用list()方法所有子文件名和路径名时，可以传入一个FilenameFilter（接口）参数，代表文件过滤器。该接口包含一个boolean accept(File dir, String name)方法，该方法将依次对指定File对象的子文件名和路径名进行迭代筛选，返回true表示符合要求。 示例： 1234567891011121314151617181920212223242526272829303132public static void main(String[] args) throws IOException &#123; File f1 = new File(&quot;E:\\\\temp&quot;); String[] list1 = f1.list(); System.out.println(&quot;该目录下的所有文件：&quot;); for (String s : list1) &#123; System.out.println(s); &#125; System.out.println(&quot;过滤掉不以.txt结尾的子文件：&quot;); String[] list2 = f1.list(((dir, name) -&gt; name.endsWith(&quot;.txt&quot;))); for (String s : list2) &#123; System.out.println(s); &#125;&#125;输出：该目录下的所有文件：a.txta.txt.bakanswers.txtb.txtb.txt.bakc.txtc.txt.bakexpFile.txt过滤掉不以.txt结尾的子文件：a.txtanswers.txtb.txtc.txtexpFile.txt Java IO概述Java的IO流是实现输入/输出的基础， 它可以方便地实现数据的输入/输出操作， 在Java中把不同的输入/输出源(键盘、文件、网络连接等) 抽象表述为“流”(stram) ， 通过流的方式允许Java程序使用相同的方式来访问不同的输入/输出源。流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。 Java io流的类层次图，其中的类皆来自java.io包（图片来自菜鸟教程）： 流的分类输入流与输出流根据数据流向不同可分为输入流和输出流。 输入流：只能从中读取数据。输入流主要以InputStream、Reader抽象类作为基类。 输出流：只能向其中输入数据。输出流主要以OutputStream、Writer抽象类作为基类。 这里的输入输出是从程序运行所在角度来划分的。 字节流和字符流根据处理数据类型的不同可分为字节流和字符流。 两者的区别： 传输数据的单位不同，字节流为8位的字节，字符流为16位的字符。 处理对象不同，字节流能处理所有类型的数据，而字符流只能处理字符类型的数据。 字节流在操作的时候本身是不会用到缓冲区的，是在文件本身直接操作；而字符流是通过缓冲区来操作文件的。 结论：优先选用字节流。首先因为硬盘上的所有文件都是以字节的形式进行传输或者保存的，包括图片等内容。但是字符只是在内存中才会形成的，所以在开发中，字节流使用广泛。 字节流以InputStream、OutputStream为基类。字符流以Reader、Writer为基类。 节点流和处理流 节点流：可以从/向一个特定的IO设备（磁盘，网络等）读/写数据的流。即程序直接连接到数据源。 处理流：对一个已存在的节点流进行连接和封装，封装后的流提供了更简便强大的数据读写功能。关闭流时，只关闭处理流即可，外层的流将会关闭内层的节点流。 以下分为字节流和字符流对一些较常用的流进行总结。 字节流字节流基类是InputStream和OutputStream。InputStream类是所有字节输入流类的抽象父类。OutputStream类是所有字节输出流的抽象父类。InputStream和OutputStream基类提供了read()和write()系列方法进行读写，可以一次读/写一个字节，也可多个字节。在处理图片、音乐等非文本文件时，使用的是字节流。 InputStream的常见子类有： FileInputStream：从文件中读取信息。 ByteArrayInputStream： 字节数组输入流, ObjectInputStream：序列化时使用。一般和ObjectOutputStream一起使用 FilterInputStream：过滤输入流，为基础的输入流提供一些额外的操作。 OutputStream的常见子类有： FileOutPutStream: 文件输出流对文件进行操作 ByteArrayOutputStream: 字节数组输出流 ObjectOutputStream: 序列化时使用。一般和OjbectInputStream一起使用 FilterOutputStream:过滤输出流,为基础的输出流提供一些额外的操作。 其中，创建OutputStream的子类时，若指定的文件在磁盘中不存在，则会创建对应的文件；对于InputStream，若文件不存在则抛出异常。 FileInputStreamFileInputStream、FileOutPutStream是针对文件的字节输入、输出流，可以通过指定文件的路径（String）或指定一个File对象来创建。 一个复制文件的简单示例： 1234567891011121314151617181920212223public class CopyDemo &#123; public static void main(String[] args) throws IOException &#123; //创建输入流，输出流，实现文件的复制 FileInputStream input = new FileInputStream(&quot;E:\\\\source.java&quot;); FileOutputStream output = new FileOutputStream(&quot;E:\\\\copy.txt&quot;); byte[] buf = new byte[32]; int hasRead = 0; //将读取的输入流数据写入输出流 while((hasRead = input.read(buf)) &gt; 0) &#123; output.write(buf); &#125; //输出复制后的文件 FileInputStream file = new FileInputStream(&quot;E:\\\\copy.txt&quot;); while((hasRead = file.read(buf)) &gt; 0) &#123; System.out.print(new String(buf, 0 ,hasRead)); &#125; //关闭资源 input.close(); output.close(); file.close(); &#125;&#125; ByteArrayInputStream流的来源或目的地并不一定是文件，也可以是内存中的一块空间，例如一个字节数组。ByteArrayInputStream、ByteArrayOutputStream就是将字节数组当作流的输入来源、输出目的地的类。 创建ByteArrayInputStream需要传入一个byte[]；创建ByteArrayOutputStream不是传入一个byte数组（ByteArrayOutputStream中封装了一个byte数组作为输出目的地，通过toByteArray()方法可以获取到该数组），而是指定ByteArrayOutputStream中byte数组的长度，也可以不指定，默认为32。 关于这两个流的应用场景（来自参考链接）： 这两个类对于要创建临时性文件的程序以及网络数据的传输、数据压缩后的传输等可以提高运行的的效率，可以不用访问磁盘。同样有StringReader与StringWriter类以字符IO流的方式处理字符串。 两个流的用法比较简单，直接看示例： 12345678910111213141516171819202122232425262728293031323334public class ByteArrayOutputStreamDemo &#123; public static void main(String[] args) throws IOException &#123; demo1(); demo2(); //输出： //hello //hello, world! &#125; private static void demo1() throws IOException &#123; ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); ByteArrayInputStream inputStream; byte[] bytes = new byte[]&#123;&#x27;h&#x27;, &#x27;e&#x27;, &#x27;l&#x27;, &#x27;l&#x27;, &#x27;o&#x27;&#125;; byte[] bytes1 = new byte[bytes.length]; outputStream.write(bytes); inputStream = new ByteArrayInputStream(outputStream.toByteArray()); inputStream.read(bytes1); System.out.println(new String(bytes1)); &#125; private static void demo2()&#123; String str = &quot;hello, world!&quot;; byte[] bytes = str.getBytes(); ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes); int hasRead = 0; while ((hasRead = inputStream.read())&gt;0)&#123; System.out.print((char)hasRead); &#125; &#125;&#125; ObjectInputStreamObjectInputStream和ObjectOutpuStream一般用于反序列化/序列化Java对象。被操作的对象对应的类必须实现Serializable接口。 ObjectInputStream能够从输入流中读取Java对象，而不需要每次读取一个字节（反序列化） ObjectOutputStream能够把对象写入到输出流中，而不需要每次写入一个字节（序列化） 创建ObjectInputStream和ObjectOutpuStream流需要传入一个节点流。 示例： 一个要注意的点是：若是要从流中读取多个对象，则读取顺序要与写入的顺序一致。 123456789101112131415161718192021222324252627public void demo1() throws Exception &#123; Data w=new Data(2); ObjectOutputStream out=new ObjectOutputStream(new FileOutputStream(&quot;E:\\\\worm.out&quot;)); //序列化对象，把对象写到worm.out里面 out.writeObject(&quot;Worm storage\\n&quot;); //序列化对象，把对象写到worm.out里面 out.writeObject(w); //从worm.out里面读取对象 ObjectInputStream in=new ObjectInputStream(new FileInputStream(&quot;E:\\\\worm.out&quot;)); //读取String对象 String s=(String)in.readObject(); //读取Data对象 Data d=(Data)in.readObject(); System.out.println(s+&quot;Data = &quot;+d);&#125;class Data implements Serializable &#123; private int n; public Data(int n)&#123; this.n=n; &#125; @Override public String toString()&#123; return Integer.toString(n); &#125;&#125; ObjectInputStream和ObjectOutpuStream也提供了系列readXxx()和writeXxx()方法，用于写入/读取int、char或者字符串等类型的值。与读写对象一样，使用readXxx()读取数据时，要与写入时的顺序一致。如下示例： 1234567891011121314151617181920212223242526public void demo2() throws Exception &#123; ObjectOutputStream out=new ObjectOutputStream(new FileOutputStream(&quot;E:\\\\test.out&quot;)); ObjectInputStream in; out.writeInt(2); out.writeChar(&#x27;H&#x27;); out.writeDouble(3.14); out.writeUTF(&quot;hello, world!&quot;);//写入字符串 out.writeObject(&quot;I am a String Object&quot;); out.close(); in =new ObjectInputStream(new FileInputStream(&quot;E:\\\\test.out&quot;)); //从输入流中读取数据的顺序要与写入时的顺序一致，否则抛出异常 int val = in.readInt(); char c = in.readChar(); double val1 = in.readDouble(); String str = in.readUTF(); String strObj = (String) in.readObject(); System.out.println(val); System.out.println(c); System.out.println(val1); System.out.println(str); System.out.println(strObj);&#125; 过滤io流这里的过滤输入/输出流是指FilterInputStream和FilteOutputStream，他们的作用是为基础流提供一些额外的功能。 常用子类： FilterInputStream常用子类 DataInputStream BufferedInputStream：可以从缓冲区中读取数据，不用每次和文件的操作都进行实际操作了。 FilterOutputStream常用子类 DataOutputStream PrintStream:用于产生格式化的输出 BufferedOutputStream:通过缓冲区像文件中写入数据。 DataInputStreamDataInputStream是数据字节输入流，用来装饰其他的输入流，允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型；DataOutputStream可以向文件中写入基本类型的数据，与DataInputStream配合使用。 创建DataInputStream和DataOutputStream都要基于一个输入/输出节点流。 示例： 其中的writeUTF()方法，是以UTF-8编码写入指定字符串；相应的，readUTF()是以UTF-8编码读取字符串。 1234567891011121314151617181920212223242526272829303132public class DataInOutStreamDemo &#123; public static void main(String[] args) throws Exception&#123; File file = new File(&quot;E:\\\\data.txt&quot;); FileInputStream in; FileOutputStream out; DataInputStream dataIn; DataOutputStream dataOut; out = new FileOutputStream(file); dataOut = new DataOutputStream(out); //写入数据 dataOut.writeInt(2020); dataOut.writeBoolean(true); dataOut.writeChar(&#x27;H&#x27;); dataOut.writeUTF(&quot;hello,world&quot;); in = new FileInputStream(file); dataIn = new DataInputStream(in); //读出数据（注意顺序） int readInt = dataIn.readInt(); boolean readBoolean = dataIn.readBoolean(); char readChar = dataIn.readChar(); String readStr = dataIn.readUTF(); System.out.println(&quot;readInt = &quot; + readInt); System.out.println(&quot;readBoolean = &quot; + readBoolean); System.out.println(&quot;readChar = &quot; + readChar); System.out.println(&quot;readStr = &quot; + readStr); &#125;&#125; BufferedInputStreamBufferedInputStream和BufferedOutputStream是两个缓冲流。对于没有缓冲的节点流，如FileInputStream，读取一个字节就要与磁盘交互一次，与磁盘的交互过于频繁，读取速度较低。 缓冲流中内置了一个缓冲区， 对于BufferedOutputStream，使用write()方法写入数据时，写入的数据暂时被放在缓冲区，当调用flush()方法或者缓冲区满时才把数据写入输出流，从而减少了与磁盘的交互，提高效率。 对于BufferedInputStream，在新建某输入流对应的BufferedInputStream后，当通过read()读取输入流的数据时，BufferedInputStream会将该输入流的数据分批的填入到缓冲区中。每当缓冲区中的数据被读完之后，输入流会再次填充数据缓冲区；如此反复，直到读完输入流数据位置。从内存中读取数据的速度比从硬盘读取数据的速度快得多，且分批读取数据减少了与磁盘的交互，所以BufferedInputStream的效率比普通的输入节点流要高很多。 一个复制图片的示例： 123456789101112131415161718192021222324public class BufferedInOutStreamDemo &#123; public static void main(String[] args) throws Exception&#123; copyDemo(); &#125; private static void copyDemo() throws Exception&#123; File srcImg = new File(&quot;E:\\\\xiaogailun.jpg&quot;); File copyImg = new File(&quot;E:\\\\copy.jpg&quot;); FileInputStream in = new FileInputStream(srcImg); FileOutputStream out = new FileOutputStream(copyImg); BufferedInputStream bufIn = new BufferedInputStream(in); BufferedOutputStream bufOut = new BufferedOutputStream(out); byte[] buf = new byte[64]; int hasRead = 0; while ((hasRead = bufIn.read(buf)) &gt; 0)&#123; bufOut.write(buf, 0, hasRead); &#125; bufOut.flush(); bufIn.close(); bufOut.close(); &#125;&#125; 最后关闭流时，只需关闭外层流（处理流）即可，在外层流中会把包装的内层流（节点流）关闭。 PrintStreamPrintStream 是用来装饰其它输出流，其中提供了系列print()方法，让其他输出流能够方便地输出各种形式的数据。另外，PrintStream提供了自动flush（写入数据时自动调用flush()）和字符集设置功能。 PrintStream的构造器：（其中的boolean值是指定是否自动flush；String是指定文件名或字符集名） 简单示例： 12345678910111213public class PrintStreamDemo &#123; public static void main(String[] args) throws Exception&#123; File file = new File(&quot;E:\\\\print.txt&quot;); PrintStream printStream = new PrintStream(new FileOutputStream(file)); printStream.println(&quot;hello,world!啊哈哈哈&quot;);//结尾加回车符 printStream.print(12138);//结尾无回车符 printStream.println(); printStream.print(&#x27;H&#x27;); printStream.close(); &#125;&#125; 执行后的print.txt文件内容： 123hello,world!啊哈哈哈12138H 更多关于PrintStream的内容推荐看（贼详细）：java io系列16之 PrintStream(打印输出流)详解 2.4 字符流字符流操作的数据单位是字符，在处理文本文件的时候更多使用的是字符流。 字符流的两个抽象基类是Reader和 Writer。其常见子类如下： Reader类常见子类有： InputStreamReader：字节流到字符流的桥接器。 FileReader：文件字符输入流 BufferedReader： 带缓冲区的字符输入流 StringReader：以字符串为源的字符输入流。（StringReader和StringWriter的使用较简单，不作总结） Writer类常见子类有： OutputStreamWriter：字节流到字符流的桥接器。 FileWriter:文件字符输出流 BufferedWriter:带缓冲区的字符输出流 StringWriter：内部封装了一个StringBuffer，作为该输出流的源。提供了一个getBuffer()方法获取其中的StringBuffer。 要注意的点： Writer抽象类中定义了一个char[]缓冲区（即Writer的系列子类都有一个缓冲区），该缓冲区的默认大小是1024，且不可自行指定大小。在执行写操作时，只有缓冲区满或调用flush()或调用close()方法时才会将内容写入磁盘中的文件。 创建Writer子类时，与OutputStream一样，若指定的文件在磁盘中不存在，则会创建对应的文件；对于Reader，若文件不存在则同样抛出异常。 InputStreamReaderInputStreamReader和OutputStreamWriter是字节流到字符流的桥接器，它们可以根据指定的字符集来进行读写内容，没有指定字符集时使用的是java虚拟机的字符集。 每次调用InputStreamReader的read()都将从底层读取一个或多个字节；每次调用OutputStreamWriter的write()方法都会将指定内容写入底层文件。为了提高效率，一般用BufferedReader和BufferedWriter来包装它们。 创建InputStreamReader和OutputStreamWriter时传入的是字节流，它们会根据指定的字符集进行字节和字符间的转换。 InputStreamReader的构造器： OutputStreamWriter的构造器： FileReaderFileWriter和FileReader是InputStreamWriter和OutputStreamReader的子类，在FileWriter和FileReader中，字符集使用的是Java虚拟机的字符集。 FileWriter和FileReader的使用比较简单。它们都是节点流，可以直接传入一个FIle或文件路径来创建流。 其中，创建FileWriter时可以传入一个boolean值，若为true，表示写入的内容是追加在原文件结尾之后，该值默认为false。对应的两个构造器： 12FileWriter(File file, boolean append)FileWriter(String fileName, boolean append) 源码中关于append参数的解释： 1boolean if true, then data will be written to the end of the file rather than the beginning. 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class FileReaderAndWriterDemo &#123; public static void main(String[] args) throws Exception&#123; write(); read(); System.out.println(&quot;\\n\\n---------------------------------------------------------------------\\n&quot;); appendWrite(); read(); &#125; private static void write() throws Exception&#123; File file = new File(&quot;E:\\\\file.txt&quot;); FileWriter writer = new FileWriter(file); writer.write(&quot;hello,world!你好，世界！\\n&quot;); writer.write(&quot;12345678999+*-\\n&quot;); //写入时会把int数值转换为对应的char writer.write(67); writer.flush();//可以省略，因为调用close时会调用flush writer.close(); &#125; private static void read()throws Exception&#123; File file = new File(&quot;E:\\\\file.txt&quot;); FileReader reader = new FileReader(file); char[] cbuf = new char[16]; int hasRead = 0; while ((hasRead=reader.read(cbuf)) &gt; 0)&#123; System.out.print(new String(cbuf, 0, hasRead)); &#125; reader.close(); &#125; /** * 在文件结尾写入内容 */ private static void appendWrite() throws Exception&#123; File file = new File(&quot;E:\\\\file.txt&quot;); FileWriter writer = new FileWriter(file, true); writer.write(&quot;\\n------以下内容并没有覆盖原文件内容------\\n&quot;); writer.write(&quot;啊哈哈哈哈哈哈哈\\n&quot;); writer.write(&quot;弹指间、数据库灰飞烟灭&quot;); writer.flush(); writer.close(); &#125;&#125;/**输出：hello,world!你好，世界！12345678999+*-C---------------------------------------------------------------------hello,world!你好，世界！12345678999+*-C------以下内容并没有覆盖原文件内容------啊哈哈哈哈哈哈哈弹指间、数据库灰飞烟灭*/ BufferedReaderBufferedReader和BufferedWriter的功能是为其他字符输入/输出流提供缓存的功能。关于缓存功能的说明在上文的BufferedInputStream和BufferedOutputStream中已有描述，此处不再赘述。 一个问题是，上文中提到Writer抽象基类中已经有了一个缓冲区，为何还要使用BufferedWriter？ 原因：Writer中定义的缓冲区大小是不能自定义的，且大小只有1024；BufferedWriter中的缓冲区默认大小是8192（1024的8倍），且大小可以自定义，可以指定更大的缓冲区，这个差别使得在操作大量数据时，BufferedWriter的效率将会比普通的字符流，如FileWriter要快得多（BufferedWriter与磁盘的交互次数更少）。 使用BufferedReader和BufferedWriter来处理文本时为了保证字符集的统一，内层流可以使用InputStreamReader和OutputStreamWriter，它们可以指定字符集。 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class BufferedWriterReaderDemo &#123; public static void main(String[] args) throws Exception &#123; File file = new File(&quot;E:\\\\file.txt&quot;); write(file); readLine(file); System.out.println(&quot;\\n---------------------------\\n&quot;); readAll(file); &#125; private static void write(File file)throws Exception&#123; FileOutputStream outStream = new FileOutputStream(file); BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(outStream, StandardCharsets.UTF_8)); writer.write(&quot;hello,world!你好，世界！\\n&quot;); writer.write(&quot;123456789&quot;, 0, 5);//写入前5个字符 writer.flush(); writer.close(); &#125; /** * 使用readLine()按行读取 */ private static void readLine(File file)throws Exception&#123; FileInputStream inStream = new FileInputStream(file); BufferedReader reader = new BufferedReader(new InputStreamReader(inStream, StandardCharsets.UTF_8)); String line1 = reader.readLine(); System.out.println(&quot;读取文件的第一行：&quot; + line1); String line2 = reader.readLine(); System.out.println(&quot;读取文件的第二行：&quot; + line2); reader.close(); &#125; private static void readAll(File file)throws Exception&#123; FileInputStream inStream = new FileInputStream(file); BufferedReader reader = new BufferedReader(new InputStreamReader(inStream, StandardCharsets.UTF_8)); char[] cbuf = new char[(int) file.length()]; reader.read(cbuf); System.out.println(new String(cbuf)); reader.close(); &#125;&#125;/**输出：读取文件的第一行：hello,world!你好，世界！读取文件的第二行：12345---------------------------hello,world!你好，世界！12345 */ 移动输入流中的记录指针在对输入流进行读操作（read()）时，流中的记录指针随之向后移动。InputStream和Reader中提高了下列方法来移动输入流中的记录指针，从而可以重复读取内容： mark(int readlimit)：在此输入流中的当前位置做一个标记。readlimit参数告诉输入流允许在标记位置之后读取多个字节（注意是字节，不管是对于InputStream还是Reader），若是reset()之后读取的字节数超过该参数，则抛出异常：java.io.IOException: Mark invalid。 markSupported()：判断是否支持标记，即是否支持mark方法。 reset()：将此流的记录指针重新定位到上一次在此输入流上调用 mark()方法时的位置。调用reset()之前必须有进行标记，否则抛出异常：java.io.IOException: Stream not marked。 skip(long n)：跳过输入流中的 n个字节或字符。 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class MarkDemo &#123; public static void main(String[] args) throws Exception &#123; File file = new File(&quot;E:\\\\file.txt&quot;); write(file); read(file); &#125; private static void write(File file)throws Exception&#123; FileOutputStream outStream = new FileOutputStream(file); BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(outStream, StandardCharsets.UTF_8)); writer.write(&quot;hello,world!你好，世界！\\n&quot;); writer.write(&quot;123456789&quot;); writer.flush(); writer.close(); &#125; private static void read(File file)throws Exception&#123; FileInputStream inStream = new FileInputStream(file); BufferedReader reader = new BufferedReader(new InputStreamReader(inStream, StandardCharsets.UTF_8)); char[] chars = new char[128]; //在开头进行mark。输出文件全部内容后进行reset reader.mark(1024); reader.read(chars); System.out.println(&quot;文件的全部内容是：&quot;); System.out.println(new String(chars) + &quot;\\n&quot;); reader.reset(); reader.read(chars, 0, 12); System.out.println(&quot;读取前12个字符：&quot; + new String(chars, 0, 12)); System.out.println(&quot;BufferedReader是否支持标记：&quot; + reader.markSupported()); System.out.println(&quot;\\n在当前位置进行mark()&quot;); reader.mark(32); //跳过7个字符，即跳过了 你好，世界！\\n reader.skip(7); System.out.println(&quot;\\n跳过7个字符，并读取整行：&quot;); String line = reader.readLine(); System.out.println(line); //reset，再读取，读取的开始位置是上一次mark时的位置 System.out.println(&quot;\\n--调用了reset()--\\n&quot;); reader.reset(); String line2 = reader.readLine(); System.out.println(&quot;reset之后再读取：&quot;); System.out.println(line2); reader.close(); &#125;&#125; 参考 《疯狂Java讲义 第4版》 关于：File.separator （ 详解 ） 一文带你看懂JAVA IO流 - 知乎 ByteArrayInputStream的作用，和BufferedOutputStream 的区别 Java IO流学习总结三：缓冲流-BufferedInputStream、BufferedOutputStream java io系列16之 PrintStream(打印输出流)详解 OutputStreamWriter InputStreamReader 另外推荐一个博主的Java io系列文章：java io系列01之 “目录” ----------------------------------------------------------------","categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"http://example.com/categories/Java/%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"MySQL基础","slug":"MySQL/MySQL基础","date":"2020-11-01T09:41:43.673Z","updated":"2021-03-20T13:00:53.757Z","comments":true,"path":"2020/11/01/MySQL/MySQL基础/","link":"","permalink":"http://example.com/2020/11/01/MySQL/MySQL%E5%9F%BA%E7%A1%80/","excerpt":"","text":"DQL 该笔记的实例代码中的数据库是myemploees。 SQL语言的分类： DQL（Data Query Language）：数据查询语言。 DML（Data Management Language）：数据操作语言，修改表的语言，如插入、修改、删除语句。 DDL（Data Definition Language）：数据定义语言，如创建表、创建库。 TCL（Translation Control Language）：事物控制语言。 基础查询tips：字符型、日期型的值用单引号括起来。 查询表中字段：select queryList from tableName; 查询所有字段：select * from tableName; 查询常量：select 100;或 select &#39;string&#39;; 查询表达式：select 100*90; 查询函数：select version(); ----------------------------------------------- 起别名（别名可用于字段名重复的情况）： SELECT first_name AS 姓,last_name AS 名 FROM employees 或 SELECT first_name 姓,last_name 名 FROM employees; SELECT salary AS &#39;out put&#39; FROM employees; ----------------------------------------------- 去重：SELECT DISTINCT job_id FROM employees ----------------------------------------------- SQL中的+号： 两个运算数都是数值型，作加法运算：select 100+10; 有一个是字符串，则试图转化字符串为数字，若是转化失败则化为0： select &#39;123&#39;+10; //133 select &#39;string&#39;+10; //0 + 10 = 10 SELECT 10 + &#39;10sdfef3s&#39; + 10;若字符串的前端有数字，会进行转换，此处查询结果为10+10+10=30 若有运算数为null，则结果为null：select null+10; SQL中的+号没有字符串拼接功能，要拼接字符使用concat()函数： SELECT CONCAT(last_name,first_name) AS 姓名 FROM employees ----------------------------------------------- 条件查询条件查询语句：select 查询列表 from tableName where condition; 其中，筛选条件顺序为：tableName -&gt; condition -&gt; 查询列表。 按条件表达式筛选包含这些运算符的表达式：&gt; &lt; = != &lt;&gt;(建议) &gt;= &lt;= eg： SELECT * FROM employees WHERE salary&gt;12000; SELECT last_name, first_name FROM employees WHERE department_id&lt;&gt;20; 按逻辑表达式筛选and or not（建议）或&amp;&amp; || ! （连接条件表达式） SELECT last_name, salary, commission_pct FROM employees WHERE salary&gt;=10000 AND salary&lt;=20000; SELECT * FROM employeesWHERE NOT(department_id&gt;=90 AND department_id&lt;=110) OR salary&gt;15000; 模糊查询like like一般与通配符配合使用，如下： %：表示任意多个字符，包括空字符。 _：表示一个字符。 eg： SELECT * FROM employees WHERE last_name LIKE &#39;%a%&#39;; SELECT last_name,salary FROM employees WHERE last_name LIKE &#39;__t_b%&#39;; 当需要查询包含通配符的字段，需要使用转义字符\\，也可通过escape自定义转移字符。 eg： 查询last_name中第二个字符是_的字段：SELECT last_name FROM employees WHERE last_name LIKE &#39;_\\_%&#39;; 或：SELECT last_name FROM employees WHERE last_name LIKE &#39;_$_%&#39; ESCAPE &#39;#39;; like也可用于筛选int类型值，eg： SELECT * FROM employees WHERE department_id LIKE &#39;1__&#39;; ------------------------------------------------------------------------------------- （not） between and （左右为闭区间） 代替where value1&gt;= 100 and value1&lt;=120;，代码更整洁。 eg： SELECT * FROM employees WHERE employee_id BETWEEN 100 AND 120; ------------------------------------------------------------------------------------- in 若字段的值等于in列表内的任一值即满足条件。其中，in列表中的值必须为同一类型或可兼容（如’123’可等于123），且不支持通配符。 eg： SELECT last_name,job_id FROM employees WHERE job_id IN(&#39;IT_PROG&#39;,&#39;AD_VP&#39;); ------------------------------------------------------------------------------------- is （not） null MySQL中的=，&lt;&gt;不能比较字段值跟null，只能用is null或is not null。eg： SELECT last_name,commission_pct FROM employees WHERE commission_pct IS NOT NULL; MySQL中，有安全等与符号：&lt;=&gt; ，可用于普通值间的比较跟null值的比较。 eg： SELECT last_name,commission_pct FROM employees WHERE commission_pct &lt;=&gt; NULL; ------------------------------------------------------------------------------------- REGEXP 使用正则表达式匹配。操作符见 菜鸟教程 。 eg：SELECT * FROM admin WHERE username REGEXP &#39;^谢&#39;; 排序查询排序查询语法： 1234select queryListfrom tableNamewhere conditionorder by 排序列表名 asc|desc; # asc 升序；desc 降序，默认为asc order by的排序列表可用别名、单个字段、多个字段、函数及表达式。 eg： 工资降序： SELECT * FROM employees ORDER BY salary DESC; 全部信息，年薪降序： SELECT *,salary*12*(1+IFNULL(commission_pct,0)) yearSalary FROM employees ORDER BY yearSalary DESC; 按多个字段排序：其中，先将salary升序排序，再在每个salary相同的区间内，对这些记录的employee_id进行降序排序。 SELECT * FROM employees ORDER BY salary ASC,employee_id DESC; 分组查询分组查询使用group by关键字，配合分组函数，根据条件将记录分为若干组。语法： 12345678# 只有出现在group by后的列才能位于查询列表；下列的数字为语句执行顺序SELECT colum,groupFunction(colum) #5FROM tableName #1（把整个表拿出来）[WHERE condition] #2GROUP BY expr #3[HAVING condition2] #4[ORDER BY colum] #6 ​ 其中，若有where字句，则必须放在from后；且只有出现在group by后的列（字段）才能位于查询列表，其中，数字为底层执行顺序。分组函数将根据GROUP BY的分组情况分别作用于每一组。 ​ 一般不在having子句使用别名，原因是Oracle等数据库不支持，不使用别名从而有更好的通用性。 例子： 1234567891011#每个工种的最高工资SELECT job_id,MAX(salary)FROM employeesGROUP BY job_id;#每个位置上的部门个数SELECT location_id,COUNT(*) FROM departments GROUP BY location_id;#添加分组前的筛选 为分组查询添加筛选条件： 12345#查询邮箱中带有a的，每个部门的平均工资SELECT department_id,AVG(salary) 平均工资 FROM employeesWHERE email LIKE &#x27;%a%&#x27;GROUP BY department_id; 分组后筛选(having子句)​ 上述的有筛选条件的分组查询都是分组前的筛选，即在原始表上进行筛选。 ​ 有时需要对分组的后的结果再添加筛选条件（分组后的筛选），即对分组查询的结果集再添加筛选条件，这时where子句不能满足需求，需使用having子句，放在group by后面。 如下： 例1中，先按部门id分组，查询出部门id和每个部门的员工个数，再在该查询基础上，使用having子句添加员工个数&gt;2的筛选条件。 例2分析见注释。 12345678910111213141516171819202122#添加分组后的筛选#1.查询员工个数大于2的部门SELECT department_id,COUNT(*)FROM employeesGROUP BY department_idHAVING COUNT(*)&gt;2;#2.查询每个工种有奖金的员工的最高工资&gt;12000的 的工种编号和最高工资#对题目解析：#查询每个工种(group by)有奖金(comm.. is not null，分组前，即可在原始表上进行筛选)的员工的#最高工资(max salary)&gt;12000(having,即分组后）的 的工种编号和最高工资SELECT job_id,MAX(salary) FROM employeesWHERE commission_pct IS NOT NULLGROUP BY job_idHAVING MAX(salary)&gt;12000;#3.查询领导编号大于102的领导手下员工的最低工资&gt;5000 的领导编号和最低工资SELECT manager_id,MIN(salary) FROM employeesWHERE manager_id&gt;102GROUP BY manager_idHAVING MIN(salary)&gt;5000; 分组条件也可以是函数或其他表达式： 12345#按表达式或函数分组#1.按员工姓名的长度分组，查询每一组的员工个数，并筛选出员工个数长度大于5的SELECT LENGTH(last_name) name_len,COUNT(*) c FROM employeesGROUP BY name_lenHAVING c&gt;5; 按多个字段分组：按多个字段分组的最终结果其实就是：各分组字段值都一样的若干记录为一组，分组函数再根据分组情况作用于每一组。若把分组的字段顺序改变，其结果将一样。。 eg： 12345678#1.查询每个部门中，每个工种的员工平均工资SELECT department_id,job_id,AVG(salary) FROM employeesGROUP BY department_id,job_id;#2.按平均工资降序排序SELECT job_id,department_id,AVG(salary) FROM employeesGROUP BY job_id,department_idORDER BY AVG(salary) DESC; ​ 综上，分组查询的筛选条件分为分组前筛选跟分组后筛选，如下表 数据源 位置 关键字 分组前筛选 原始表 group by子句前 where 分组后筛选 分组后的结果集 group by子句后 having 其中，对分组函数做条件必须放在having子句中；能用分组前筛选则优先使用分组前筛选。 连接查询（sql99标准） ​ 当查询对象来自多个表时，需要用到连接查询。当连接查询没有添加任何限制时，将会发送笛卡尔积现象，即若表1有12行，表2有4行，查询结果将会有12*4=48行。 ​ 多表查询的结果可按以下思路：先查询出笛卡尔积结果，再根据where子句的条件进行筛选。 ​ 连接查询按功能可分为： 内连接 inner（连接类型关键字可省略） 等值连接 非等值连接 自连接 外连接 左外连接 left [outer] 右外连接 right [outer] 全外连接（MySQL不支持） 交叉连接 cross 连接查询的语法： 其中，连接类型关键字见上面功能分类。连接条件与筛选条件分开，可读性更高。#num表示执行顺序。 12345678910select 查询列表 #6from table1 别名 #1【连接类型关键字】join table2 别名 #2（笛卡尔积）on 连接条件1【join table3 别名 on 连接条件2】【where 筛选条件】 #3【group by 分组条件】 #4【having 分组后筛选】 #5【order by ...】 #7 内连接-等值连接其查询结果与sql92标准中的一致。inner关键字可以省略；多表（3以上）查询中，需保证前后两个表有连接条件。 12345678910111213141516171819202122232425262728293031#1.查询员工名以及对应的部门SELECT last_name,d.department_id FROM employees e INNER JOIN departments dON e.`department_id`=d.`department_id`;#2.名字包含e的员工名和工种名SELECT last_name,job_titleFROM employees eINNER JOIN jobs jON e.`job_id`=j.`job_id`WHERE e.`last_name` LIKE &#x27;%e%&#x27;;#3.部门员工个数大于3的部门名以及对应员工个数，按个数降序SELECT department_name,COUNT(*) FROM departments dINNER JOIN employees eON d.`department_id`=e.`department_id`GROUP BY department_nameHAVING COUNT(*)&gt;3ORDER BY COUNT(*) DESC;#4.员工名，部门名，工种名，按部门名降序SELECT last_name,department_name,job_titleFROM employees eINNER JOIN departments d ON e.`department_id`=d.`department_id`INNER JOIN jobs j ON e.`job_id`=j.`job_id`ORDER BY department_name; 内连接-非等值连接非等值连接与等值连接的不同之处在于：where子句使用=以外的条件运算符。 12345678910111213#查询员工的工资跟工资等级（employees表跟job_grades表）SELECT last_name,salary,grade_levelFROM employees eJOIN job_grades gON salary BETWEEN lowest_sal AND highest_sal;#查询员工的工资等级及该等级的工资的员工个数SELECT grade_level,COUNT(*)FROM employees eJOIN job_grades gON salary BETWEEN lowest_sal AND highest_salGROUP BY grade_level; 内连接-自连接自连接，顾名思义，即一个表连接它本身。适用的表的特点：表中有一个字段指向当前表的另一个字段。 查询员工名，对应的领导id跟领导名：（领导id指向员工名） 此处为两个employees表起了两个别名。 123SELECT a.`last_name`,a.`manager_id`,b.`last_name` manager_nameFROM employees a,employees bWHERE a.`manager_id`=b.`employee_id`; 1234SELECT a.`last_name`,a.`manager_id`,b.`last_name` manager_nameFROM employees aJOIN employees bON a.`manager_id`=b.`employee_id`; 外连接左/右外连接查询的特点：（注意主表、从表的概念） 查询结果保留主表的所有记录，对于从表，若有与主表匹配额的，显示匹配的值；若没用匹配的，显示null。 区分主表从表：对于左外连接，左主右从；对于右连接，右主左从。 可用于查询两表除了交集部分的剩余不匹配的记录。 ​ eg，例子只用了左外连接，右外连接同理，此处省略： 12345678910111213#1.查询所有女神，且若女神有男朋友，显示男朋友名SELECT b.&#96;id&#96;,b.name,bo.boyNameFROM beauty bLEFT JOIN boys boON b.&#96;boyfriend_id&#96;&#x3D;bo.&#96;id&#96;;#2.查询莫得男朋友的女神#先查询出上面例子的中间表，再使用筛选条件筛出莫得男朋友的女神SELECT b.name FROM beauty b LEFT JOIN boys bo ON b.&#96;boyfriend_id&#96; &#x3D; bo.&#96;id&#96; WHERE bo.&#96;id&#96; IS NULL; 上述例题2的实现可见如下图解： ​ 对于全外连接，MySQL不支持，理论上全外连接的查询结果是：对两个表的左外连接与右外连接的查询结果的并集。 交叉连接​ 交叉连接其实就是笛卡尔乘积的sql99标准写法。。。 即以下两钟查询结果相同： 123456SELECT b.name,bo.boyNameFROM beauty bCROSS JOIN boys bo;SELECT b.name,bo.boyNameFROM beauty b,boys bo; 子查询​ 出现在其他语句内部的select语句，成为子查询语句；相应的，内部嵌套其他select语句的查询成为外查询语句。子查询必须放在()内。 ​ 子查询按结果集的行列数不同可分为： 标量子查询（结果集只有一行一列，即一个单一值） 列子查询（一列多行） 行子查询（一行多列） 表子查询（多行多列） ​ 子查询可出现的位置： select后：仅支持标量子查询。 from后：支持上述所有查询。 where或having后：支持标量子查询、列、行子查询。 exists后（相关子查询）：表子查询。 以下按子查询出现位置展开。 where/having后的子查询​ where/having后的子查询支持标量、列、行子查询。其中 若条件表达式是&gt; &lt; = &lt;= &gt;= &lt;&gt;，则必须使用标量子查询，因为这些运算符只能匹配一个操作数。 若使用列子查询，一般搭配in，any/some，all关键字。 操作符 含义 in/not in 等于（或不等于）列表中的任一个 any/some（两者意义相同） 与列表中的任意一个比较满足条件，可用min、max代替 all 与列表中的所有值比较都满足条件 子查询的执行优先度高于主查询，因为主查询需用到子查询作为判断条件。 标量子查询： 12345678910111213141516171819202122232425262728293031#1.工资比Abel高的员工SELECT last_name FROM employeesWHERE salary&gt;( #标量子查询 SELECT salary FROM employees WHERE last_name&#x3D;&#39;Abel&#39;);#2.返回job_id与141号员工相同,sa1a比143号员工多的员工姓名, job_id和工资SELECT last_name,job_id,salary FROM employeesWHERE job_id&#x3D;( SELECT job_id FROM employees WHERE employee_id&#x3D;141)ANDsalary&gt;( SELECT salary FROM employees WHERE employee_id&#x3D;143);#3.查询最低工资大于50号部门最低工资 的 部门id 和 其最低工资SELECT department_id,MIN(salary)FROM employeesGROUP BY department_idHAVING MIN(salary)&gt;( SELECT MIN(salary) FROM employees WHERE department_id&#x3D;50); 列子查询： 1234567891011121314#1.返回1ocation_id是1400或1700的部门中的所有员工姓名SELECT last_name FROM employeesWHERE department_id IN( SELECT department_id FROM locations WHERE location_id IN (1400,1700));#2.返回其它工种中比（job_id为IT_PROG工种任一工资 1）低的员工的（员工号、姓名、job_id以及sa1ary 2）SELECT employee_id,last_name,job_id,salaryFROM employeesWHERE salary&lt;ANY( SELECT DISTINCT salary FROM employees WHERE job_id&#x3D;&#39;IT_PROG&#39;) AND job_id&lt;&gt;&#39;IT_PROG&#39;; 行子查询（一行多列或多行多列）：当筛选条件个数&gt;=2，且使用的判断符都一样，可以使用行子查询对多个字段同时判断。 123456#查询员工编号最小，工资最高的员工信息SELECT * FROM employeesWHERE (employee_id,salary)&#x3D;( SELECT MIN(employee_id),MAX(salary) FROM employees); select后的子查询select后的子查询只支持标量子查询。若子查询结果为空，则返回null值。 123456#每个部门的员工个数SELECT d.department_name,( SELECT COUNT(*) FROM employees e WHERE d.&#96;department_id&#96; &#x3D;e.department_id) &#39;count&#39; FROM departments d; from后的子查询from后的子查询可支持任何类型的子查询。eg： 1234567891011#查询每个部门的平均工资的工资等级#先查询每个部门的平均工资，再与工资等级表进行内连接查询SELECT ag_dep.*,grade_levelFROM ( SELECT department_id,AVG(salary) ag FROM employees GROUP BY department_id) ag_depINNER JOIN job_grades jON ag_dep.ag BETWEEN j.&#96;lowest_sal&#96; AND j.&#96;highest_sal&#96;; exists后的子查询**exists函数语法：exists(查询语句)**。 当查询语句的结果集不为空，则返回1，否则返回0。 eg： 1234567891011121314151617#有员工的部门名SELECT department_name FROM departments dWHERE EXISTS( SELECT * FROM employees e WHERE e.&#96;department_id&#96;&#x3D;d.&#96;department_id&#96;);# 用列子查询SELECT department_nameFROM departments dWHERE d.&#96;department_id&#96; IN(SELECT e.department_idFROM employees e); 分页查询（Limit）​ 当要显示的查询结果过多，只需先显示部分记录时，可用limit进行分页查询。**limit语句要放在查询语句的最后**。 ​ 语法： 123456limit size #显示从第一条记录开始的size条记录-- 显示从第pos（索引从0开始）条开始的size条记录limit pos,size -- 或limit pos offset size 对于web应用中的分页查询，假如要显示第page页，每页有size个记录，则查询语句为： select * from tableName limit (page-1)*size,size; 联合查询&emsp;&emsp;联合查询的作用是将多条查询语句的结果集合并为一个结果集。当要查询的信息来自多个表，且要查询的信息对应的字段在这些表中的类型一致，但这些表又没有直接关联，这时可使用联合查询。联合查询使用UNION关键字。 联合查询的语法： 12345查询语句1union查询语句2union... 联合查询的特点： 多条查询语句的查询列数必须一致。 每一列的类型必须一致；为了查询结果的正确显示，字段顺序也要一致（不一致不会报错，但结果会错误显示）。 union关键字默认去重（若是多个字段，则全部字段值相同才算相等），可使用union all显示重复项。 查询结果集的字段名与第一条查询语句的查询字段对应。 eg： 123select id,cname,csex from t_ca where csex=&#x27;男&#x27;unionselect t_id,tName,tGender from t_ua where tGender=&#x27;male&#x27;; DML&emsp;&emsp;DML（Data Manage Language），数据操作语言，用于对表进行插入（insert）、删除（delete）、更新（update）操作。 插入（insert）&emsp;&emsp;插入语句的语法有两种，如下： 123456789101112#1INSERT INTO table_name[(colum1, colum2, ...)] #该部分省略时默认所有字段VALUES(value1, value2, ...)[, (value11, value22, ...)] ; #可同时插入多个记录#2INSERT INTO table_nameSET colum1=value1, colum2=value2, ...;#3INSERT INTO table_name[(colum1, colum2, ...)]SELECT ...; &emsp;&emsp;第一种方式可以同时插入多个记录，字段列表可省略，省略时默认插入表对应的所有字段；当只是要插入一条记录，且插入少数字段，可使用第二种方式，更为简便，但不支持插入多条记录。还可以通过子查询语句插入记录，此时子查询语句的查询列表要与要插入的表的字段对应。 eg： 1234567891011INSERT INTO beauty VALUES(NULL, &#x27;女朋友&#x27;, &#x27;女&#x27;, &#x27;2000-02-26&#x27;, &#x27;123456&#x27;, NULL, 2); #主键部分写null即可#插入多条记录INSERT INTO beauty(NAME, sex, borndate, phone) VALUES(&#x27;女朋友&#x27;, &#x27;女&#x27;, &#x27;2000-02-26&#x27;, &#x27;4546984&#x27;),(&#x27;迪丽热巴&#x27;, &#x27;女&#x27;, &#x27;2020-02-26&#x27;, &#x27;549884&#x27;);#使用第二种语法INSERT INTO beauty set name=&#x27;ggggg&#x27;, borndate=&#x27;1998-02-25&#x27;, phone=&#x27;8582321&#x27;; 通过子查询插入值。eg： 12insert into beauty(id,name,phone)select 26,&#x27;宋茜&#x27;,&#x27;856132123&#x27;; 更新（update）​ 更新表的SQL语句语法：其中，更新多表记录就是先将多个表连接起来，再对连接后的结果集进行更改。更改操作将作用到原表。 123456789101112#更新单表记录UPDATE table_nameSET colum1=new_value1, colum2=new_value2, ...WHERE condition; #若不加筛选条件，会对字段对应的所有记录修改#更新多表记录(sql99标准)UPDATE table_name1 [alias]JOIN_TYPE JOIN table_name2 [alias]ON join_conditionSET colum1=new_value1, colum2=new_value2, ...WHERE condition; eg: 123456789101112UPDATE boys SET boyname=&#x27;张飞&#x27; WHERE boyname=&#x27;鹿晗&#x27;;#多表更新#修改张无忌的女朋友的电话号码为114455。需要先将boys表跟beauty表进行内连接UPDATE boys boINNER JOIN beauty beON bo.`id`=be.`boyfriend_id`SET be.`phone`=&#x27;114455&#x27;WHERE bo.`boyName`=&#x27;张无忌&#x27;; 删除（delete）​ 删除语句会删除满足条件的所有记录。且删除语句也支持单表跟多表的删除，其语法如下：其中： 多表删除中，若只是想删除其中一个表的记录，DELETE后的只写要删除的表的表名即可。总之，delete后写上要删除的记录对应的表。 12345678910#单表DELETE FROM table_nameWHERE condition; #若不加筛选条件，该语句会删除整个表的记录#多表DELETE alias1,alias2FROM table1_name alias1[join_type] join table2_name alias2ON join_conditionWHERE condition; eg： 123456789delete from beauty where phone like &#x27;%9&#x27;;#多表删除（该例子只删除beauty表）#删除张无忌的女朋友的信息DELETE beFROM boys boINNER JOIN beauty beON bo.`id`=be.`boyfriend_id`WHERE bo.`boyName`=&#x27;张无忌&#x27;; 当要删除整个表的记录，可以使用truncate关键字，语法是TRUNCATE [TABLE] table_name;。 使用delete删除跟truncate删除的区别： truncate不能加where。 truncate的删除效率稍微高一点。 若表中有自增长列，使用delete删除后不会改变当前的自增长值；而使用truncate删除后自增长值变为1。 truncate不能返回受影响的记录数，而delete可以。 在事务方面：delete是可以回滚的，而truncate不可回滚。 以下来自 MySQL TRUNCATE TABLE语句简介 如果使用 InnoDB表，MySQL将在删除数据之前检查表中是否有可用的外键约束。 以下是一些情况： 如果表具有任何外键约束，则TRUNCATE TABLE语句会逐个删除行。如果外键约束具有DELETE CASCADE动作，则子表中的相应行也将被删除。 如果外键约束没有指定 DELETE CASCADE 动作，则TRUNCATE TABLE将逐个删除行，并且遇到由子表中的行引用的行时（即其他表的外键指向该表的字段），它将停止并发出错误。 如果表没有任何外键约束，则TRUNCATE TABLE语句将删除该表并重新创建一个具有相同结构的新表，这比使用DELETE语句特别是对于大表更快更有效。 如果使用其他存储引擎，则 TRUNCATE TABLE 语句将删除并重新创建一个新表。 此外，TRUNCATE TABLE语句不使用DELETE语句，因此与表关联的DELETE触发器将不被调用。 DDL​ 数据定义语言（Data Define Language， DDL）用于对数据库、表进行创建、修改、删除操作。 库的管理库的相关语法如下：其中，对于创建、删除库，若是库已存在或不存在会报错，可使用IF (NOT) EXISTS进行判断，使语句正确执行。 123456789101112#创建库CREATE DATABASE [IF NOT EXISTS] database_name;#删除库DROP DATABASE [IF EXISTS] database_name;#修改库#修改库名（该语法似乎不用了）RENAME DATABASE database_name TO new_name;#修改字符集ALTER DATABASE database_name CHARACTER SET character_name; 表的管理1.表的创建创建表的语法： 123456CREATE TABLE [IF NOT EXISTS] table_name( colum_name COLUM_TYPE [(length) 约束], colum_name COLUM_TYPE [(length) 约束], ... colum_name COLUM_TYPE [(length) 约束],); eg: 12345CREATE TABLE book( id INT, bname VARCHAR(20), author VARCHAR(10)); 2.表的修改表的修改有修改列名、修改列的类型或约束、添加新列、删除列以及修改修改表名。对应的语法为： 1234567891011121314151617181920212223242526-- 修改表 -- 修改表本身的选项 ALTER TABLE 表名 表的选项（具体选项可见 5.-） eg: ALTER TABLE 表名 ENGINE=MYISAM; -- 对表进行重命名 RENAME TABLE 原表名 TO 新表名 RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库） -- RENAME可以交换两个表名 -- 修改表的字段机构 ALTER TABLE 表名 操作名 -- 操作名 ADD[ COLUMN] 字段定义 -- 增加字段 AFTER 字段名 -- 表示增加在该字段名后面 FIRST -- 表示增加在第一个 ADD PRIMARY KEY(字段名) -- 创建主键 ADD UNIQUE [索引名] (字段名)-- 创建唯一索引 ADD INDEX [索引名] (字段名) -- 创建普通索引 DROP[ COLUMN] 字段名 -- 删除字段 MODIFY[ COLUMN] 字段名 字段属性 -- 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上) CHANGE[ COLUMN] 原字段名 新字段名 字段属性 -- 支持对字段名修改 DROP PRIMARY KEY -- 删除主键(删除主键前需删除其AUTO_INCREMENT属性) DROP INDEX 索引名 -- 删除索引 DROP FOREIGN KEY 外键 -- 删除外键 -- 删除约束 # 除了上面3个drop，删除一些列级约束可以通过modify MODIFY [COLUMN] 字段名 字段类型 [新的约束]; -- 通过这种方法重新让字段没有约束越换成新的约束 TIPS：**表的修改中不支持if (not) exists**。 对于自增的主键字段，在删除若干记录再重新插入数据时，会出现id值“断层”，可以通过以下sql语句修改自增值： 1ALTER TABLE table_name AUTO_INCREMENT &#x3D; N; 3.表的删除DROP TABLE [IF EXISTS] table_name. 在sql脚本文件中写表或库创建的语句时，可以先删除表或库再创建，如下： 12DROP DATABASE IF EXISTS database_name;CREATE DATABASE database_name; 4.表的复制表的复制可分为： 通过LIKE关键字仅复制表的结构（复制全部字段，不包含数据）：CREATE TABLE copy_table_name LIKE exists_table; 复制表的结构（部分或全部字段）跟数据（部分或全部数据） 123CREATE TABLE copy_table_name SELECT 查询列表 FROM exists_tableWHERE condition; 通过查询列表来选择要复制的字段（使用select *即实现复制全部字段）。 通过where来筛选要复制的数据。可以通过where 0来过滤掉全部的数据，即只复制部分或全部字段；也可以直接去掉where来复制所选字段对应的全部数据。 5.表的选项/查看表结构12345678910111213141516171819202122232425262728表选项 -- 字符集 CHARSET = charset_name 如果表没有设定，则使用数据库字符集 -- 存储引擎 ENGINE = engine_name 表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同 常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive 不同的引擎在保存表的结构和数据时采用不同的方式 MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引 InnoDB表文件含义：.frm表定义，表空间数据和日志文件 SHOW ENGINES -- 显示存储引擎的状态信息 SHOW ENGINE 引擎名 &#123;LOGS|STATUS&#125; -- 显示存储引擎的日志或状态信息 -- 自增起始数 AUTO_INCREMENT = 行数 -- 数据文件目录 DATA DIRECTORY = &#x27;目录&#x27; -- 索引文件目录 INDEX DIRECTORY = &#x27;目录&#x27; -- 表注释 COMMENT = &#x27;string&#x27; -- 分区选项 PARTITION BY ... (详细见手册)-- 查看表结构 SHOW CREATE TABLE 表名 （信息更详细） DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE &#x27;PATTERN&#x27;] SHOW TABLE STATUS [FROM db_name] [LIKE &#x27;pattern&#x27;] MySQL数据类型MySQL的数据类型有： 数值型： 整型 小数：定点、浮点 字符型： 短文本：char、varchar 长文本：text、blob(较长的二进制数据) 日期型 整型​ 整形数据按字节大小可分为（括号内为字节数）：tinyint(1)、smallint(2)、mediumint(3)、int/integer(4)、bigint(8)。 整形数据的特点： 整形数据有有符号数和无符号数，默认是有符号数；要设置无符号数需在建表时添加 UNSIGNED关键字。如： create table test(t1 int, t2 int unsigned);。 若插入的数值超出了类型值的范围，会报out of range异常，并停止插入操作。 整型值的长度指的是最多能显示出来有多少个数字。若无指定，每种类型的整型都有默认长度。建表时可以使用ZEROFILL关键字，当不足长度时用0进行左填充。eg： 1234CREATE TABLE testss( t1 INT(7) ZEROFILL);INSERT INTO testss VALUES(55);#插入55，因为使用了zerofill关键字，会对55左填充0，即0000055. 小数小数类型有浮点型和定点型： 浮点型 float(M, D) double(M, D) 定点型（高精度）：dec/decimal(M, D) ​ 其中（M, D)的形式在建表时使用，M指整个数值的长度（意义同整型的长度），即整数部分长度+小数部分长度；D指小数部分的长度。也可省略，省略时dec默认是（10，0），而float跟double会自适应插入的数。 FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。 字符型字符型的分类： 短文本 char：建表时最大字符数可以省略，默认为1。该类型是固定长度的字符，即不管存入的数据是多少个字符，占用的空间都是指定的最大字符数。 varchar：建表时最大字符数不可以省略。该类型是可变长度的字符，即占用的空间根据存入的数据自适应，多大就存多少空间（存入数据&lt;=指定的最大字符数时）。 VARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。 在进行存储和检索时，会保留 VARCHAR 末尾的空格，而会删除 CHAR 末尾的空格 长文本 text blob（存放较大的二进制） 其他 binary、varbinary：类似char跟varchar。用于保存较短的二进制。 enum，用于保存枚举（只能保存一个数据），保存的值必须是枚举列表之一，枚举列表在建表时指定，eg： 1234567CREATE TABLE enumm( colum1 ENUM(&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;));INSERT INTO enumm VALUES(&#x27;a&#x27;);INSERT INTO enumm VALUES(&#x27;A&#x27;);#mysql不区分大小写，插入a、A效果一样INSERT INTO enumm VALUES(&#x27;d&#x27;);#插入的值不是枚举列表之一，报错 set，用于保存集合（可以保存多个数据），和enum类似，但可以保存多个值。eg： 123456CREATE TABLE sett( s1 SET(&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;) );INSERT INTO sett VALUES(&#x27;a,b&#x27;);INSERT INTO sett VALUES(&#x27;a,b,e&#x27;);#报错 enum、set值占用的存储空间随列表值个数的增加而增加。 日期类型日期类型如下表： 类型 字节 最小值 最大值 DATE 4 1000-01-01（只有日期） 9999-12-31 DATETIME 8 1000-01-01 00:00:00（日期+时间） 9999-12-31 23:59:59 TIMESTAMP 4 19700101080001（日期+时间） 2038 年的某个时刻 TIME 3 -838:59:59（只有时间） 838:59:59 YEAR 1 1901（只有年） 2155 timestamp和datetime 时间范围不一样，TIMESTAMP 要小很多 ，2038 年到期。timestamp 和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年到 2038 年。 对于TIMESTAMP，它把客户端插入的时间从当前时区转化为UTC（世界标准时间）进行存储。查询时，将其又转化为客户端当前时区（即根据系统变量time_zone的值）对应的时间进行返回。而对于DATETIME，不做任何改变，原样输入和输出。 timestamp更能反应实际的日期。 eg：（tips：中国位于东八时区，当前时间是2020-7-15 21:40分左右） 创建表并插入数据： 12345CREATE TABLE timee( t1 DATETIME, t2 TIMESTAMP);INSERT INTO timee VALUES(NOW(),NOW()); 使用select * from timee;查询表，如下： 设置当前时区为东九区：SET time_zone=&#39;+9:00&#39;; ，查询： 可见，两次查询t1的两个值都不变，插入时的时间是什么，查询出的是什么。 而t2查询出的值是保存的UTC时间转化为当前时区的时间。比如第一行的t2值，插入数据时是在东八区，该时刻的东九区比东八区快一个小时。 MySQL约束概述​ 约束就是一种限制，用于限制表中的数据，使数据有更好的准确和可靠性。 MySQL中的常见约束： 约束类型 主键 外键 唯一 非空 自增 默认值 关键字 primary key foreign key unique not null auto_increment default 含义 相当于unique+not null，一般用于id 用于限制两个表的关系，即从表的某个字段指向主表的某一字段 唯一性、可以为空 不能为空 自增 指定字段的默认值 ​ 添加约束可以在创建表时或修改表时。 ​ 约束又可分为列级约束和表级约束：除了外键，其他约束都支持列级约束；除了非空、默认以及自增，其他约束都支持表级约束。列级约束在创建表时在字段名+字段数据类型之后添加即可；表级约束在最底下声明，语法为： [CONSTRAINT constraint_name] CONSTRAINT_TYPE(colum_name) 主键、唯一键可以使用列级跟表级两种语法进行声明。 eg： 1234567891011121314151617#列级约束CREATE TABLE major( id INT PRIMARY KEY, major_name VARCHAR(10) NOT NULL UNIQUE #可以同时添加多个约束);CREATE TABLE stuinfo( id INT AUTO_INCREMENT, stu_name VARCHAR(10) NOT NULL, stu_number CHAR(8), majorid INT , CONSTRAINT fk_stuinfo_major FOREIGN KEY(majorid) REFERENCES major(id), UNIQUE(stu_number), PRIMARY KEY(id)); PRIMARY KEY和UNIQUE 两者都保证了唯一性，但主键不能为空。 一个表中只能有一个主键，但可以有多个unique。 unique约束的字段，是可以插入多个null值的。 可以多个字段组合成一个主键或unique。**该方式不推荐**。 关于上述组合的解释： 12345678910111213CREATE TABLE test( id INT , sname VARCHAR(10), number VARCHAR(10), PRIMARY KEY(id, number) #将id和number组合为一个主键);INSERT INTO test VALUES(1,&#x27;as&#x27;,&#x27;john&#x27;);INSERT INTO test VALUES(2,&#x27;as&#x27;,&#x27;john&#x27;);INSERT INTO test VALUES(2,&#x27;as&#x27;,&#x27;mike&#x27;);INSERT INTO test VALUES(1,&#x27;as&#x27;,&#x27;john&#x27;);SELECT * FROM test; 前3条insert语句都能正确执行，第4条则报错。即对于组合的主键，**只有组合的几个字段的值都相等才算相同。组合unique同理**。 关于外键外键的一些特点： 外键是在从表设置的。 从表的外键字段的数据类型与主表的关联列的类型要一致或可兼容。 主表的关联列必须是一个key，一般都是主键，也可以是unique键。eg: 1234567891011DROP TABLE IF EXISTS main_table;CREATE TABLE main_table( id INT UNIQUE #unique键);DROP TABLE IF EXISTS forei_table;CREATE TABLE forei_table( mainid INT, fname VARCHAR(10), FOREIGN KEY(mainid) REFERENCES main_table(id)); 外键字段的值可以为null，但要插入值时，在主表的关联字段必须有对应的数据存在，否则不可插入。 默认情况下，主表被关联字段的数据的更改或更新操作被拒绝。有以下几个操作可选（在从表设置外键时在语句的最后添加ON DELETE加上以下字段）： cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。 set null，置null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。注意，要求该外键列没有not null属性约束。 restrict，拒绝主表的外键关联字段的删除和更新。（默认） eg： 1234567DROP TABLE IF EXISTS stu;CREATE TABLE stu( id INT PRIMARY KEY, stuname VARCHAR(10), major_id INT, FOREIGN KEY(major_id) REFERENCES major(id) ON DELETE CASCADE); 外键只被InnoDB存储引擎所支持。其他引擎是不支持的。 关于auto_increment 对有auto_increment约束的字段插入值，比如插入10，那么下一个序号将会是11。 auto_increment必须和key搭配，如主键，唯一键。 一个表只能有一个auto_increment。 auto_increment只能用于数值型字段。 标识列可以通过SET auto_increment_increment=3;设置步长，也可以通过手动插入值设置起始值。 视图概述（部分摘抄自https://shockerli.net/post/1000-line-mysql-note/） ​ 视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。 ​ 视图具有表结构文件，但不存在数据文件。对其中所引用的基础表来说，视图的作用类似于筛选。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。 ​ 可简单的这样理解：视图存储的是sq逻辑，即sql语句，当要使用视图时根据该语句动态生成结果集。 视图的创建和使用创建视图的语法： 12345CREATE VIEW view_nameAS查询语句; -- 一般是涉及多个表的复杂的查询语句SHOW CREATE VIEW view_name; -- 显示视图结构 创建视图后，使用视图类似于使用表。 eg: 12345678910CREATE VIEW myv1ASSELECT last_name,department_name,job_titleFROM employees eJOIN departments d ON e.department_id=d.department_idJOIN jobs j ON j.job_id = e.job_id;SELECT * FROM myv1 WHERE last_name LIKE &#x27;%a%&#x27;; 视图的修改两种方式： 1234567891011121314151617181920212223242526#1(如果视图不存在会创建；视图存在就代替)CREATE OR REPLACE VIEW view_nameas查询语句;eg:CREATE OR REPLACE VIEW myv1ASSELECT last_name,d.manager_id,job_titleFROM employees eJOIN departments d ON e.department_id=d.department_idJOIN jobs j ON j.job_id = e.job_id;#2ALTER VIEW view_nameAS查询语句;eg:ALTER VIEW myv1ASSELECT last_name,department_name,job_titleFROM employees eJOIN departments d ON e.department_id=d.department_idJOIN jobs j ON j.job_id = e.job_id; 视图的删除和查看123456#删除DROP VIEW view1_name,view2_name...;#查看结构DESC view_name;SHOW CREATE VIEW view_name; 视图更新​ 视图的可更新性和视图中查询的定义有关系，以下类型的视图是不能更新的 包含以下关键字的sql语句：分组函数、distinct、group by、having、union或者uunion all 常量视图 Select中包含子查询 Join from一个不能更新的视图 where子句的子查询引用了from子句中的表 一般情况下视图都是不可更新的。 可更新视图的简单示例：tips：更新会作用到原表。 1234567891011121314CREATE VIEW myv3AS SELECT last_name, phone_numberFROM employees ;#insertINSERT INTO myv3 VALUES(&#x27;许褚&#x27;,&#x27;888888&#x27;);#updateUPDATE myv3 SET last_name=&#x27;典韦&#x27; WHERE last_name=&#x27;许褚&#x27;;#deleteDELETE FROM myv3 WHERE last_name=&#x27;典韦&#x27;; 对视图进行修改需要有权限。 视图与表 两者创建的语法不同。 从占用存储空间方面：视图只是保存了sql语句，只占用了很小的空间；而表保存了数据，占用空间较大。 视图一般都不允许增删改查；表允许。 变量MySQL变量的分类： 系统变量 全局变量 会话变量 自定义变量 用户变量 局部变量 系统变量​ 系统变量是由MySQL系统提供的，用于设置服务器的某些功能。分为全局（global）变量和会话（session）变量。两者主要区别是作用域不同，全局变量的作用域是所有会话（连接），但每次重启MySQL服务器都会重置；而会话变量只针对当前会话有效。 1234567891011121314151617181920--（对于会话变量，session可省略）--查看所有全局/会话变量SHOW GLOBAL|SESSION VARIABLES;--添加筛选条件SHOW GLOBAL VARIABLES LIKE condition;--查看单个变量SELECT @@global|[session].变量名--修改SET GLOBAL|SESSION 变量名=new_value;SET @@global|[session].变量名=new_value;eg:SHOW GLOBAL VARIABLES LIKE &#x27;%tx_is%&#x27;;SELECT @@global.autocommit;SHOW GLOBAL VARIABLES LIKE &#x27;%char%&#x27;; 自定义变量用户变量针对当前会话有效，即与会话变量作用域相同。用户变量可以应用在begin-end里面以及外面。 12345678910111213141516--声明(变量名使用@开头，避免与系统变量产生冲突)SET @variable_name=value;SET @variable_name:=value;SELECT @variable_name:=value;--修改（与声明同）--1SET @variable_name=value;SET @variable_name:=value;SELECT @variable_name:=value;--2SELECT column_name(只能有一个字段) INTO @variable_nameFROM table_name [where ...]--使用SELECT @variable_name; 局部变量只在begin-end块中有效。在块的开头声明。一般不使用@。局部变量应用在存储过程、函数等。 1234567891011121314--声明(可不加@)DECLARE variable_name DATATYPE [DEFAULT value];--修改--1(使用select加@)SET variable_name=value;SET variable_name:=value;SELECT @variable_name:=value;--2SELECT column_name(只能有一个字段) INTO variable_nameFROM table_name [where ...]--使用SELECT variable_name; eg： 12345678--user variableSET @m=1;SET @n=2;SET @sum=@m+@n;SELECT @sum;--局部变量。。 存储过程​ 存储过程是一段可执行性sql代码的集合。相比函数，更偏向于业务逻辑。实际上存储过程即类似于Java中的方法。 关于DELIMITER：该关键字用于指定命令结束符号，即告诉MySQL当遇见结束符时表示命令结束，可以执行。默认情况下是;。在某些情况下，不止要执行一条SQL语句，但又需要;作为各语句的结束，这时可使用该关键字指定其他的结束符。下面的存储过程创建即使用了这一点。 创建存储过程前需要先使用DELIMITER关键字指定除;外的结束符。 12345678910111213141516171819202122232425--语法--若过程体只有一句SQL语句，begin-end可以省略--过程体的每条SQL语句必须以分号结尾DELIMITER $(可使用其他符号)CREATE PROCEDURE 过程名 (参数列表)BEGIN 过程体END $--参数列表的每个参数定义包含3个部分IN|OUT|INOUT 参数名 数据类型--其中IN 输入：在调用过程中，将数据输入到过程体内部的参数OUT 输出：在调用过程中，将过程体处理完的结果返回到客户端INOUT 输入输出：既可输入，也可输出--调用CALL 存储过程名(实参列表)--删除存储过程DROP PROCEDURE procedure_name;--查看存储过程的结构SHOW CREATE PROCEDURE procedure_name; eg： 12345678910111213141516171819202122232425262728293031323334353637DELIMITER $CREATE PROCEDURE insert_to_major()BEGIN INSERT INTO major VALUES(4,&#x27;a&#x27;),(5,&#x27;b&#x27;),(6,&#x27;c&#x27;),(7,&#x27;d&#x27;);END $CALL insert_to_major();--判断登录是否成功DELIMITER $CREATE PROCEDURE login(IN username VARCHAR(10),IN password VARCHAR(10))BEGIN DECLARE result INT DEFAULT 0; SELECT COUNT(*) INTO result FROM admin WHERE admin.`username`=username AND admin.`password`=password; SELECT IF(result&gt;0,&#x27;登录成功&#x27;,&#x27;登录失败&#x27;) &#x27;登录情况&#x27;;END $CALL login(&#x27;吴彦祖&#x27;,&#x27;123456&#x27;);--根据女神名获取男朋友名字（使用了in out）DELIMITER $CREATE PROCEDURE get_boyfriend(IN girl_name VARCHAR(10),OUT boyfriend VARCHAR(10))BEGIN SELECT bo.boyName INTO boyfriend FROM boys bo INNER JOIN beauty b ON b.boyfriend_id=bo.id WHERE b.name=girl_name;END $SET @bname = &#x27;&#x27;;CALL get_boyfriend(&#x27;王语嫣&#x27;,@bname);SELECT @bname; 函数自定义函数MySQL的函数有系统自带（内置函数）的，也可以自定义函数。函数于存储体类似，都是一组SQL语句的集合。 其与存储体的区别如下： 存储体可以有0或多个返回值。适合批量操作。 函数有且仅有一个返回值。适合用于对数据处理后返回一个数据。 (部分摘抄自https://shockerli.net/post/1000-line-mysql-note/) 12345678910111213141516171819202122232425-- 创建函数DELIMITER $(可使用其他符号)CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型BEGIN 函数体END $- 函数名，应该合法的标识符，并且不应该与已有的关键字冲突。- 一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。- 参数部分，由&quot;参数名&quot;和&quot;参数类型&quot;组成。多个参数用逗号隔开。- 函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。- 若函数体只有一条语句，可以省略begin-end- 必须有 return 返回值语句。-- 调用SELECT function_name(实参列表);-- 删除DROP FUNCTION [IF EXISTS] function_name; -- 查看SHOW FUNCTION STATUS LIKE &#x27;partten&#x27;SHOW CREATE FUNCTION function_name; -- 修改ALTER FUNCTION function_name 函数选项 eg: 12345678910111213#根据员工名获取工资DELIMITER $CREATE FUNCTION getsal(empName VARCHAR(10)) RETURNS DOUBLEBEGIN SET @sal = 0; SELECT salary INTO @sal FROM employees WHERE last_name=empName; RETURN @sal;END $SELECT getsal(&#x27;Hunold&#x27;); 内置函数​ MySQL内置函数有单行函数和分组函数： 单行函数：作用范围只有一行，即一个记录。 分组函数：作用的范围是多个记录（即一列），对多个记录进行统计，再返回一个结果。又称统计函数。 单行函数-字符函数LENGTH(str) 返回str的长度（字节数），其中，若使用的是utf8字符集，则一个英文占1个字节，一个中文占3个字节。 eg： SELECT LENGTH(&#39;不摇碧莲&#39;); 返回12.SELECT LENGTH(&#39;jonh&#39;); 返回4. ---------------------------------------------------------------------------------- UPPER(str)、LOWER(str) 转化为大写、小写。eg： SELECT UPPER(&#39;john&#39;); SELECT LOWER(&#39;MIKE&#39;); ---------------------------------------------------------------------------------- CONCAT(str1,str2,...) 拼接字符。 SELECT CONCAT(last_name,&#39;_&#39;,first_name) &#39;name&#39; FROM employees;SELECT CONCAT(LOWER(last_name),&#39;_&#39;,UPPER(first_name)) &#39;name&#39; FROM employees; （函数嵌套） ---------------------------------------------------------------------------------- SUBSTR substring 该函数有4个重载的形式。sql中的索引从1开始。 substr(str,start)： substr(str FROM pos) 返回从pos开始的子字符串 substr(str, pos, length) 返回从索引pos开始，长度为length的子字符串 substr(str FROM pos FOR length) 1234SELECT SUBSTR(&#x27;一二三四五六&#x27;,4) output;SELECT SUBSTR(&#x27;一二三四五六&#x27; FROM 3) output; #三四五六SELECT SUBSTR(&#x27;一二三四五六&#x27;,1,4) output;SELECT SUBSTR(&#x27;一二三四五六&#x27; FROM 1 FOR 3) output; ---------------------------------------------------------------------------------- INSTR(str,substr) 返回子串第一次出现的位置，若不包含该子串，返回0。 SELECT INSTR(&#39;一二三四五六&#39;, &#39;四五六&#39;) output; #4SELECT INSTR(&#39;一二三四五六&#39;, &#39;四六&#39;) output; #0 ---------------------------------------------------------------------------------- TRIM([deleteStr] FROM str) 去掉前后的空格或指定字符（中间的字符不受影响）。eg： SELECT TRIM(&#39; 啊哈哈哈 &#39;) output;SELECT TRIM(&#39;a&#39; FROM &#39;aaaaa啊哈哈aaa&#39;) output; ---------------------------------------------------------------------------------- LPAD(str,length,padstr) 用padstr对str进行左填充达到length长度。rpad()同理。 eg： SELECT LPAD(&#39;张三&#39;,10,&#39;a&#39;) output; # aaaaaaaa张三 SELECT RPAD(&#39;张三&#39;,10,&#39;a&#39;) output; # 张三aaaaaaaa **其中，若是length参数小于str的长度，相当于substr(str,1,length)**，对lpad、rpad都一样。eg： SELECT LPAD(&#39;张三四&#39;,2,&#39;a&#39;) output; # 张三 SELECT RPAD(&#39;张三四&#39;,2,&#39;a&#39;) output; # 张三 ---------------------------------------------------------------------------------- REPLACE(str,fromStr,toStr) 替换。eg： SELECT REPLACE(&#39;小明爱上了小红&#39;,&#39;小红&#39;,&#39;小绿&#39;) output; #小红爱上了小绿 单行函数-数字函数12345678910111213141516#四舍五入SELECT ROUND(1.56) output; # 2SELECT ROUND(-1.54) output; #-2SELECT ROUND(1.567, 2) output; # 1.57#向上取整SELECT CEIL(1.2) output; #2SELECT CEIL(-1.1) output; # -1#向下取整SELECT FLOOR(1.2) output;SELECT FLOOR(-1.2) output; # -2#截断SELECT TRUNCATE(1.1999,1) output; # 1.1，没有四舍五入#模运算SELECT MOD(10,3) output; #10%3#生成0-1的任意数以及0-100的任意数SELECT RAND(),RAND()*100; 单行函数-日期函数1234567891011121314151617181920212223242526#返回当前系统日期+时间SELECT NOW() &#x27;time&#x27;;#返回当前系统日期SELECT CURDATE() &#x27;time&#x27;;#返回当前系统时间SELECT CURTIME() &#x27;time&#x27;;#截取日期中的年、月、日day、小时hour、分min?、秒secondSELECT YEAR(NOW()) &#x27;year&#x27;;SELECT YEAR(&quot;1998-12-12&quot;) &#x27;year&#x27;;SELECT YEAR(hiredate) &#x27;year&#x27; FROM employees;SELECT MINUTE(NOW()) &#x27;minute&#x27;;SELECT MONTH(NOW()) &#x27;month&#x27;;SELECT MONTHNAME(NOW()) &#x27;monthname&#x27;; # 获取月的英文名称#将字符串根据指定格式转化为日期，具体格式见下表SELECT STR_TO_DATE(&#x27;1999-10-22&#x27;,&#x27;%Y-%m-%d&#x27;) output;SELECT * FROM employees WHERE hiredate=STR_TO_DATE(&#x27;4-3 1992&#x27;,&#x27;%c-%d %Y&#x27;);#将日期根据指定格式转化为字符，SELECT DATE_FORMAT(NOW(),&#x27;%Y年%m月%d日&#x27;) output;#查询有奖金的员工名跟入职日期(xx月/xx日 xx年的格式)SELECT last_name, DATE_FORMAT(hiredate,&#x27;%m月/%d日 %Y年&#x27;) FROM employeesWHERE commission_pct IS NOT NULL; #计算两个日期之间相差的天数SELECT DATEDIFF(MAX(hiredate),MIN(hiredate)) FROM employees; 单行函数-其他函数1234567891011SELECT VERSION();#当前版本SELECT DATABASE();#当前数据库名SELECT USER(); #当前用户名#返回字符串的加密形式、md5加密形式SELECT PASSWORD(&#x27;objk&#x27;),MD5(&#x27;ojbk&#x27;);--若exp1为null，返回exp2值，否则返回exp1的值。IFNULL(exp1, exp2)-- 若expr为真，返回1，否则0isnull(expr) 单行函数-流程控制函数if(condition,expr1,expr2) 若条件为真，返回expr1，否则返回expr2。 eg： SELECT last_name,IF(commission_pct IS NOT NULL,&#39;有奖金&#39;,&#39;没奖金&#39;) 备注 FROM employees; 分组函数常见的分组函数有： sum(expr) 求和 avg(expr) 求平均值 max(expr) 求最大值 min(expr) 求最小值 count(expr) 求数量 其中： 分组函数的参数一般为字段名。 sum、avg一般只接受数值型参数，max、min、count可接受任何类型的参数。 5个函数对null值忽略，即对null值不统计、不计算。 可与distinct配合使用，会对结果先去重，再进行函数计算。 与分组函数一同查询的字段应有限制（分组函数查询结果只有一个值，而查询字段可能会有多个值），一般要求是group by后的字段。 eg： 12345678SELECT SUM(salary) &#x27;sum&#x27;,AVG(salary) &#x27;average&#x27;,MIN(salary) &#x27;min&#x27;,MAX(salary) &#x27;max&#x27;,COUNT(salary) &#x27;count&#x27;FROM employees;SELECT MAX(last_name),MIN(last_name) FROM employees;SELECT MAX(hiredate),MIN(hiredate) FROM employees;SELECT SUM(DISTINCT salary) 去重,SUM(salary) 不去重 FROM employees;##SELECT COUNT(DISTINCT commission_pct),COUNT(commission_pct) FROM employees; COUNT()函数 ​ 在5个函数中，count()函数有些许不同。 ​ 可使用count(*)跟count(1)来统计一个表有多少个记录。使用后者相当于在每个记录中添加一个名为1的字段（即新添加一个列），并统计共有多少行。 tips：myisam引擎下，count(*)效率更高；innodb引擎下，两者效率相差不多。 流程控制分支结构if函数见函数\\内置函数第5点。 case..when该语法有两种使用形式，可嵌套在select中（此时整个case-when执行后返回一个值），也可单独使用。 **第一钟类似Java的swich..case**。具体语法： 1234567891011case 要判断的字段、表达式when 常量1 then 要显示的值1或语句1;...when 常量n then 要显示的值n或语句n;else 默认显示end eg，根据部门id的不同，显示不同的最终工资： 12345678SELECT last_name,salary 原工资,department_id,CASE department_idWHEN 30 THEN salary*1.1WHEN 40 THEN salary*1.2WHEN 50 THEN salary*1.3ELSE salaryEND AS 最终工资FROM employees; 第二种用法类似多层if，语法如下： 1234567891011case when condition1 then 要显示的值1或语句1;...when condition_n then 要显示的值n或语句n;else 默认显示end eg： 12345678910111213141516171819202122232425--嵌套在select中使用--根据工资的大小区间分多个工资级别：SELECT last_name,salary,CASEWHEN salary&gt;20000 THEN &#x27;A&#x27;WHEN salary&gt;15000 THEN &#x27;B&#x27;WHEN salary&gt;10000 THEN &#x27;C&#x27;ELSE &#x27;D&#x27;END AS 工资级别FROM employees;--在存储过程中使用--根据工资显示工资级别DELIMITER $CREATE PROCEDURE testcase(IN score INT)BEGIN CASE WHEN score&gt;=90 AND score&lt;=100 THEN SELECT &#x27;A&#x27;; WHEN score&gt;=80 THEN SELECT &#x27;B&#x27;; WHEN score&gt;=60 THEN SELECT &#x27;C&#x27;; ELSE SELECT &#x27;D&#x27;; END CASE;END $ CALL testcase(95); 两种case-when的特点： 可以作为表达式， 嵌套在其他语句中使用（此时整个CASE-WHEN执行完毕后返回一个值，如第一种用法的例子）；可以作为独立的语句，但必须放在begin-end中。 如果WHEN中的值满足或条件成立， 则执行对应的THEN后面的语句，并且结束CASE。如果都不满足， 则执行ELSE中的语句或值。 ELSE可以省略， 如果ELSE省略了， 并且所有WHEN条件都不满足， 则返回NULL。 if结构if结构只能使用在begin-end中。 语法 12345IF search_condition THEN statement_list ELSEIF search_condition THEN statement_list...[ELSE statement_list;]END IF; 循环结构123456789101112131415161718192021-- while循环[label_name:] while 循环条件 do 循环体;end while [label_name];- 如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。 -- 退出循环 退出整个循环 leave label_name; 退出当前循环 iterate label_name;--loop循环[label_name:] loop 循环体;end loop [label_name]; --需搭配leave和iterate，否则会死循环--repeat[label_name:] repeat 循环体;until 结束循环的条件end repeat [label_name];","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/Tag/MySQL/"}]}],"categories":[{"name":"Java","slug":"Java","permalink":"http://example.com/categories/Java/"},{"name":"多线程","slug":"Java/多线程","permalink":"http://example.com/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"其他","slug":"Java/其他","permalink":"http://example.com/categories/Java/%E5%85%B6%E4%BB%96/"},{"name":"集合源码","slug":"Java/集合源码","permalink":"http://example.com/categories/Java/%E9%9B%86%E5%90%88%E6%BA%90%E7%A0%81/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/categories/MySQL/"},{"name":"基础","slug":"Java/基础","permalink":"http://example.com/categories/Java/%E5%9F%BA%E7%A1%80/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"JVM","slug":"Java/JVM","permalink":"http://example.com/categories/Java/JVM/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"IDEA","slug":"IDEA","permalink":"http://example.com/categories/IDEA/"},{"name":"框架","slug":"框架","permalink":"http://example.com/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Java并发","slug":"Java并发","permalink":"http://example.com/Tag/Java%E5%B9%B6%E5%8F%91/"},{"name":"Java","slug":"Java","permalink":"http://example.com/Tag/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"http://example.com/Tag/Java%E5%9F%BA%E7%A1%80/"},{"name":"MySQL","slug":"MySQL","permalink":"http://example.com/Tag/MySQL/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/Tag/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"JVM","slug":"JVM","permalink":"http://example.com/Tag/JVM/"},{"name":"设计模式","slug":"设计模式","permalink":"http://example.com/Tag/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"IDEA","slug":"IDEA","permalink":"http://example.com/Tag/IDEA/"},{"name":"Jackson","slug":"Jackson","permalink":"http://example.com/Tag/Jackson/"},{"name":"Mybatis","slug":"Mybatis","permalink":"http://example.com/Tag/Mybatis/"}]}